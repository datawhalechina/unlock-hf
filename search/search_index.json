{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Unlock-HuggingFace","text":"<p>\u8fd1\u5e74\u6765\uff0c\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u9886\u57df\u968f\u7740 Transformer \u67b6\u6784\u7684\u51fa\u73b0\u53d6\u5f97\u4e86\u7a81\u7834\u6027\u8fdb\u5c55\uff0cHuggingFace\u00a0\u29c9 \u4f5c\u4e3a NLP \u793e\u533a\u7684\u91cd\u8981\u529b\u91cf\uff0c\u63d0\u4f9b\u4e86\u6d77\u91cf\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u4f17\u591a\u5f3a\u5927\u6613\u7528\u7684\u51fd\u6570\u5e93\uff0c\u6781\u5927\u5730\u964d\u4f4e\u4e86 NLP \u5e94\u7528\u5f00\u53d1\u7684\u95e8\u69db\u3002</p> <p>\u672c\u9879\u76ee\u65e8\u5728\u4e3a\u5b66\u4e60\u8005\u63d0\u4f9b\u6df1\u5165\u5b66\u4e60 HuggingFace\ud83d\ude0a \u751f\u6001\u7cfb\u7edf\u7684\u6559\u7a0b\uff0c\u5e76\u901a\u8fc7\u5b8c\u6210\u751f\u52a8\u6709\u8da3\u7684\u5177\u4f53\u9879\u76ee\u63d0\u5347\u5b66\u4e60\u8005\u5b9e\u8df5\u6c34\u5e73\u3002</p>"},{"location":"#_1","title":"\u5185\u5bb9\u5bfc\u822a","text":"<p>\u5185\u5bb9\u5927\u7eb2\u5927\u81f4\u4e3a:</p> <p></p> \u7ae0\u8282 \u5185\u5bb9 \u5907\u6ce8 \u524d\u8a00 NLP\u4e0eHuggingFace\u6574\u4f53\u4ecb\u7ecd \u5305\u62ec\u73af\u5883\u914d\u7f6e \u7b2c\u4e00\u7ae0 Datasets\u5de5\u5177 \u7b2c\u4e8c\u7ae0 Transformers\u5de5\u5177 Pipeline\u5de5\u5177,Tokenizer\u5de5\u5177,Model\u5de5\u5177,Trainer\u5de5\u5177 \u7b2c\u4e09\u7ae0 PEFT\u5de5\u5177 \u7b2c\u56db\u7ae0 Evaluate\u5de5\u5177 \u7b2c\u4e94\u7ae0 Diffusers\u5de5\u5177 \u7b2c\u516d\u7ae0 \u9879\u76ee\u6848\u4f8b \u7b2c\u4e03\u7ae0 Gradio\u5de5\u5177 \u5927\u7eb2\u5177\u4f53\u5185\u5bb9 <p></p>"},{"location":"#_2","title":"\u53c2\u4e0e\u8d21\u732e","text":"<ul> <li>\u5982\u679c\u4f60\u60f3\u53c2\u4e0e\u5230\u9879\u76ee\u4e2d\u6765\u6b22\u8fce\u67e5\u770b\u9879\u76ee\u7684 Issue\u00a0\u29c9 \u67e5\u770b\u6ca1\u6709\u88ab\u5206\u914d\u7684\u4efb\u52a1\u2728\u3002</li> <li>\u5982\u679c\u4f60\u53d1\u73b0\u4e86\u4e00\u4e9b\u95ee\u9898\uff0c\u6b22\u8fce\u5728 Issue\u00a0\u29c9 \u4e2d\u8fdb\u884c\u53cd\u9988\ud83d\udc1b\u3002</li> </ul> <p>\u5982\u679c\u4f60\u5bf9 Datawhale \u5f88\u611f\u5174\u8da3\u5e76\u60f3\u8981\u53d1\u8d77\u4e00\u4e2a\u65b0\u7684\u9879\u76ee\uff0c\u6b22\u8fce\u67e5\u770b Datawhale \u8d21\u732e\u6307\u5357\u00a0\u29c9\u3002</p>"},{"location":"#_3","title":"\u8d21\u732e\u8005\u540d\u5355","text":"\u59d3\u540d \u804c\u8d23 \u7b80\u4ecb \u7530\u5065\u7fd4 \u9879\u76ee\u8d1f\u8d23\u4eba \u5185\u5bb9\u521b\u4f5c\u8005 \u4e8e\u5c0f\u654f \u9879\u76ee\u6307\u5bfc\u4eba DataWhale\u6b63\u5f0f\u6210\u5458 \u5362\u946b\u658c \u7b2c1\u7ae0(Datasets)\u8d21\u732e\u8005 \u5185\u5bb9\u521b\u4f5c\u8005 \u80e5\u4f73\u7a0b \u7b2c3\u7ae0(PEFT)\u8d21\u732e\u8005 \u5185\u5bb9\u521b\u4f5c\u8005 \u79e6\u5b50\u6db5 \u7b2c5\u7ae0(Diffusers)\u8d21\u732e\u8005 \u5185\u5bb9\u521b\u4f5c\u8005 \u9648\u51ef\u6b4c \u7b2c7\u7ae0(Gradio)\u8d21\u732e\u8005 \u5185\u5bb9\u521b\u4f5c\u8005 \u5218\u7855 \u7b2c7\u7ae0(Gradio)\u8d21\u732e\u8005 \u5185\u5bb9\u521b\u4f5c\u8005 <ul> <li>PEFT<ul> <li>LoRa\uff1a@\u946b\u6c11\u00a0\u29c9</li> <li>AdaLoRa\uff1a@\u946b\u6c11\u00a0\u29c9</li> <li>IA3\uff1a@\u946b\u6c11\u00a0\u29c9</li> <li>Prefix-Tuning\uff1a@\u946b\u6c11\u00a0\u29c9</li> <li>prompt-Tuning\uff1a@\u946b\u6c11\u00a0\u29c9</li> <li>P-Tuning\uff1a@\u946b\u6c11\u00a0\u29c9</li> </ul> </li> </ul> <p>\u9879\u76ee\u4fdd\u59c6(o^^o)\uff1a\u9ad8\u589e\u7389</p> <p>\u8d1f\u8d23\u4eba\u8054\u7cfb\u90ae\u7bb1\ud83d\udceb: wwxy.mail@gmail.com</p>"},{"location":"#_4","title":"\u5173\u6ce8\u6211\u4eec","text":"<p>\u626b\u63cf\u4e0b\u65b9\u4e8c\u7ef4\u7801\u5173\u6ce8\u516c\u4f17\u53f7\uff1aDatawhale</p>"},{"location":"#license","title":"LICENSE","text":"<p>\u672c\u4f5c\u54c1\u91c7\u7528\u77e5\u8bc6\u5171\u4eab\u7f72\u540d-\u975e\u5546\u4e1a\u6027\u4f7f\u7528-\u76f8\u540c\u65b9\u5f0f\u5171\u4eab 4.0 \u56fd\u9645\u8bb8\u53ef\u534f\u8bae\u8fdb\u884c\u8bb8\u53ef\u3002</p> <p>\u6ce8\uff1a\u9ed8\u8ba4\u4f7f\u7528CC 4.0\u534f\u8bae\uff0c\u4e5f\u53ef\u6839\u636e\u81ea\u8eab\u9879\u76ee\u60c5\u51b5\u9009\u7528\u5176\u4ed6\u534f\u8bae</p>"},{"location":"_sidebar/","title":"sidebar","text":"<ul> <li>\u7b2c1\u7ae0 \u6211\u662f\u7b2c1\u7ae0\u7684\u6807\u9898</li> <li>\u7b2c2\u7ae0 \u6211\u662f\u7b2c2\u7ae0\u7684\u6807\u9898<ul> <li>2.1 \u6211\u662f2.1\u7684\u6807\u9898</li> <li>2.2 \u6211\u662f2.2\u7684\u6807\u9898</li> </ul> </li> <li>\u7b2c3\u7ae0 \u6211\u662f\u7b2c3\u7ae0\u7684\u6807\u9898<ul> <li>3.1 \u6211\u662f3.1\u7684\u6807\u9898<ul> <li>3.1.1 \u6211\u662f3.1.1\u7684\u6807\u9898</li> <li>3.1.2 \u6211\u662f3.1.2\u7684\u6807\u9898</li> </ul> </li> </ul> </li> </ul>"},{"location":"appendix/appendix_index/","title":"\u7d22\u5f15","text":"<p>\u4e3b\u9875</p> <ul> <li>\u865a\u62df\u73af\u5883\u914d\u7f6e</li> <li>\u53ef\u89c6\u5316\u5de5\u5177TensorBoard</li> </ul>"},{"location":"appendix/env_config/env/","title":"\u73af\u5883\u914d\u7f6e","text":""},{"location":"appendix/env_config/env/#anacondaminiconda","title":"\u5b89\u88c5 Anaconda/Miniconda","text":""},{"location":"appendix/env_config/env/#miniconda","title":"\u4e0b\u8f7d Miniconda","text":"<p>\u5404\u5927\u64cd\u4f5c\u7cfb\u7edf\u6700\u65b0\u7248\u672c\u7684 Minconda \u90fd\u53ef\u4ee5\u5728\u4e0b\u65b9\u7f51\u5740\u8fdb\u884c\u4e0b\u8f7d\uff1a</p> <p>Miniconda \u2014 Anaconda documentation</p> <p>\u6ce8\u610f\uff1a\u9009\u62e9\u4e0b\u8f7d\u7684 Miniconda3 \u7248\u672c\u9700\u8981\u548c\u7535\u8111\u5904\u7406\u5668\u7684\u67b6\u6784\u543b\u5408\u3002\u4e3a\u4e86\u65b9\u4fbf\uff0c\u5728\u6b64\u4e0b\u65b9\u76f4\u63a5\u63d0\u4f9b\u5404\u5927\u64cd\u4f5c\u7cfb\u7edf\u63a8\u8350\u7684\u4e0b\u8f7d\u94fe\u63a5\u3002</p> \u7cfb\u7edf \u4e0b\u8f7d\u5730\u5740 Windows https://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe\u00a0\u29c9 macOS\uff08Intel\uff09 https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh\u00a0\u29c9 macOS\uff08M/ARM\uff09 https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh\u00a0\u29c9 Linux\uff08x64\uff09 https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\u00a0\u29c9 Linux\uff08ARM\uff09 https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh\u00a0\u29c9"},{"location":"appendix/env_config/env/#miniconda_1","title":"\u5b89\u88c5 Miniconda","text":"<p>\u4e0b\u9762\u6211\u4eec\u5206\u522b\u4ecb\u7ecd\u5728 Windows \u7cfb\u7edf\u548c Linux \u7cfb\u7edf\u4e0b\u7684\u5b89\u88c5\u6d41\u7a0b\u3002</p>"},{"location":"appendix/env_config/env/#windows-miniconda","title":"Windows \u7cfb\u7edf\u5b89\u88c5 Miniconda","text":"<ul> <li>\u8fd0\u884c\u4e0b\u8f7d\u597d\u7684\u5b89\u88c5\u5305</li> </ul> <ul> <li>\u4e00\u8defnext\u548cagree\uff0c\u76f4\u5230\u9009\u62e9\u8def\u5f84\uff0c\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u504f\u597d\u9009\u62e9\u8def\u5f84\uff0c\u8fd9\u91cc\u9009\u62e9\u9ed8\u8ba4\u3002</li> </ul> <ul> <li>\u4fdd\u6301\u9ed8\u8ba4\u914d\u7f6e\u5373\u53ef\uff0c\u4e0b\u4e00\u6b65\u3002</li> </ul> <ul> <li>\u5b8c\u6210\uff0c\u4ee5\u540e\u4f7f\u7528<code>conda</code> \u4ece\u5f00\u59cb\u83dc\u5355\u70b9\u5f00\u5373\u53ef\u3002</li> </ul>"},{"location":"appendix/env_config/env/#linux-miniconda","title":"Linux \u7cfb\u7edf\u5b89\u88c5 Miniconda","text":"<p>\u4e0b\u8f7d\u597d\u7684\u5b89\u88c5\u6587\u4ef6\u653e\u5728 Downloads \u6587\u4ef6\u4e2d</p> <p></p> <p>\u5728<code>Miniconda3</code>\u6240\u5728\u6587\u4ef6\u5939\u4e0b\u6253\u5f00\u7ec8\u7aef</p> <ul> <li>\u4e3a\u6587\u4ef6\u6dfb\u52a0\u6267\u884c\u6743\u9650\uff08\u6587\u4ef6\u540d\u79f0\u8981\u548c\u81ea\u5df1\u4e0b\u8f7d\u7684\u7248\u672c\u4e00\u81f4\uff09\u547d\u4ee4\u662f\uff1a<code>chmod a+x ./Miniconda3-latest-Linux-x86_64.sh</code></li> </ul> <p></p> <ul> <li>\u8fd0\u884c\u5b89\u88c5\u7a0b\u5e8f\u547d\u4ee4\uff0c\u547d\u4ee4\u662f<code>sh ./Miniconda3-latest-Linux-x86_64.sh</code> \uff0c\u7136\u540e\u6839\u636e\u63d0\u793a\u56de\u8f66\u3002</li> </ul> <p></p> <ul> <li>\u8fd9\u91cc\u4f1a\u8ba9\u9605\u8bfb\u76f8\u5173\u534f\u8bae\uff0c\u76f4\u63a5\u6309<code>q</code> \u7ed3\u675f\u9605\u8bfb\uff0c\u8f93\u5165<code>yes</code>\uff0c\u7136\u540e\u56de\u8f66\u3002</li> </ul> <p></p> <p></p> Bash<pre><code>- Press ENTER to confirm the location\n- Press CTRL-C to abort the installation\n- Or specify a different location below\n</code></pre> <ul> <li>\u5728\u8fd9\u91cc\u7a0b\u5e8f\u63d0\u793a\u4ee5\u4e0b\u4fe1\u606f\uff0c\u8fd9\u91cc\u6709\u4e09\u79cd\u9009\u62e9\uff0c\u5206\u522b\u662f:<ol> <li>\u56de\u8f66\u4f7f\u7528\u9ed8\u8ba4\u8def\u5f84<code>\\home\\user\\miniconda3</code></li> <li>\u4f7f\u7528<code>ctrl c</code> \u7ec8\u6b62\u7a0b\u5e8f</li> <li>\u7528\u6237\u81ea\u5b9a\u4e49\u8def\u5f84</li> </ol> </li> </ul> <p>\u7528\u6237\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u9700\u8981\u9009\u62e9\u5b89\u88c5\u76ee\u5f55\u3002</p> <p></p> <ul> <li>\u7a0b\u5e8f\u7ecf\u8fc7\u5b89\u88c5\u540e\u4f1a\u8be2\u95ee\u662f\u5426\u6bcf\u6b21\u542f\u52a8\u7ec8\u7aef\u662f\u5426\u81ea\u52a8\u542f\u52a8<code>conda</code>\u3002\u8f93\u5165<code>yes</code>\u7136\u540e\u56de\u8f66\u3002</li> </ul> <p></p> <ul> <li>\u6839\u636e\u63d0\u793a\u91cd\u542f\u7ec8\u7aef\uff0c\u518d\u6b21\u6253\u5f00\u5c31\u4f1a\u51fa\u73b0<code>(base)</code> \u3002\u4ee5\u540e\u5c31\u5728\u7ec8\u7aef\u64cd\u4f5c<code>conda</code>\u3002</li> </ul> <p></p>"},{"location":"appendix/env_config/env/#_1","title":"\u6362\u6e90","text":"<p>\u5728\u5b89\u88c5package\u65f6\uff0c\u6211\u4eec\u7ecf\u5e38\u4f1a\u4f7f\u7528<code>pip install package_name</code>\u548c<code>conda install package_name</code>\u7684\u547d\u4ee4\uff0c\u4f46\u662f\u4e00\u4e9bpackage\u4e0b\u8f7d\u901f\u5ea6\u4f1a\u5f88\u6162\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u8fdb\u884c\u6362\u6e90\uff0c\u6362\u6210\u56fd\u5185\u6e90\uff0c\u52a0\u5feb\u6211\u4eec\u7684\u4e0b\u8f7d\u901f\u5ea6\u3002\u4ee5\u4e0b\u4fbf\u662f\u4e24\u79cd\u5bf9\u5e94\u65b9\u5f0f\u7684\u6362\u6e90\u3002</p> <p>\u5982\u679c\u6211\u4eec\u4ec5\u4ec5\u60f3\u4e3a\u5355\u6b21\u4e0b\u8f7d\u6362\u6e90\u53ef\u4ee5\u4f7f\u7528<code>pip install package_name -i https://pypi.tuna.tsinghua.edu.cn/simple</code>\u8fdb\u884c\u4e0b\u8f7d\u3002</p>"},{"location":"appendix/env_config/env/#windows","title":"Windows \u7cfb\u7edf\u6362\u6e90","text":""},{"location":"appendix/env_config/env/#pip","title":"<code>pip</code>\u6362\u6e90","text":"<ul> <li>\u6587\u4ef6\u7ba1\u7406\u5668\u6587\u4ef6\u8def\u5f84\u5730\u5740\u680f\u6572\uff1a<code>%APPDATA%</code>\u00a0\u56de\u8f66\uff0c\u5feb\u901f\u8fdb\u5165\u00a0<code>C:\\Users\\User\\AppData\\Roaming</code>\u00a0\u6587\u4ef6\u5939\u3002</li> </ul> <ul> <li>\u65b0\u5efa pip \u6587\u4ef6\u5939\u5e76\u5728\u6587\u4ef6\u5939\u4e2d\u65b0\u5efa\u00a0<code>pip.ini</code>\u00a0\u914d\u7f6e\u6587\u4ef6\u3002</li> </ul> <ul> <li>\u4f7f\u7528\u8bb0\u4e8b\u672c\u6253\u5f00\uff0c\u8f93\u5165\u4ee5\u4e0b\u5185\u5bb9\uff0c\u5e76\u6309\u4e0b<code>ctrl+s</code>\u4fdd\u5b58\u3002</li> </ul> pip.ini<pre><code>[global]\nindex-url = https://pypi.tuna.tsinghua.edu.cn/simple\n[install]\nuse-mirrors =true\nmirrors = https://pypi.tuna.tsinghua.edu.cn/simple/\ntrusted-host = pypi.tuna.tsinghua.edu.cn\n</code></pre>"},{"location":"appendix/env_config/env/#conda","title":"<code>conda</code>\u6362\u6e90","text":"<p>\u6211\u4eec\u9700\u8981\u5728<code>.condarc</code>\u6587\u4ef6\u5185\u8fdb\u884c\u6362\u6e90\uff0c\u4f46\u662fWindows \u7528\u6237\u65e0\u6cd5\u76f4\u63a5\u521b\u5efa\u540d\u4e3a\u00a0<code>.condarc</code>\u00a0\u7684\u6587\u4ef6\uff0c\u53ef\u5148\u6267\u884c<code>conda\u00a0config\u00a0--set\u00a0show_channel_urls\u00a0yes</code>\u751f\u6210\u8be5\u6587\u4ef6\u4e4b\u540e\u518d\u4fee\u6539\u3002</p> <ul> <li>\u6267\u884c\u5b8c<code>conda\u00a0config\u00a0--set\u00a0show_channel_urls\u00a0yes</code>\u540e\u4f1a\u5728\u7528\u6237\u6587\u4ef6\u5939\u627e\u5230<code>.condarc</code> \u6587\u4ef6\u3002</li> </ul> <p></p> <ul> <li>\u4fee\u6539\u8fd9\u4e2a\u6587\u4ef6\uff0c\u66ff\u6362\u4e3a\u4ee5\u4e0b\u5185\u5bb9\u3002</li> </ul> .condarc<pre><code>channels:\n  - defaults\nshow_channel_urls: true\ndefault_channels:\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2\ncustom_channels:\n  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\nauto_activate_base: false\n</code></pre>"},{"location":"appendix/env_config/env/#linux","title":"Linux \u7cfb\u7edf\u6362\u6e90","text":"<p>\u524d\u60c5\u63d0\u793a\uff1a\u5728<code>vim</code>\u4e0b\uff0c\u6211\u4eec\u9700\u8981\u8f93\u5165<code>i</code>\u8fdb\u5165\u7f16\u8f91\u6a21\u5f0f\uff0c\u5c06\u5185\u5bb9\u7c98\u8d34\u8fdb\u53bb\uff0c\u6309<code>ESC</code>\u9000\u51fa\u7f16\u8f91\u6a21\u5f0f\uff0c\u8f93\u5165<code>:wq</code>\u4fdd\u5b58\u5e76\u9000\u51fa\u3002</p>"},{"location":"appendix/env_config/env/#pip_1","title":"<code>pip</code>\u6362\u6e90","text":"<p>\u5728\u7ec8\u7aef\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4</p> Bash<pre><code>cd ~\nmkdir .pip/\ncd .pip\nvim pip.conf\n</code></pre> <p>\u5728\u8fd9\u4e2a<code>pip.conf</code>\u6587\u4ef6\u4e0b\u5e94\u8be5\u7c98\u8d34\u4ee5\u4e0b\u5185\u5bb9\uff0c\u76f4\u63a5\u590d\u5236\u7c98\u8d34\u5230\u6587\u4ef6\u5185\u5373\u53ef\uff0c\u7136\u540e\u7ed3\u675f\u7f16\u8f91\u3002</p> pip.conf<pre><code>[global]\nindex-url = https://pypi.tuna.tsinghua.edu.cn/simple\n[install]\nuse-mirrors =true\nmirrors = https://pypi.tuna.tsinghua.edu.cn/simple/\ntrusted-host = pypi.tuna.tsinghua.edu.cn\n</code></pre>"},{"location":"appendix/env_config/env/#conda_1","title":"<code>conda</code>\u6362\u6e90","text":"<p>\u5728\u7ec8\u7aef\u6267\u2f8f\u4ee5\u4e0b\u547d\u4ee4</p> Bash<pre><code>cd ~\nvim .condarc\n</code></pre> <p>\u5728<code>.condarc</code> \u6587\u4ef6\u5185\u5e94\u8be5\u7c98\u8d34\u4ee5\u4e0b\u5185\u5bb9\uff0c\u76f4\u63a5\u590d\u5236\u7c98\u8d34\u5230\u6587\u4ef6\u5185\u5373\u53ef\u3002\u7136\u540e\u7ed3\u675f\u7f16\u8f91</p> .condarc<pre><code>channels:\n  - defaults\nshow_channel_urls: true\ndefault_channels:\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2\ncustom_channels:\n  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\nauto_activate_base: false\n</code></pre> <p>\u6700\u540e\u4f7f\u7528<code>conda\u00a0clean\u00a0-i</code>\u00a0\u6e05\u9664\u7d22\u5f15\u7f13\u5b58\u3002</p>"},{"location":"appendix/env_config/env/#condapip","title":"<code>conda</code>/<code>pip</code>\u7684\u4f7f\u7528","text":"<ul> <li>\u67e5\u770b\u73b0\u6709\u865a\u62df\u73af\u5883\uff1a<code>conda env list</code></li> <li>\u521b\u5efa\u865a\u62df\u73af\u5883\uff1a<code>conda create -n env_name python=version</code></li> <li><code>create</code>\uff1a \u521b\u5efa\u73af\u5883\u547d\u4ee4</li> <li><code>n</code>\uff1a<code>-name</code> \u7f29\u5199\uff0c\u540e\u9762\u7d27\u63a5\u7740\u662f\u865a\u62df\u73af\u5883\u540d\u79f0</li> <li><code>env_name</code>\uff1a\u865a\u62df\u73af\u5883\u540d\u79f0\uff1a\u89c1\u540d\u77e5\u610f\uff0c\u53ef\u4ee5\u6839\u636e\u5b9e\u9645\u9700\u6c42\u66f4\u6539</li> <li><code>version</code> \uff1aPython\u7248\u672c\uff0c\u4f8b\u59823.8\uff0c\u4ee5\u4e0b\u662f\u5177\u4f53\u793a\u4f8b</li> </ul> <ul> <li>\u6fc0\u6d3b\u865a\u62df\u73af\u5883\uff1a<code>conda activate env_name</code> \uff0c\u6fc0\u6d3b\u865a\u62df\u73af\u5883\u540e\uff0c\u7ec8\u7aef\u5c06\u4f1a\u5728\u62ec\u53f7\u5185\u663e\u793a\u5f53\u524d\u73af\u5883\u540d\u79f0\u3002</li> </ul> <ul> <li>\u5b89\u88c5\u5305\uff1a<code>conda install package_name</code>\u6216\u8005<code>pip install package_name</code></li> <li><code>pip</code>\u5728\u5b89\u88c5\u5305\u65f6\u4e34\u65f6\u66f4\u6362\u955c\u50cf\u6e90\uff1a<code>pip install package_name -i https://pypi.tuna.tsinghua.edu.cn/simple</code></li> <li>\u5378\u8f7d\u5305\uff1a<code>conda remove package_name</code>\u6216\u8005<code>pip uninstall package_name</code></li> <li>\u663e\u793a\u6240\u6709\u5b89\u88c5\u7684\u5305\uff1a<code>conda list</code></li> <li>\u5220\u9664\u6307\u5b9a\u865a\u62df\u73af\u5883\uff1a<code>conda remove -n env_name --all</code></li> <li>\u9000\u51fa\u5f53\u524d\u73af\u5883\uff1a<code>conda deactivate</code></li> </ul> <p>\u66f4\u591a\u7684<code>conda</code>\u547d\u4ee4\u53c2\u8003\u5b98\u7f51\u3002</p> <p>Commands \u2014 conda 24.3.1.dev30 documentation</p>"},{"location":"appendix/env_config/env/#_2","title":"\u5b89\u88c5\u51fd\u6570\u5e93","text":"Warning <p>\ud83d\udcaf \u5f53\u4f60\u60f3\u5728\u865a\u62df\u73af\u5883\u5b89\u88c5\u5305\u7684\u65f6\u5019\uff0c\u786e\u8ba4\u4f60\u6b63\u5904\u5728\u6b63\u786e\u7684\u865a\u62df\u73af\u5883\u4e2d\uff01\uff01</p> pip/conda<pre><code>pip install numpy pandas matplotlib transformers datasets peft evaluate diffusers gradio torch jupyterlab\n</code></pre>"},{"location":"appendix/env_config/env/#_3","title":"\u53c2\u8003","text":"<ul> <li> <p>Datawhale \u5f00\u6e90 PyTorch \u6559\u7a0b</p> <p>\u6df1\u5165\u6d45\u51fa <code>PyTorch</code>\u00a0\u29c9</p> </li> <li> <p>Miniconda \u5b98\u65b9\u6587\u6863</p> <p>Miniconda documentation\u00a0\u29c9</p> </li> </ul>"},{"location":"appendix/tensorboard/TensorBoard/","title":"\u53ef\u89c6\u5316\u5de5\u5177TensorBoard","text":""},{"location":"appendix/tensorboard/TensorBoard/#_1","title":"\u5feb\u901f\u5f00\u59cb","text":"Bash<pre><code>tensorboard --logdir=runs\n</code></pre> <p>\u5728\u7ec8\u7aef\u6267\u884c<code>tensorboard</code>\u547d\u4ee4\uff0c\u6307\u5b9a<code>logdir</code>\u53c2\u6570\u4e3a\u5b58\u50a8\u65e5\u5fd7\u6570\u636e\u7684\u76ee\u5f55\u3002</p> Python<pre><code>from torch.utils.tensorboard import SummaryWriter\n\n# default `log_dir` is \"runs\" - we'll be more specific here\nwriter = SummaryWriter('runs/unlock-hf')\n</code></pre> <p>\u521b\u5efaTensorBoard\u65e5\u5fd7\u8bb0\u5f55\u5668\uff0c\u65e5\u5fd7\u6570\u636e\u5c06\u88ab\u5b58\u50a8\u5728 <code>runs/unlock-hf</code> \u76ee\u5f55\u4e0b\u3002</p> <p>\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668</p> <p>\u4e5f\u53ef\u4ee5\u4f7f\u7528<code>with</code>\u8bed\u53e5\u5efa\u7acb\u65e5\u5fd7\u8bb0\u5f55\u5668\u3002</p>"},{"location":"appendix/tensorboard/TensorBoard/#_2","title":"\u53ef\u89c6\u5316\u7f51\u7edc","text":"<p>\u5b9a\u4e49\u795e\u7ecf\u7f51\u7edc\u3002</p> Python<pre><code>class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\n</code></pre> <ul> <li>\u5229\u7528<code>add_graph</code>\u65b9\u6cd5\u5411\u65e5\u5fd7\u8bb0\u5f55\u5668\u4e2d\u6dfb\u52a0\u7f51\u7edc\u6a21\u578b\u7ed3\u6784\u3002</li> </ul> Python<pre><code>with SummaryWriter('runs/unlock-hf') as writer:\n    writer.add_graph(net, torch.rand(1, 1, 28, 28))\n</code></pre> <p></p>"},{"location":"appendix/tensorboard/TensorBoard/#_3","title":"\u53ef\u89c6\u5316\u56fe\u7247","text":"Python<pre><code>imgs = torch.zeros(3, 3, 256, 256)\n\nimgs[0, 0, :, :] = 255\nimgs[1, 1, :, :] = 255\nimgs[2, 2, :, :] = 255\n\nimgs = torchvision.utils.make_grid(imgs)\n\nwith SummaryWriter('runs/unlock-hf') as writer:\n    writer.add_image('example', imgs)\n</code></pre> <ul> <li>\u5229\u7528<code>add_image</code>\u65b9\u6cd5\u5411\u65e5\u5fd7\u8bb0\u5f55\u5668\u4e2d\u6dfb\u52a0\u56fe\u7247\u3002</li> </ul>"},{"location":"appendix/tensorboard/TensorBoard/#_4","title":"\u53ef\u89c6\u5316\u53d8\u91cf","text":"Python<pre><code>with SummaryWriter('runs/unlock-hf') as writer:\n    for i in range(100):\n        x = i\n        y = x**2\n        writer.add_scalar(\"x\", x, i) #\u65e5\u5fd7\u4e2d\u8bb0\u5f55x\u5728\u7b2cstep i \u7684\u503c\n        writer.add_scalar(\"y\", y, i) #\u65e5\u5fd7\u4e2d\u8bb0\u5f55y\u5728\u7b2cstep i \u7684\u503c\n</code></pre> <ul> <li>\u5229\u7528<code>add_scalar</code>\u65b9\u6cd5\u5411\u65e5\u5fd7\u8bb0\u5f55\u5668\u4e2d\u6dfb\u52a0\u53d8\u91cf\u6570\u636e\u3002</li> </ul>"},{"location":"appendix/tensorboard/TensorBoard/#_5","title":"\u53ef\u89c6\u5316\u5411\u91cf\u7a7a\u95f4","text":"Python<pre><code>images = torch.randn(100, 1, 28, 28)\nlabels = torch.randint(0, 10, (100,))\nwith SummaryWriter('runs/unlock-hf') as writer:\n    features = images.view(-1, 28 * 28)\n    class_labels = [f'Class {i}' for i in labels]\n    labels = labels.unsqueeze(1)\n    writer.add_embedding(features, metadata=labels, label_img=images)\n</code></pre> <ul> <li>\u5229\u7528<code>add_embedding</code>\u65b9\u6cd5\u5411\u65e5\u5fd7\u8bb0\u5f55\u5668\u4e2d\u6dfb\u52a0\u5411\u91cf\u6570\u636e\u3002</li> </ul> <p>\u6ce8\u610f</p> <p>\u90e8\u5206\u6d4f\u89c8\u5668\u53ef\u80fd\u65e0\u6cd5\u6b63\u5e38\u663e\u793a\u6b64\u90e8\u5206\u754c\u9762\u3002</p>"},{"location":"appendix/tensorboard/TensorBoard/#_6","title":"\u53c2\u8003\u8d44\u6599","text":"<ul> <li>Visualizing Models, Data, and Training with TensorBoard\u00a0\u29c9</li> <li>TensorBoard Projector \u7b80\u6613\u6307\u5357\u00a0\u29c9</li> </ul>"},{"location":"chapter1/datasets_index/","title":"\u7d22\u5f15","text":"<p>\u4e3b\u9875</p> <ul> <li><code>Arrow</code>\u4ecb\u7ecd</li> <li><code>Datasets</code>\u4ecb\u7ecd</li> <li><code>Features</code>\u4ecb\u7ecd</li> <li>\u81ea\u5b9a\u4e49\u6570\u636e\u96c6</li> </ul>"},{"location":"chapter1/arrow_tour/arrow_tour/","title":"Arrow\u4ecb\u7ecd","text":"<p>\u7ffb\u8bd1\u81eaHuggingFace Arrow\u00a0\u29c9</p>"},{"location":"chapter1/arrow_tour/arrow_tour/#arrow","title":"<code>Arrow</code>\u662f\u4ec0\u4e48\uff1f","text":"<p><code>Arrow</code>\u662f\u4e00\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u53ef\u4ee5\u5feb\u901f\u5904\u7406\u548c\u79fb\u52a8\u5927\u91cf\u6570\u636e\u3002\u5b83\u4f7f\u7528\u5217\u5f0f\u5185\u5b58\u5e03\u5c40\u5b58\u50a8\u6570\u636e\uff0c\u5b83\u7684\u6807\u51c6\u683c\u5f0f\u5177\u6709\u4ee5\u4e0b\u4f18\u70b9\uff1a</p> \u7279\u5f81 \u63cf\u8ff0 \u8bfb\u53d6\u65b9\u5f0f \u652f\u6301\u96f6\u62f7\u8d1d\u8bfb\u53d6\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u51e0\u4e4e\u6240\u6709\u5e8f\u5217\u5316\u5f00\u9500\u3002 \u8de8\u8bed\u8a00\u652f\u6301 \u652f\u6301\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u3002 \u5b58\u50a8\u65b9\u5f0f \u9762\u5411\u5217\u7684\u5b58\u50a8\uff0c\u5728\u67e5\u8be2\u548c\u5904\u7406\u6570\u636e\u5207\u7247\u6216\u5217\u65f6\u901f\u5ea6\u66f4\u5feb\u3002 \u517c\u5bb9\u6027 \u6570\u636e\u53ef\u4ee5\u65e0\u7f1d\u4f20\u9012\u7ed9\u4e3b\u6d41\u673a\u5668\u5b66\u4e60\u5de5\u5177\uff0c\u5982<code>NumPy</code>\u3001<code>Pandas</code>\u3001<code>PyTorch</code>\u548c<code>TensorFlow</code>\u3002 \u5217\u7c7b\u578b \u652f\u6301\u591a\u79cd\u5217\u7c7b\u578b\uff0c\u751a\u81f3\u652f\u6301\u5d4c\u5957\u5217\u7c7b\u578b\u3002"},{"location":"chapter1/arrow_tour/arrow_tour/#_1","title":"\u5185\u5b58\u6620\u5c04","text":"<p><code>Datasets</code>\u4f7f\u7528<code>Arrow</code>\u4f5c\u4e3a\u5176\u672c\u5730\u7f13\u5b58\u7cfb\u7edf\u3002\u5b83\u5141\u8bb8\u6570\u636e\u96c6\u7531\u78c1\u76d8\u7f13\u5b58\u4f5c\u4e3a\u540e\u76fe\uff0c\u8be5\u7f13\u5b58\u88ab\u5185\u5b58\u6620\u5c04\u4ee5\u5b9e\u73b0\u5feb\u901f\u67e5\u627e\u3002</p> <p>\u8fd9\u79cd\u67b6\u6784\u5141\u8bb8\u5728\u8bbe\u5907\u5185\u5b58\u8f83\u5c0f\u7684\u673a\u5668\u4e0a\u4f7f\u7528\u5927\u578b\u6570\u636e\u96c6\u3002</p> <p>\u4f8b\u5982\uff0c\u52a0\u8f7d\u5b8c\u6574\u7684\u82f1\u6587\u7ef4\u57fa\u767e\u79d1\u6570\u636e\u96c6\u53ea\u9700\u8981\u51e0\u5146\u5b57\u8282\u7684\u5185\u5b58\uff1a</p> Python<pre><code>import os\nimport psutil\nimport timeit\nfrom datasets import load_dataset\n\nmem_before = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\nwiki = load_dataset(\"wikipedia\", \"20220301.en\", split=\"train\")\nmem_after = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n\nprint(f\"RAM memory used: {(mem_after - mem_before)} MB\")\n</code></pre> <p>\u4e4b\u6240\u4ee5\u80fd\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u662f\u56e0\u4e3a<code>Arrow</code>\u6570\u636e\u5b9e\u9645\u4e0a\u662f\u4ece\u78c1\u76d8\u5185\u5b58\u6620\u5c04\u7684\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u52a0\u8f7d\u5230\u5185\u5b58\u4e2d\u7684\u3002\u5185\u5b58\u6620\u5c04\u5141\u8bb8\u8bbf\u95ee\u78c1\u76d8\u4e0a\u7684\u6570\u636e\uff0c\u5e76\u5229\u7528\u865a\u62df\u5185\u5b58\u529f\u80fd\u8fdb\u884c\u5feb\u901f\u67e5\u627e\u3002</p>"},{"location":"chapter1/arrow_tour/arrow_tour/#_2","title":"\u6027\u80fd","text":"<p>\u4f7f\u7528Arrow\u5728\u5185\u5b58\u6620\u5c04\u6570\u636e\u96c6\u4e2d\u8fdb\u884c\u8fed\u5408\u662f\u5feb\u901f\u7684\u3002\u5728\u7b14\u8bb0\u672c\u7535\u8111\u4e0a\u904d\u7528\u7ef4\u57fa\u767e\u79d1\uff0c\u901f\u5ea6\u4e3a1-3 Gbit/s\u3002</p> Python<pre><code>s = \"\"\"batch_size = 1000\nfor batch in wiki.iter(batch_size):\n    ...\n\"\"\"\n\nelapsed_time = timeit.timeit(stmt=s, number=1, globals=globals())\nprint(\n    f\"Time to iterate over the {wiki.dataset_size &gt;&gt; 30} GB dataset: {elapsed_time:.1f} sec, \"\n    f\"ie. {float(wiki.dataset_size &gt;&gt; 27)/elapsed_time:.1f} Gb/s\"\n)\n</code></pre> Python<pre><code>Time to iterate over the 18 GB dataset: 31.8 sec, ie. 4.8 Gb/s\n</code></pre>"},{"location":"chapter1/custom_dataset/custom_dataset/","title":"\u81ea\u5b9a\u4e49\u6570\u636e\u96c6","text":""},{"location":"chapter1/custom_dataset/custom_dataset/#_1","title":"\u524d\u8a00","text":""},{"location":"chapter1/dataset_tour/datasets/","title":"Datasets\u4ecb\u7ecd","text":""},{"location":"chapter1/dataset_tour/datasets/#_1","title":"\u524d\u8a00","text":"<p>\u65e0\u8bba\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u8fd8\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\uff0c\u60f3\u8981\u8bad\u7ec3\u4e00\u4e2a\u667a\u80fd\u7cfb\u7edf\u5fc5\u7136\u662f\u4ece\u6570\u636e\u52a0\u8f7d\u5f00\u59cb\uff0c\u7136\u540e\u9488\u5bf9\u6570\u636e\u8fdb\u884c\u5343\u53d8\u4e07\u5316\u4ee5\u7b26\u5408\u6a21\u578b\u7684\u8f93\u5165\u8981\u6c42\u3002</p> <p>\u5728\u8fc7\u53bb\uff0c\u5f00\u53d1\u8005\u9762\u5bf9\u4e0d\u540c\u4efb\u52a1\u65f6\u4f1a\u9047\u5230\u4e0d\u5c3d\u76f8\u540c\u7684\u6570\u636e\u683c\u5f0f\uff0c\u751a\u81f3\u540c\u4e00\u4e2a\u4efb\u52a1\u4e5f\u4f1a\u9047\u5230\u4e0d\u540c\u7684\u6570\u636e\u683c\u5f0f\u3002\u4e0b\u9762\u4e3e\u51fa\u4e86\u4e00\u4e9b\u5e38\u89c1\u7684\u95ee\u9898\uff1a</p> \u95ee\u9898 \u8bf4\u660e \u6587\u672c\u683c\u5f0f\u4e0d\u4e00\u81f4 \u67d0\u4e9b\u6570\u636e\u96c6\u4f7f\u7528 <code>json</code> \u683c\u5f0f\u5b58\u50a8\uff0c\u6709\u4e9b\u4f7f\u7528 <code>csv</code> \u6216 <code>txt</code> \u683c\u5f0f\uff0c\u800c\u4e14\u5b57\u6bb5\u547d\u540d\u548c\u6570\u636e\u7ed3\u6784\u4e5f\u53ef\u80fd\u4e0d\u540c\u3002 \u6807\u7b7e\u8868\u793a\u65b9\u6cd5\u591a\u6837 \u5728\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u67d0\u4e9b\u6570\u636e\u96c6\u4f7f\u7528\u6570\u5b57\u6807\u7b7e\uff0c\u67d0\u4e9b\u5219\u4f7f\u7528\u6587\u672c\u6807\u7b7e\u3002 \\(\\cdots\\) <p>\u4e3a\u4e86\u5c3d\u5feb\u5b8c\u6210\u4efb\u52a1\uff0c\u5f00\u53d1\u8005\u9700\u8981\u7f16\u5199\u4e0d\u540c\u7684\u5904\u7406\u51fd\u6570\uff0c\u4ee5\u6ee1\u8db3\u6a21\u578b\u7684\u8f93\u5165\u8981\u6c42\uff0c\u8fd9\u4e9b\u95ee\u9898\u5bfc\u81f4\u5f00\u53d1\u8005\u9700\u8981\u4e3a\u6bcf\u4e2a\u9879\u76ee\u751a\u81f3\u6bcf\u4e2a\u6570\u636e\u96c6\u7f16\u5199\u5927\u91cf\u91cd\u590d\u7684\u4ee3\u7801\uff0c\u6781\u5927\u5730\u964d\u4f4e\u4e86\u5f00\u53d1\u6548\u7387\u3002</p> <p>\u4f46\u73b0\u5728\uff0c <code>Datasets</code> \u7684\u51fa\u73b0\u6709\u6548\u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u5b83\u63d0\u4f9b\u4e86\u4e00\u5957\u6070\u5230\u597d\u5904\u3001\u5f3a\u6709\u529b\u3001\u6807\u51c6\u5316\u7684\u6570\u636e\u683c\u5f0f\u548c\u5904\u7406\u6d41\u7a0b\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u6446\u8131\u7e41\u7410\u7684\u6570\u636e\u9884\u5904\u7406\u5de5\u4f5c\uff0c\u4e13\u6ce8\u4e8e\u6a21\u578b\u5f00\u53d1\u3002\u4e0e\u4f20\u7edf\u6570\u636e\u96c6\u5de5\u5177\u76f8\u6bd4\uff0c<code>Datasets</code>\u00a0\u7684\u4f18\u52bf\u4e3b\u8981\u4f53\u73b0\u5728\u4ee5\u4e0b\u51e0\u4e2a\u65b9\u9762\uff1a</p> \u4f18\u52bf \u8bf4\u660e \u7b80\u5316\u6570\u636e\u52a0\u8f7d \u65e0\u9700\u624b\u52a8\u4e0b\u8f7d\u3001\u89e3\u538b\u3001\u89e3\u6790\u6570\u636e\u6587\u4ef6\uff0c<code>Datasets</code> \u63d0\u4f9b\u4e00\u952e\u52a0\u8f7d\u529f\u80fd\uff0c\u6781\u5927\u7b80\u5316\u6570\u636e\u83b7\u53d6\u6d41\u7a0b\u3002 \u5185\u7f6e\u5904\u7406\u51fd\u6570 \u5f3a\u5927\u7684\u5185\u7f6e\u51fd\u6570 (\u4f8b\u5982 <code>map</code>, <code>filter</code>, <code>sort</code>, <code>shuffle</code> \u7b49) \u7528\u4e8e\u6570\u636e\u6e05\u6d17\u3001\u8f6c\u6362\u3001\u589e\u5f3a\u7b49\u64cd\u4f5c\u3002 \u9ad8\u6548\u5904\u7406\u5927\u578b\u6570\u636e\u96c6 \u4f7f\u7528 <code>Apache Arrow</code> \u683c\u5f0f\u5b58\u50a8\u6570\u636e\uff0c\u652f\u6301\u5e76\u884c\u5904\u7406\uff0c\u53ef\u4ee5\u9ad8\u6548\u5904\u7406\u6d77\u91cf\u6570\u636e\u3002 \u652f\u6301\u591a\u79cd\u6570\u636e\u683c\u5f0f <code>Datasets</code> \u5e7f\u6cdb\u652f\u6301\u6570\u636e\u683c\u5f0f\uff0c\u65b9\u4fbf\u7528\u6237\u4f7f\u7528\u6765\u81ea\u4e0d\u540c\u6765\u6e90\u7684\u6570\u636e\u96c6\u3002 \u81ea\u5b9a\u4e49\u51fd\u6570 \u7528\u6237\u53ef\u4ee5\u4f7f\u7528 <code>map</code> \u51fd\u6570\u5e94\u7528\u81ea\u5b9a\u4e49\u51fd\u6570\u5bf9\u6570\u636e\u96c6\u8fdb\u884c\u7075\u6d3b\u5904\u7406\uff0c\u6ee1\u8db3\u4e2a\u6027\u5316\u9700\u6c42\u3002 \u4ee3\u7801\u6613\u4e8e\u5171\u4eab\u548c\u590d\u7528 \u6807\u51c6\u5316\u7684\u6570\u636e\u683c\u5f0f\u548c\u5904\u7406\u6d41\u7a0b\u4f7f\u5f97\u4ee3\u7801\u66f4\u6613\u4e8e\u5171\u4eab\u548c\u590d\u7528\uff0c\u63d0\u9ad8\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\u3002 \u4e0e <code>transformers</code> \u751f\u6001\u65e0\u7f1d\u96c6\u6210 \u53ef\u4ee5\u8f7b\u677e\u5730\u5c06\u5904\u7406\u540e\u7684\u6570\u636e\u96c6\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30 <code>transformers</code> \u6a21\u578b\u3002"},{"location":"chapter1/dataset_tour/datasets/#datasets","title":"\u5b89\u88c5 <code>Datasets</code>","text":"pip<pre><code>pip install datasets\n</code></pre>"},{"location":"chapter1/dataset_tour/datasets/#_2","title":"\u52a0\u8f7d\u6570\u636e\u96c6","text":"<p>\u5728\u4e0b\u6587\uff0c\u4ece\u4ee5\u4e0b\u4e24\u4e2a\u89d2\u5ea6\u6f14\u793a <code>Datasets</code> \u5e93\u63d0\u4f9b\u7684\u4e00\u952e\u52a0\u8f7d\u6570\u636e\u96c6\u7684\u529f\u80fd\u3002</p> <ol> <li>\u4ece Hub \u52a0\u8f7d\u6570\u636e\u96c6</li> <li>\u4ece\u672c\u5730\u52a0\u8f7d\u6570\u636e\u96c6</li> </ol>"},{"location":"chapter1/dataset_tour/datasets/#hub","title":"\u4ece Hub \u52a0\u8f7d\u6570\u636e\u96c6","text":"<p>\u6240\u6709\u88ab\u6258\u7ba1\u7684\u6570\u636e\u96c6\u90fd\u53ef\u4ee5\u5728\u6570\u636e\u96c6\u4e3b\u9875\u00a0\u29c9\u67e5\u770b\uff0c\u5229\u7528\u5de6\u4fa7\u7684\u9009\u9879\u53ef\u4ee5\u66f4\u5feb\u5730\u7b5b\u9009\u51fa\u7b26\u5408\u9700\u6c42\u7684\u6570\u636e\u96c6\u3002</p> <p></p> <p>\u7ecf\u8fc7\u9009\u62e9\u540e\uff0c\u53ef\u4ee5\u6253\u5f00\u6570\u636e\u96c6\u4ecb\u7ecd\u9875\u67e5\u770b\u8be6\u7ec6\u4fe1\u606f\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u6570\u636e\u96c6\u90fd\u4f1a\u6709\u5176\u72ec\u7279\u7684\u4ed3\u5e93\u8def\u5f84\uff0c\u5f85\u4f1a\u52a0\u8f7d\u6570\u636e\u96c6\u65f6\uff0c\u51fd\u6570\u4f1a\u6839\u636e\u4ed3\u5e93\u8def\u5f84\u81ea\u52a8\u4ece Hub \u4e0b\u8f7d\u5e76\u52a0\u8f7d\u6570\u636e\u96c6\uff0c\u4f8b\u5982\u4e0b\u56fe\u7684\u4ed3\u5e93\u8def\u5f84\u4e3a <code>LooksJuicy/ruozhiba</code>\uff0c\u518d\u6bd4\u5982\u53e6\u4e00\u4e2a\u4ed3\u5e93\u8def\u5f84\u4e3a <code>hfl/cmrc2018</code>\u3002</p> <p></p> <p></p> <p>\u5f53\u5f00\u53d1\u8005\u9009\u5b9a\u4e86\u6570\u636e\u96c6\u540e\uff0c\u4fbf\u53ef\u4ee5\u4f7f\u7528 <code>load_dataset</code> \u51fd\u6570\u6839\u636e\u4ed3\u5e93 <code>ID</code> \u52a0\u8f7d\u6570\u636e\u96c6\u3002</p> hfl/cmrc2018<pre><code>from datasets import load_dataset\n\ndata = load_dataset(\"hfl/cmrc2018\")\n</code></pre> data<pre><code>{\n    'test': Dataset(\n        {\n            'features': ['id', 'context', 'question', 'answers'],\n            'num_rows': 1002\n        }\n    ),\n    'train': Dataset(\n        {\n            'features': ['id', 'context', 'question', 'answers'],\n            'num_rows': 10142\n        }\n    ),\n    'validation': Dataset(\n        {\n            'features': ['id', 'context', 'question', 'answers'],\n            'num_rows': 3219\n        }\n    )\n}\n</code></pre> <p>\u901a\u8fc7\u8fd4\u56de\u7ed3\u679c\u53ef\u4ee5\u770b\u51fa <code>data</code> \u7684\u6570\u636e\u7c7b\u578b\u4e3a <code>DatasetDict</code>\uff0c\u5b83\u662f <code>Datasets</code> \u5e93\u4e2d\u91cd\u8981\u7684\u6570\u636e\u7c7b\u578b\u3002</p> <p>train_test_split</p> <p>\u5e76\u975e\u6240\u6709\u6570\u636e\u96c6\u90fd\u5305\u542b\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002\u6709\u4e9b\u6570\u636e\u96c6\u53ef\u80fd\u53ea\u6709\u4e00\u4e2a\u6216\u4e24\u4e2a\u5b50\u96c6\u3002 \u5bf9\u4e8e\u6570\u636e\u96c6 <code>hfl/cmrc2018</code> \u5b58\u5728\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002\u4f46\u662f\u5bf9\u4e8e <code>LooksJuicy/ruozhiba</code> \u5374\u53ea\u5b58\u5728\u8bad\u7ec3\u96c6\u3002</p> <p>\u5728\u5b9e\u9645\u7684\u5f00\u53d1\u4e2d\uff0c\u53ef\u4ee5\u4f7f\u7528 <code>train_test_split</code> \u51fd\u6570\u5c06\u8bad\u7ec3\u96c6\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002</p> <p></p> <p> </p> <p><code>DatasetDict</code> \u5c31\u50cf\u4e00\u4e2a <code>Python</code> \u5b57\u5178\uff0c\u5b83\u5305\u542b\u591a\u4e2a\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u6570\u636e\u96c6\u90fd\u6709\u4e00\u4e2a\u540d\u5b57\u4f5c\u4e3a\u952e\u548c\u5bf9\u5e94\u7684\u6570\u636e\u96c6\u5bf9\u8c61\u4f5c\u4e3a\u503c\u3002</p> <p>\u5f00\u53d1\u8005\u53ef\u4ee5\u50cf\u8bbf\u95ee\u666e\u901a\u5b57\u5178\u4e00\u6837\u8bbf\u95ee <code>DatasetDict</code> \u4e2d\u7684\u6570\u636e\u96c6\u3002</p> Python<pre><code>train_dataset = data['train']  # \u83b7\u53d6\u8bad\u7ec3\u96c6\n\nprint(len(dataset_dict['validation']))  # \u83b7\u53d6\u9a8c\u8bc1\u96c6\u5927\u5c0f\n</code></pre> train_dataset<pre><code>Dataset({\n    features: ['id', 'context', 'question', 'answers'],\n    num_rows: 10142\n})\n</code></pre> len(dataset_dict[\"validation\"])<pre><code>3219\n</code></pre> <p>\u5728\u4f7f\u7528 <code>load_dataset</code> \u7684\u65f6\u5019\u8fd8\u6709\u4e00\u4e2a\u53c2\u6570\u503c\u5f97\u88ab\u5173\u6ce8\uff0c\u90a3\u5c31\u662f <code>split</code>\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u6570\u636e\u96c6\uff0c<code>split</code> \u53ef\u4ee5\u662f\u952e\u6216\u8005\u952e\u7ec4\u6210\u7684\u5217\u8868\u4ee5\u8868\u793a\u52a0\u8f7d\u54ea\u90e8\u5206\u6570\u636e\u3002</p> <ul> <li>\u5982\u679c\u4f7f\u7528 <code>data = load_datase(\"hfl/cmrc2018\")</code> \u65f6\u4e0d\u6307\u5b9a <code>split</code>\uff0c\u90a3\u4e48 <code>data</code> \u4f1a\u50cf\u4e0b\u9762\u4e00\u6837\u3002</li> </ul> Python<pre><code>{\n    'test': Dataset(\n        {\n            'features': ['id', 'context', 'question', 'answers'],\n            'num_rows': 1002\n        }\n    ),\n    'train': Dataset(\n        {\n            'features': ['id', 'context', 'question', 'answers'],\n            'num_rows': 10142\n        }\n    ),\n    'validation': Dataset(\n        {\n            'features': ['id', 'context', 'question', 'answers'],\n            'num_rows': 3219\n        }\n    )\n}\n</code></pre> <ul> <li>\u5982\u679c\u4f7f\u7528 <code>data = load_datase(\"hfl/cmrc2018\", split='train')</code> \uff0c\u90a3\u4e48 <code>data</code> \u4f1a\u50cf\u4e0b\u9762\u4e00\u6837\u3002</li> </ul> split='train'<pre><code>Dataset({\n    features: ['id', 'context', 'question', 'answers'],\n    num_rows: 10142\n})\n</code></pre> <ul> <li>\u5982\u679c\u4f7f\u7528 <code>data = load_datase(\"hfl/cmrc2018\", split=[\"train\", \"test\"])</code> \uff0c\u90a3\u4e48 <code>data</code> \u4f1a\u50cf\u4e0b\u9762\u4e00\u6837\u3002</li> </ul> split=[\"train\", \"test\"]<pre><code>[\n    Dataset({\n        features: ['id', 'context', 'question', 'answers'],\n        num_rows: 10142\n    }),\n    Dataset({\n        features: ['id', 'context', 'question', 'answers'],\n        num_rows: 1002\n    })\n]\n</code></pre> <p>\u914d\u7f6e</p>"},{"location":"chapter1/dataset_tour/datasets/#configurations","title":"\u914d\u7f6e (Configurations)","text":"<ul> <li>\u4e00\u4e9b\u6570\u636e\u96c6\u5305\u542b\u591a\u4e2a\u5b50\u6570\u636e\u96c6\uff0c\u5b50\u6570\u636e\u96c6\u53c8\u53ef\u80fd\u5305\u542b\u8bad\u7ec3\u96c6\u3001\u6d4b\u8bd5\u96c6\u548c\u9a8c\u8bc1\u96c6\u3002\u4f8b\u5982<code>Minds-14</code>\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u5b50\u6570\u636e\u96c6\u5305\u542b\u4e0d\u540c\u8bed\u8a00\u7684\u97f3\u9891\u6570\u636e\u3002\u8fd9\u4e9b\u5b50\u6570\u636e\u96c6\u88ab\u79f0\u4e3a\u914d\u7f6e (configurations)\u3002</li> <li>\u5728\u52a0\u8f7d\u6709\u4e0d\u540c\u914d\u7f6e\u7684\u6570\u636e\u96c6\u65f6\uff0c\u9700\u8981\u660e\u786e\u9009\u62e9\u4e00\u4e2a\u914d\u7f6e\u3002\u53ef\u4ee5\u4f7f\u7528 <code>get_dataset_config_names()</code> \u51fd\u6570\u68c0\u7d22\u6570\u636e\u96c6\u7684\u6240\u6709\u53ef\u7528\u914d\u7f6e\u5217\u8868\u3002\u4f8b\u5982\uff0c<code>get_dataset_config_names(\"PolyAI/minds14\")</code> \u8fd4\u56de<code>Minds-14</code>\u6570\u636e\u96c6\u7684\u6240\u6709\u53ef\u7528\u8bed\u8a00\u914d\u7f6e\u5217\u8868\u3002</li> <li>\u52a0\u8f7d\u6570\u636e\u96c6\u65f6\uff0c\u6307\u5b9a\u8981\u52a0\u8f7d\u7684\u914d\u7f6e\uff0c\u4f8b\u5982<code>load_dataset(\"PolyAI/minds14\", \"fr-FR\", split=\"train\")</code>\u52a0\u8f7d\u6cd5\u8bed\u8bad\u7ec3\u96c6\u3002</li> </ul>"},{"location":"chapter1/dataset_tour/datasets/#dataset","title":"Dataset \u65b9\u6cd5\u4ecb\u7ecd","text":""},{"location":"chapter1/dataset_tour/datasets/#add_column","title":"<code>add_column</code> \u65b9\u6cd5","text":"<p>\u8be5\u65b9\u6cd5\u5411\u6570\u636e\u96c6\u4e2d\u589e\u52a0\u4e00\u5217\u6570\u636e\u3002\u4ee5\u4e0b\u662f\u8be5\u65b9\u6cd5\u7684\u53c2\u6570\u8868\u683c\u3002</p> \u53c2\u6570 \u6570\u636e\u7c7b\u578b \u9ed8\u8ba4\u503c \u8bf4\u660e <code>name</code> <code>str</code> \u5217\u540d <code>column</code> <code>list</code> or <code>numpy.array</code> \u6240\u8981\u6dfb\u52a0\u7684\u6570\u636e <code>new_fingerprint</code> <code>feature</code> <code>FeatureType</code> or <code>None</code> <code>None</code> \u5217\u6570\u636e\u7c7b\u578b Python<pre><code>from datasets import load_dataset\n\nds = load_dataset(\"rotten_tomatoes\", split=\"validation\")\n</code></pre> <p>\u4e0b\u9762\u662f\u4f7f\u7528 <code>ds.to_pandas()</code> \u65b9\u6cd5\u83b7\u53d6\u7684\u6570\u636e\u3002</p> text label compassionately explores the seemingly irreconcilable contradictions of love and faith 1 the soundtrack alone is worth the price of admission 1 rodriguez does a splendid job of racial profiling in a balanced and complex way 1 beneath the film's obvious determination to shock lies genuine intelligence and insight 1 bielinsky is a filmmaker of impressive talent 1 \\(\\cdots\\) \\(\\cdots\\) <p>\u73b0\u5728\u8c03\u7528 <code>add_column</code> \u65b9\u6cd5\u5411\u539f\u6709\u6570\u636e\u589e\u52a0\u4e00\u5217\u6570\u636e\uff0c\u5728\u8fd9\u91cc\u5c06\u5217\u540d\u4e3a <code>text</code> \u5217\u7684\u6570\u636e\u6dfb\u52a0\u6570\u636e\u96c6\u4e2d\uff0c\u5e76\u547d\u540d\u4e3a <code>new_column</code>\u3002</p> Python<pre><code>new_column = ds[\"text\"]\n\nds.add_column(name=\"new_column\", column=new_column)\n</code></pre> <p>\u4e0b\u9762\u662f\u53d8\u5316\u540e\u7684\u6570\u636e\u3002</p> text label new_column compassionately explores the seemingly irreconcilable contradictions of love and faith 1 compassionately explores the seemingly irreconcilable contradictions of love and faith the soundtrack alone is worth the price of admission 1 the soundtrack alone is worth the price of admission rodriguez does a splendid job of racial profiling in a balanced and complex way 1 rodriguez does a splendid job of racial profiling in a balanced and complex way beneath the film's obvious determination to shock lies genuine intelligence and insight 1 beneath the film's obvious determination to shock lies genuine intelligence and insight bielinsky is a filmmaker of impressive talent 1 bielinsky is a filmmaker of impressive talent \\(\\cdots\\) \\(\\cdots\\) \\(\\cdots\\) <p>\u6ce8\u610f</p> <p>\u786e\u4fdd\u6dfb\u52a0\u7684\u6570\u636e\u548c\u539f\u6570\u636e\u7684\u6570\u76ee\u4e00\u81f4\uff0c\u5426\u5219\u4f1a\u51fa\u73b0\u9519\u8bef\uff1a <code>ValueError: Failed to concatenate on axis=1 because tables don't have the same number of rows</code></p>"},{"location":"chapter1/features_tour/features_tour/","title":"Features\u4ecb\u7ecd","text":""},{"location":"chapter1/features_tour/features_tour/#_1","title":"\u524d\u8a00","text":"<p><code>Features</code>\u7c7b\u662f\u4e00\u79cd\u7528\u6765\u5b9a\u4e49\u6570\u636e\u96c6\u7ed3\u6784\u7684\u7279\u6b8a\u5b57\u5178\uff0c\u8be5\u5b57\u5178\u671f\u671b\u7684\u683c\u5f0f\u4e3a<code>dict[str, FieldType]</code>\uff0c\u5176\u4e2d\u952e\u5bf9\u5e94\u5217\u540d\uff0c\u503c\u5bf9\u5e94\u76f8\u5e94\u7684\u6570\u636e\u7c7b\u578b\u3002</p> <p>\u6709\u5173\u53d7\u652f\u6301\u7684<code>FieldType</code>\u7c7b\u578b\u53ef\u4ee5\u67e5\u9605HuggingFace\u5173\u4e8e<code>FieldType</code>\u7684\u6587\u6863\u00a0\u29c9\uff0c\u4ee5\u4e0b\u662f\u53d7\u652f\u6301\u7684\u6570\u636e\u7c7b\u578b\u53ca\u5176\u63cf\u8ff0\u3002</p> <code>FieldType</code> \u63cf\u8ff0 <code>Value</code> \u6307\u5b9a\u5355\u4e00\u6570\u636e\u7c7b\u578b\uff0c\u4f8b\u5982<code>int64</code>\u6216<code>string</code>\u3002 <code>ClassLabel</code> \u6307\u5b9a\u4e00\u7ec4\u9884\u5b9a\u4e49\u7684\u7c7b\u522b\uff0c\u8fd9\u4e9b\u7c7b\u522b\u53ef\u4ee5\u5177\u6709\u4e0e\u4e4b\u5173\u8054\u7684\u6807\u7b7e\uff0c\u5e76\u4e14\u5c06\u4f5c\u4e3a\u6574\u6570\u5b58\u50a8\u5728\u6570\u636e\u96c6\u4e2d\u3002\u6bd4\u5982<code>['bad', 'ok', 'good']</code> <code>dict</code> \u6307\u5b9a\u4e00\u4e2a\u590d\u5408\u7279\u5f81\uff0c\u5176\u4e2d\u5305\u542b\u5b50\u5b57\u6bb5\u5230\u5b50\u7279\u5f81\u7684\u6620\u5c04\u3002\u5b50\u5b57\u6bb5\u53ef\u4ee5\u4efb\u610f\u65b9\u5f0f\u5d4c\u5957\u3002 <code>list</code>, <code>LargeList</code>, <code>Sequence</code> \u6307\u5b9a\u4e00\u4e2a\u590d\u5408\u7279\u5f81\uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a\u5b50\u7279\u5f81\u5e8f\u5217\uff0c\u6240\u6709\u5b50\u7279\u5f81\u7684\u7c7b\u578b\u76f8\u540c\u3002 <code>Array2D</code>, <code>Array3D</code>, <code>Array4D</code>, <code>Array5D</code> \u7528\u4e8e\u5b58\u50a8\u591a\u7ef4\u6570\u7ec4\u3002 <code>Audio</code> \u7528\u4e8e\u5b58\u50a8\u6307\u5411\u97f3\u9891\u6587\u4ef6\u7684\u7edd\u5bf9\u8def\u5f84\u6216\u4e00\u4e2a\u5b57\u5178\uff0c\u5176\u4e2d\u5305\u542b\u6307\u5411\u97f3\u9891\u6587\u4ef6\u7684\u76f8\u5bf9\u8def\u5f84\u548c\u5b57\u8282\u5185\u5bb9\u3002 <code>Image</code> \u7528\u4e8e\u5b58\u50a8\u6307\u5411\u56fe\u50cf\u6587\u4ef6\u7684\u7edd\u5bf9\u8def\u5f84\u3001\u4e00\u4e2a<code>NumPy</code>\u6570\u7ec4\u5bf9\u8c61\u3001\u4e00\u4e2a<code>PIL</code>\u5bf9\u8c61\u6216\u4e00\u4e2a<code>dict</code>\uff0c\u5176\u4e2d\u5305\u542b\u6307\u5411\u56fe\u50cf\u6587\u4ef6\u7684\u76f8\u5bf9\u8def\u5f84\u548c\u5b57\u8282\u5185\u5bb9\u3002 <code>Translation</code>, <code>TranslationVariableLanguages</code> \u7279\u5b9a\u4e8e\u673a\u5668\u7ffb\u8bd1\u3002"},{"location":"chapter1/features_tour/features_tour/#features","title":"<code>Features</code>\u5c5e\u6027\u4ecb\u7ecd","text":""},{"location":"chapter1/features_tour/features_tour/#_2","title":"\u7b80\u5355\u6570\u636e\u96c6\u5b9a\u4e49","text":"Python<pre><code>from datasets import Features, Value, ClassLabel\nfeatures = Features(\n    {\n        \"text\": Value(dtype=\"string\"),\n        \"label\": ClassLabel(num_classes=3, names=[\"negative\", \"positive\"]),\n    }\n)\n</code></pre> <p>\u8be5\u4f8b\u5b50\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5305\u542b\u4e24\u4e2a\u7279\u5f81\u7684\u7b80\u5355\u6570\u636e\u96c6\u7ed3\u6784\u3002</p> <ul> <li><code>text</code>\uff1a\u5b57\u7b26\u4e32\u7c7b\u578b\uff0c\u7528\u4e8e\u5b58\u50a8\u6587\u672c\u6570\u636e\u3002</li> <li><code>label</code>\uff1a\u7c7b\u522b\u6807\u7b7e\u7c7b\u578b\uff0c\u7528\u4e8e\u5b58\u50a8\u60c5\u611f\u7c7b\u522b\u6807\u7b7e\uff0c\u53d6\u503c\u4e3a<code>negative</code>\u6216<code>positive</code>\u3002</li> </ul> features<pre><code>{\n    \"text\": Value(dtype=\"string\", id=None),\n    \"label\": ClassLabel(names=[\"negative\", \"positive\"], id=None),\n}\n</code></pre>"},{"location":"chapter1/features_tour/features_tour/#_3","title":"\u590d\u5408\u6570\u636e\u96c6\u5b9a\u4e49","text":"Python<pre><code>from datasets import Features, Value, ClassLabel, Sequence\n\nfeatures = Features(\n    {\n        \"text\": Value(dtype=\"string\"),\n        \"entities\": Sequence(\n            {\n                \"start\": Value(dtype=\"int64\"),\n                \"end\": Value(dtype=\"int64\"),\n                \"label\": ClassLabel(num_classes=3, names=[\"PERSON\", \"ORG\", \"LOC\"]),\n            }\n        ),\n    }\n)\n</code></pre> <p>\u8be5\u4f8b\u5b50\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5305\u542b<code>entities</code>\u590d\u5408\u7279\u5f81\u7684\u6570\u636e\u96c6\u7ed3\u6784\u3002</p> <ul> <li><code>text</code>: \u5b57\u7b26\u4e32\u7c7b\u578b\uff0c\u7528\u4e8e\u5b58\u50a8\u6587\u672c\u6570\u636e\u3002</li> <li><code>entities</code>: \u5e8f\u5217\u7c7b\u578b\uff0c\u7528\u4e8e\u5b58\u50a8\u6587\u672c\u4e2d\u7684\u5b9e\u4f53\u4fe1\u606f\u3002\u6bcf\u4e2a\u5b9e\u4f53\u5305\u542b\u4e09\u4e2a\u7279\u5f81\u3002<ul> <li><code>start</code>: \u6574\u6570\u7c7b\u578b\uff0c\u8868\u793a\u5b9e\u4f53\u5728\u6587\u672c\u4e2d\u7684\u8d77\u59cb\u4f4d\u7f6e\u3002</li> <li><code>end</code>: \u6574\u6570\u7c7b\u578b\uff0c\u8868\u793a\u5b9e\u4f53\u5728\u6587\u672c\u4e2d\u7684\u7ed3\u675f\u4f4d\u7f6e\u3002</li> <li><code>label</code>: \u7c7b\u522b\u6807\u7b7e\u7c7b\u578b\uff0c\u8868\u793a\u5b9e\u4f53\u7684\u7c7b\u522b\uff0c\u53ef\u4ee5\u662f<code>PERSON</code>, <code>ORG</code>\u6216<code>LOC</code>\u3002</li> </ul> </li> </ul> features<pre><code>{\n    \"text\": Value(dtype=\"string\", id=None),\n    \"entities\": Sequence(\n        feature={\n            \"start\": Value(dtype=\"int64\", id=None),\n            \"end\": Value(dtype=\"int64\", id=None),\n            \"label\": ClassLabel(names=[\"PERSON\", \"ORG\", \"LOC\"], id=None),\n        },\n        length=-1,\n        id=None,\n    ),\n}\n</code></pre>"},{"location":"chapter1/features_tour/features_tour/#_4","title":"\u591a\u7ef4\u6570\u7ec4","text":"Python<pre><code>from datasets import Features, Array2D, Value\n\nfeatures = Features(\n    {\n        \"image\": Array2D(shape=(224, 224, 3), dtype=\"float32\"),\n        \"label\": Value(\"int64\"),\n    }\n)\n</code></pre> <p>\u8be5\u4f8b\u5b50\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5305\u542b<code>image</code>\u7279\u5f81\u7684\u6570\u636e\u96c6\u7ed3\u6784\u3002</p> <ul> <li><code>image</code>: \u591a\u7ef4\u6570\u7ec4\u7c7b\u578b\uff0c\u7528\u4e8e\u5b58\u50a8\u56fe\u50cf\u6570\u636e\uff0c\u5f62\u72b6\u4e3a<code>(224, 224, 3)</code>\uff0c\u6570\u636e\u7c7b\u578b\u4e3a<code>float32</code>\u3002</li> <li><code>label</code>: \u6574\u6570\u7c7b\u578b\uff0c\u7528\u4e8e\u5b58\u50a8\u56fe\u50cf\u7684\u7c7b\u522b\u6807\u7b7e\u3002</li> </ul> features<pre><code>{\n    \"image\": Array2D(shape=(224, 224, 3), dtype=\"float32\", id=None),\n    \"label\": Value(dtype=\"int64\", id=None),\n}\n</code></pre>"},{"location":"chapter1/features_tour/features_tour/#_5","title":"\u97f3\u9891\u6570\u636e","text":"Python<pre><code>from datasets import Features, Audio, ClassLabel\n\nfeatures = Features(\n    {\n        \"audio\": Audio(sampling_rate=44100),\n        \"label\": ClassLabel(num_classes=2, names=[\"negative\", \"positive\"]),\n    }\n)\n</code></pre> <p>\u8be5\u4f8b\u5b50\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5305\u542b<code>audio</code>\u548c<code>label</code>\u7279\u5f81\u7684\u6570\u636e\u96c6\u7ed3\u6784\u3002</p> <ul> <li><code>audio</code>: \u97f3\u9891\u7c7b\u578b\uff0c\u7528\u4e8e\u5b58\u50a8\u97f3\u9891\u6570\u636e\uff0c\u91c7\u6837\u7387\u4e3a<code>44100 Hz</code>\u3002</li> <li><code>label</code>: \u6574\u6570\u7c7b\u578b\uff0c\u7528\u4e8e\u5b58\u50a8\u97f3\u9891\u60c5\u611f\u7c7b\u522b\u6807\u7b7e\u3002</li> </ul> features<pre><code>{\n    \"audio\": Audio(sampling_rate=44100, mono=True, decode=True, id=None),\n    \"label\": ClassLabel(names=[\"negative\", \"positive\"], id=None),\n}\n</code></pre>"},{"location":"chapter1/features_tour/features_tour/#_6","title":"\u673a\u5668\u7ffb\u8bd1","text":"Python<pre><code>from datasets import Features, Translation, Value\n\nfeatures = Features(\n    {\n        \"source_text\": Value(dtype=\"string\"),\n        \"target_text\": Translation(languages=[\"en\", \"fr\"]),\n    }\n)\n</code></pre> <p>\u8be5\u4f8b\u5b50\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5305\u542b<code>source_text</code>\u548c<code>target_text</code>\u7279\u5f81\u7684\u6570\u636e\u96c6\u7ed3\u6784\u3002</p> <ul> <li><code>source_text</code>: \u5b57\u7b26\u4e32\u7c7b\u578b\uff0c\u7528\u4e8e\u5b58\u50a8\u6e90\u8bed\u8a00\u6587\u672c\u6570\u636e\u3002</li> <li><code>target_text</code>: \u7ffb\u8bd1\u7c7b\u578b\uff0c\u7528\u4e8e\u5b58\u50a8\u76ee\u6807\u8bed\u8a00\u6587\u672c\u6570\u636e\uff0c\u652f\u6301\u82f1\u8bed\u548c\u6cd5\u8bed\u4e24\u79cd\u8bed\u8a00\u3002</li> </ul> features<pre><code>{\n    \"source_text\": Value(dtype=\"string\", id=None),\n    \"target_text\": Translation(languages=[\"en\", \"fr\"], id=None),\n}\n</code></pre>"},{"location":"chapter1/features_tour/features_tour/#_7","title":"\u5176\u4ed6","text":"<p>\u6709\u5173\u53d7\u652f\u6301\u7684<code>Value</code>\u6570\u636e\u7c7b\u578b\u7684\u5b8c\u6574\u5217\u8868\uff0c\u53ef\u4ee5\u67e5\u9605HuggingFace\u5173\u4e8e<code>Value</code>\u7684\u6587\u6863\u00a0\u29c9\uff0c\u4ee5\u4e0b\u662f\u6574\u7406\u51fa\u6765\u7684\u5e38\u7528\u7684\u6570\u636e\u7c7b\u578b\u53ca\u5176\u63cf\u8ff0\u3002</p> \u6570\u636e\u7c7b\u578b \u63cf\u8ff0 \u6570\u636e\u7c7b\u578b \u63cf\u8ff0 <code>null</code> \u8868\u793a\u503c\u4e0d\u5b58\u5728 <code>float32</code> 32\u4f4d\u6d6e\u70b9\u6570 <code>bool</code> \u5e03\u5c14\u503c <code>float64</code> 64\u4f4d\u6d6e\u70b9\u6570 <code>int32</code> 32\u4f4d\u6709\u7b26\u53f7\u6574\u6570 <code>date64</code> \u65e5\u671f\uff0c\u5305\u542b\u65f6\u95f4\u4fe1\u606f <code>int64</code> 64\u4f4d\u6709\u7b26\u53f7\u6574\u6570 <code>string</code> \u6587\u672c\u6570\u636e \\(\\cdots\\) \\(\\cdots\\) \\(\\cdots\\) \\(\\cdots\\) <p>\u4e0b\u9762\u662f\u6570\u636e\u96c6<code>mrpc</code>\u7684\u6570\u636e\u96c6\u4e3b\u9875\uff0c\u53ef\u4ee5\u770b\u5230\u7f51\u9875\u6839\u636e<code>Features</code>\u5728\u6570\u636e\u96c6\u5361\u7247\u4e0a\u6b63\u786e\u663e\u793a\u4e86\u5217\u540d\u53ca\u5176\u6570\u636e\u7c7b\u578b\u3002</p> <p> </p>"},{"location":"chapter1/features_tour/features_tour/#features_1","title":"<code>Features</code>\u65b9\u6cd5\u4ecb\u7ecd","text":"<p>\u6709\u5173\u53d7\u652f\u6301\u7684<code>Features</code>\u65b9\u6cd5\u7684\u5b8c\u6574\u5217\u8868\uff0c\u53ef\u4ee5\u67e5\u9605HuggingFace\u5173\u4e8e<code>Features</code>\u65b9\u6cd5\u7684\u6587\u6863\u00a0\u29c9\uff0c\u4ee5\u4e0b\u662f\u6574\u7406\u51fa\u6765\u7684\u5e38\u7528\u65b9\u6cd5\u53ca\u5176\u63cf\u8ff0\u3002</p> \u65b9\u6cd5 \u8bf4\u660e <code>from_dict</code> \u4ece\u5b57\u5178\u6784\u5efa<code>Features</code>\u3002 <code>to_dict</code> \u8fd4\u56de\u7279\u5f81\u7684\u5b57\u5178\u8868\u793a\u3002 <code>copy</code> <code>Features</code>\u5bf9\u8c61\u7684\u6df1\u590d\u5236\u3002 <code>reorder_fields_as</code> \u91cd\u65b0\u6392\u5e8f\u5b57\u6bb5\u4ee5\u5339\u914d\u53e6\u4e00\u4e2a<code>Features</code>\u5bf9\u8c61\u7684\u987a\u5e8f\u3002 <code>flatten</code> \u901a\u8fc7\u5220\u9664\u5d4c\u5957\u5b57\u5178\u5e76\u521b\u5efa\u5177\u6709\u8fde\u63a5\u540d\u79f0\u7684\u65b0\u5217\u6765\u6241\u5e73\u5316\u7279\u5f81\u3002 \\(\\cdots\\) \\(\\cdots\\)"},{"location":"chapter1/features_tour/features_tour/#from_dict","title":"<code>from_dict</code>\u65b9\u6cd5","text":"Python<pre><code>from datasets import Features\n\nFeatures.from_dict({\"text\": { \"_type\": \"Value\", \"dtype\": \"string\", \"id\": None}})\n</code></pre> <p>\u8be5\u65b9\u6cd5\u4f7f\u7528\u4ece<code>from_dict</code>\u65b9\u6cd5\u4ece\u5b57\u5178\u521b\u5efa<code>Features</code>\u5bf9\u8c61\u3002</p> Features.from_dict({\"text\": {\"_type\": \"Value\", \"dtype\": \"string\", \"id\": None,}})<pre><code>{\"text\": Value(dtype=\"string\", id=None)}\n</code></pre>"},{"location":"chapter1/features_tour/features_tour/#to_dict","title":"<code>to_dict</code>\u65b9\u6cd5","text":"Python<pre><code>from datasets import Features, Value\n\nfeatures = Features(\n    {\n        \"text\": Value(dtype=\"string\"),\n        \"label\": Value(dtype=\"int64\"),\n    }\n)\n</code></pre> <p>\u8be5\u4f8b\u5b50\u9996\u5148\u521b\u5efa\u4e86<code>features</code>\uff0c\u7136\u540e\u5229\u7528<code>to_dict</code>\u65b9\u6cd5\u8fd4\u56de\u4e86\u5b57\u5178\u683c\u5f0f\u7684<code>features</code>\u3002</p> features.to_dict()<pre><code>{\n    \"text\": {\"dtype\": \"string\", \"_type\": \"Value\"},\n    \"label\": {\"dtype\": \"int64\", \"_type\": \"Value\"},\n}\n</code></pre>"},{"location":"chapter1/features_tour/features_tour/#reorder_fields_as","title":"<code>reorder_fields_as</code>\u65b9\u6cd5","text":"Python<pre><code>from datasets import Features, Value, ClassLabel\n\nfeatures = Features(\n    {\n        \"text\": Value(\"string\"),\n        \"label\": ClassLabel(names=[\"positive\", \"negative\"]),\n    }\n)\n\nother_features = Features(\n    {\n        \"label\": ClassLabel(names=[\"positive\", \"negative\"]),\n        \"text\": Value(\"string\"),\n    }\n)\nreordered_features = features.reorder_fields_as(other_features)\n</code></pre> <p>\u8be5\u4f8b\u5b50\u521b\u5efa\u5b57\u6bb5\u987a\u5e8f\u4e0d\u540c\u7684\u4e24\u4e2a<code>Features</code>\u5bf9\u8c61\uff0c\u7136\u540e\u5229\u7528<code>reorder_fields_as</code>\u91cd\u65b0\u6392\u5e8f<code>features</code>\u5b57\u6bb5\u4ee5\u5339\u914d<code>other_features</code>\u5b57\u6bb5\u7684\u987a\u5e8f\u3002</p> reordered_features<pre><code>{\n    \"label\": ClassLabel(names=[\"positive\", \"negative\"], id=None),\n    \"text\": Value(dtype=\"string\", id=None),\n}\n</code></pre>"},{"location":"chapter1/features_tour/features_tour/#flatten","title":"<code>flatten</code>\u65b9\u6cd5","text":"Python<pre><code>from datasets import Features, Value\n\nnested_features = Features(\n    {\n        \"a\": Value(\"string\"),\n        \"b\": {\n            \"c\": Value(\"int32\"),\n            \"d\": Value(\"float32\"),\n        },\n    }\n)\n\nflattened_features = nested_features.flatten()\n</code></pre> nested_features<pre><code>{\n    \"a\": Value(dtype=\"string\", id=None),\n    \"b\": {\"c\": Value(dtype=\"int32\", id=None), \"d\": Value(dtype=\"float32\", id=None)},\n}\n</code></pre> <p>\u8be5\u4f8b\u5b50\u5229\u7528<code>flatten</code>\u65b9\u6cd5\u5220\u9664\u5d4c\u5957\u5b57\u5178\u5e76\u521b\u5efa\u5177\u6709\u8fde\u63a5\u540d\u79f0\u7684\u65b0\u5217\u6765\u6241\u5e73\u5316\u7279\u5f81\u3002</p> flattened_features<pre><code>{\n    \"a\": Value(dtype=\"string\", id=None),\n    \"b.c\": Value(dtype=\"int32\", id=None),\n    \"b.d\": Value(dtype=\"float32\", id=None),\n}\n</code></pre>"},{"location":"chapter1/features_tour/features_tour/#_8","title":"\u53c2\u8003\u8d44\u6599","text":"<ol> <li>HuggingFace\u5173\u4e8e<code>FieldType</code>/<code>Features</code>\u7684\u6587\u6863\u00a0\u29c9</li> <li>HuggingFace\u5173\u4e8e<code>Value</code>\u7684\u6587\u6863\u00a0\u29c9</li> </ol>"},{"location":"chapter2/transformers_index/","title":"\u7d22\u5f15","text":"<p>\u4e3b\u9875</p> <ul> <li>\u7ba1\u9053\u5de5\u5177:<ul> <li>\u7ba1\u9053\u5de5\u5177\u4ecb\u7ecd</li> </ul> </li> <li>\u7f16\u7801\u5de5\u5177<ul> <li>\u5206\u8bcd\u5668\u4ecb\u7ecd</li> <li>\u5206\u8bcd\u65b9\u6cd5\u4ecb\u7ecd</li> <li>\u5feb\u901f\u5206\u8bcd\u5668\u4ecb\u7ecd</li> <li>\u622a\u65ad\u4e0e\u586b\u5145</li> </ul> </li> <li>\u6a21\u578b\u5de5\u5177<ul> <li>\u81ea\u52a8\u6a21\u578b\u5de5\u5177\u4ecb\u7ecd</li> </ul> </li> <li>Trainer\u5de5\u5177<ul> <li>Trainer\u5de5\u5177\u4ecb\u7ecd</li> <li>Trainer\u8bad\u7ec3\u81ea\u5b9a\u4e49\u7684\u6a21\u578b</li> <li>Callbacks\u56de\u8c03\u51fd\u6570</li> <li>Trainer\u5de5\u5177\u5b9e\u6218</li> </ul> </li> </ul>"},{"location":"chapter2/model/auto_model/auto_model/","title":"\u81ea\u52a8\u6a21\u578b","text":""},{"location":"chapter2/model/auto_model/auto_model/#_1","title":"\u524d\u8a00","text":"<p>\u65e0\u8bba\u662f CV \u9886\u57df\u8fd8\u662f NLP \u9886\u57df\uff0c\u6a21\u578b\u8fed\u4ee3\u6b63\u4ee5\u60ca\u4eba\u7684\u901f\u5ea6\u8fdb\u884c\u7740\u3002\u4ece CNN\u3001RNN \u5230 Transformer\uff0c\u65b0\u7684\u6a21\u578b\u67b6\u6784\u5c42\u51fa\u4e0d\u7a77\uff0c \u9762\u5bf9\u5feb\u901f\u8fed\u4ee3\u7684\u6a21\u578b\u548c\u5206\u6563\u7684\u4ee3\u7801\u5e93\uff0c\u5f00\u53d1\u8005\u9700\u8981\u82b1\u8d39\u5927\u91cf\u65f6\u95f4\u548c\u7cbe\u529b\u5728\u6a21\u578b\u9009\u62e9\u548c\u4ee3\u7801\u8c03\u8bd5\u4e0a\uff0c\u800c\u4e0d\u662f\u4e13\u6ce8\u4e8e\u4efb\u52a1\u672c\u8eab\u3002\u6240\u4ee5\u4e00\u4e2a\u7edf\u4e00\u7684\u5e73\u53f0\u6216\u5de5\u5177\u5c06\u8fd9\u4e9b\u4ee3\u7801\u90fd\u96c6\u4e2d\u5728\u4e00\u8d77\uff0c\u4f7f\u7528\u76f8\u540c\u7684\u6807\u51c6\u662f\u518d\u597d\u4e0d\u8fc7\u4e86\uff0c\u6240\u4ee5\u672c\u6587\u7684\u4e3b\u89d2 <code>AutoModel</code> \u5e94\u8fd0\u800c\u751f\u3002</p> <code>AutoModel</code> \u7279\u6027 \u63cf\u8ff0 \u6a21\u578b\u6574\u5408 \u6574\u5408\u6765\u81ea\u4e0d\u540c\u9886\u57df\u548c\u4e0d\u540c\u6765\u6e90\u7684\u6a21\u578b\u3002\u63d0\u4f9b\u7edf\u4e00\u7684\u5e73\u53f0\uff0c\u65b9\u4fbf\u5f00\u53d1\u8005\u8c03\u7528\u5404\u79cd\u6a21\u578b\u3002 \u7b80\u5316\u6a21\u578b\u4f7f\u7528 \u63d0\u4f9b\u7b80\u6d01\u6613\u7528\u7684 <code>API</code>\uff0c\u9690\u85cf\u6a21\u578b\u7684\u590d\u6742\u6027\u3002\u5f00\u53d1\u8005\u53ea\u9700\u51e0\u884c\u4ee3\u7801\u5373\u53ef\u5b8c\u6210\u6a21\u578b\u7684\u52a0\u8f7d\u3001\u8bad\u7ec3\u548c\u63a8\u7406\uff0c\u65e0\u9700\u5173\u6ce8\u5e95\u5c42\u5b9e\u73b0\u7ec6\u8282\u3002 \u81ea\u52a8\u5316\u6a21\u578b\u9009\u62e9 \u6839\u636e\u4efb\u52a1\u7c7b\u578b\u548c\u6570\u636e\u7279\u70b9\uff0c\u81ea\u52a8\u63a8\u8350\u5408\u9002\u7684\u6a21\u578b\u3002\u66f4\u8fdb\u4e00\u6b65\uff0c\u81ea\u52a8\u641c\u7d22\u6700\u4f18\u6a21\u578b\u548c\u8d85\u53c2\u6570\uff0c\u65e0\u9700\u5f00\u53d1\u8005\u624b\u52a8\u5c1d\u8bd5\u3002 \u4ee3\u7801\u590d\u7528\u548c\u53ef\u6269\u5c55\u6027 \u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u65b9\u4fbf\u5f00\u53d1\u8005\u590d\u7528\u4ee3\u7801\u3002\u652f\u6301\u6dfb\u52a0\u65b0\u7684\u6a21\u578b\u3001\u81ea\u5b9a\u4e49\u8bad\u7ec3\u6d41\u7a0b\u7b49\uff0c\u63d0\u9ad8\u5de5\u5177\u7684\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"},{"location":"chapter2/model/auto_model/auto_model/#automodel","title":"<code>AutoModel</code>","text":"<p><code>Transformers</code> \u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u7edf\u4e00\u7684\u65b9\u5f0f\u6765\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u3002\u5f00\u53d1\u8005\u53ef\u4ee5\u4f7f\u7528\u00a0<code>AutoModel</code>\u00a0\u7c7b\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5c31\u50cf\u4f7f\u7528\u00a0<code>AutoTokenizer</code>\u00a0\u52a0\u8f7d\u5206\u8bcd\u5668\u4e00\u6837\u3002\u5173\u952e\u533a\u522b\u5728\u4e8e\uff0c\u5bf9\u4e8e\u4e0d\u540c\u7684\u4efb\u52a1\uff0c\u9700\u8981\u52a0\u8f7d\u4e0d\u540c\u7c7b\u578b\u7684\u00a0<code>AutoModel</code>\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e\u6587\u672c\u5206\u7c7b\u4efb\u52a1\uff0c\u5e94\u8be5\u52a0\u8f7d\u00a0<code>AutoModelForSequenceClassification</code>\u3002\u4ee5\u4e0b\u662f\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u5b9e\u9645\u4f7f\u7528\u4e2d\u9762\u5411\u4e0d\u540c\u4efb\u52a1\u5e38\u7528\u7684 <code>AutoModel</code> \u7c7b\u522b\u4ecb\u7ecd\u3002</p> \u7c7b\u522b \u529f\u80fd \u4efb\u52a1\u793a\u4f8b AutoModelForCausalLM \u56e0\u679c\u8bed\u8a00\u5efa\u6a21\uff0c\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd \u6587\u672c\u751f\u6210\uff0c\u5bf9\u8bdd\u7cfb\u7edf AutoModelForMaskedLM \u63a9\u7801\u8bed\u8a00\u5efa\u6a21\uff0c\u9884\u6d4b\u88ab\u63a9\u76d6\u7684\u8bcd \u5b8c\u5f62\u586b\u7a7a\uff0c\u8bcd\u4e49\u6d88\u6b67 AutoModelForMaskGeneration \u63a9\u7801\u751f\u6210\uff0c\u4f8b\u5982\u7528\u4e8e BART \u548c T 5 \u6587\u672c\u6458\u8981\uff0c\u673a\u5668\u7ffb\u8bd1 AutoModelForSeq2SeqLM \u5e8f\u5217\u5230\u5e8f\u5217\u8bed\u8a00\u5efa\u6a21 \u673a\u5668\u7ffb\u8bd1\uff0c\u6587\u672c\u6458\u8981 AutoModelForSequenceClassification \u5e8f\u5217\u5206\u7c7b \u60c5\u611f\u5206\u6790\uff0c\u4e3b\u9898\u5206\u7c7b AutoModelForMultipleChoice \u591a\u9879\u9009\u62e9 \u9605\u8bfb\u7406\u89e3 AutoModelForNextSentencePrediction \u4e0b\u4e00\u53e5\u9884\u6d4b \u53e5\u5b50\u76f8\u4f3c\u5ea6 AutoModelForTokenClassification \u8bcd\u7ea7\u522b\u5206\u7c7b \u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff0c\u8bcd\u6027\u6807\u6ce8 AutoModelForQuestionAnswering \u95ee\u7b54 \u62bd\u53d6\u5f0f\u95ee\u7b54 AutoModelForTextEncoding \u6587\u672c\u7f16\u7801\uff0c\u751f\u6210\u6587\u672c\u8868\u793a \u6587\u672c\u76f8\u4f3c\u5ea6\uff0c\u8bed\u4e49\u641c\u7d22 <p>Note</p> <p>\u5728 HuggingFace \u6587\u6863\u4e2d AutoModel Class API\u00a0\u29c9 \u53ef\u4ee5\u67e5\u9605\u6240\u6709\u652f\u6301\u7684 <code>AutoModel</code> \u7c7b\u522b\u3002\u4e0d\u4ec5\u5305\u542b\u9762\u5411\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\uff0c\u8fd8\u5305\u542b\u9762\u5411\u8bed\u97f3\uff0c\u8ba1\u7b97\u673a\u89c6\u89c9\u7b49\u65b9\u5411\u7684 <code>AutoModel</code> \u4f9b\u5f00\u53d1\u8005\u4f7f\u7528\u30fe(\u2267\u25bd\u2266*) o\u3002</p>"},{"location":"chapter2/model/auto_model/auto_model/#automodel_1","title":"\u4f7f\u7528 <code>AutoModel</code>","text":""},{"location":"chapter2/model/auto_model/auto_model/#automodel_2","title":"\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684 <code>AutoModel</code>","text":"<p>\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u6709\u5f88\u591a\u4efb\u52a1\uff0c\u8fd9\u91cc\u9009\u62e9\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b <code>uer/gpt2-chinese-poem</code> \u6765\u4f53\u9a8c\u53e4\u8bd7\u8bcd\u751f\u6210\u4efb\u52a1\uff0c\u4f7f\u7528 <code>from_pretrained</code> \u65b9\u6cd5\u5e76\u6307\u5b9a\u6a21\u578b\u540d\u79f0\u6216\u672c\u5730\u8def\u5f84\u5373\u53ef\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u3002</p> <p>\u65b9\u5f0f\u4e00\uff1a\u4f7f\u7528\u00a0<code>pipeline</code>\u00a0\u7b80\u5316\u6d41\u7a0b</p> Python<pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name_or_path = \"uer/gpt2-chinese-poem\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\nmodel = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n\n\ntext_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\nresult = text_generator(\"[CLS]\u6885 \u5c71 \u5982 \u79ef \u7fe0 \uff0c\", max_length=50, do_sample=True)\n</code></pre> result[0][\"generated_text\"]<pre><code>'[CLS]\u6885 \u5c71 \u5982 \u79ef \u7fe0 \uff0c \u5386 \u4e71 \u5165 \u4e91 \u9f50 \u3002 \u6b32 \u8bc6 \u505c \u8f66 \u5904 \uff0c \u70df \u971e \u9501 \u4e00 \u6eaa \u3002 \u6da7 \u9053 \u4f55 \u7ea1 \u56de \uff0c \u5c71 \u8272 \u5ffd \u5982 \u8d6d \u3002 \u5e7d \u4eba \u9690 \u91cd \u6797 \uff0c \u677e \u841d \u81ea \u5173 \u9501 \u3002 \u72ec'\n</code></pre> <p>\u65b9\u5f0f\u4e8c\uff1a\u7cbe\u7ec6\u5730\u63a7\u5236\u6587\u672c\u751f\u6210\u8fc7\u7a0b</p> \u65b9\u5f0f\u4e8c<pre><code>import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"uer/gpt2-chinese-poem\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\n# \u8bbe\u7f6e\u53c2\u6570\nmax_length = 50\ndo_sample = True\n\n# \u8f93\u5165\u6587\u672c\ntext = \"\u660e\u6708\u51e0\u65f6\u6709\"\n\n# \u5c06\u6587\u672c\u8f6c\u6362\u4e3atoken ID\ninput_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n\n# \u5faa\u73af\u751f\u6210\u6587\u672c\nfor _ in range(max_length):\n    # \u83b7\u53d6\u6a21\u578b\u8f93\u51fa\n    outputs = model(input_ids=input_ids)\n\n    # \u83b7\u53d6\u6700\u540e\u4e00\u4e2atoken\u7684\u9884\u6d4b\u6982\u7387\u5206\u5e03\n    next_token_logits = outputs.logits[:, -1, :]\n\n    # \u5982\u679c do_sample \u4e3a True\uff0c\u5219\u8fdb\u884c\u91c7\u6837\n    if do_sample:\n        next_token_id = torch.multinomial(torch.softmax(next_token_logits, dim=-1), num_samples=1)\n    else:\n        # \u5426\u5219\u9009\u62e9\u6982\u7387\u6700\u9ad8\u7684token\n        next_token_id = torch.argmax(next_token_logits, dim=-1).unsqueeze(1)\n\n    # \u5c06\u65b0\u751f\u6210\u7684token ID\u6dfb\u52a0\u5230\u8f93\u5165\u5e8f\u5217\u4e2d\n    input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n\n# \u5c06\u751f\u6210\u7684token ID\u89e3\u7801\u6210\u6587\u672c\ngenerated_text = tokenizer.decode(input_ids[0])\n</code></pre> generated_text<pre><code>[CLS] \u660e \u6708 \u51e0 \u65f6 \u6709 [SEP] \u7f18 \uff0c \u4e0d \u9732 \u5c18 \u4e2d \u4ea6 \u81ea \u5706 \u3002 \u501f \u95ee \u949f \u58f0 \u4f55 \u5904 \u8d77 \uff0c \u78a7 \u4e91 \u76f8 \u5bf9 \u5367 \u50e7 \u7985 \u3002 [SEP] \u8a00 \u7acb \u5fd7 \u4e0b \u671d \u9633 \uff0c \u957f \u5b66 \u5176 \u4eba \u5cfb \u6cd5 \u573a \u3002 \u5fe0 \u613f \u5f97 \u6765 \u76f8 \u5bcc \u8d35 \uff0c\n</code></pre> <p>Note</p> <p>\u503c\u5f97\u6ce8\u610f\u7684\u662f\u5728\u4e0a\u9762\u7684 <code>AutoModel</code> \u7c7b\u522b\u8868\u4e2d\uff0c\u4e0d\u540c\u7684\u4efb\u52a1\u6a21\u578b\u53ef\u80fd\u9700\u8981\u4f20\u5165\u4e0d\u540c\u7684\u53c2\u6570\uff0c\u6bd4\u5982 <code>AutoModelForSequenceClassification</code> \u5728\u4f7f\u7528 <code>from_pretrained</code> \u52a0\u8f7d\u6a21\u578b\u7684\u65f6\u5019\u9700\u8981\u8bbe\u7f6e\u53c2\u6570 <code>num_labels</code>\uff0c\u8fd8\u6709\u5f88\u591a\uff0c\u5f53\u7136\u4e0d\u5fc5\u5168\u90e8\u8bb0\u4f4f\uff0c\u5f53\u5f00\u53d1\u8005\u60f3\u4f7f\u7528\u67d0\u4e2a\u4efb\u52a1\u6a21\u578b\u7684\u65f6\u5019\u53ea\u9700\u8981\u5230\u5b98\u65b9\u6587\u6863\u00a0\u29c9\u67e5\u8be2\u53c2\u6570\u5373\u53ef\u3002</p>"},{"location":"chapter2/model/auto_model/auto_model/#ing","title":"\u5185\u5bb9\u8fd8\u5728\u6784\u5efa ing","text":""},{"location":"chapter2/pipelines/pipelines/","title":"Pipelines\u8ba9NLP\u4efb\u52a1\u5316\u7e41\u4e3a\u7b80","text":""},{"location":"chapter2/pipelines/pipelines/#_1","title":"\u524d\u8a00","text":"<p>\u8fd1\u5e74\u6765\uff0c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u7a81\u98de\u731b\u8fdb\uff0c\u5404\u79cd\u6a21\u578b\u67b6\u6784\u5c42\u51fa\u4e0d\u7a77\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u60f3\u8981\u5229\u7528<code>NLP</code>\u6280\u672f\u5374\u5bf9\u590d\u6742\u6a21\u578b\u671b\u800c\u5374\u6b65\u7684\u65b0\u624b\u6765\u8bf4\uff0c\u65e0\u7591\u662f\u4e00\u9053\u95e8\u69db\u3002\u5018\u82e5\u6709\u4e00\u79cd\u5de5\u5177\u80fd\u4e00\u952e\u542f\u52a8\u590d\u6742\u7684\u4efb\u52a1\u5c31\u597d\u4e86\u3002</p> <p>Pipelines</p> <p><code>Pipelines</code>\u5e94\u8fd0\u800c\u751f\uff0c\u5b83\u5c06\u590d\u6742\u7684<code>NLP</code>\u4efb\u52a1\u6d41\u7a0b\u5c01\u88c5\u6210\u7b80\u6d01\u6613\u7528\u7684\u63a5\u53e3\uff0c\u8ba9<code>NLP</code>\u7684\u529b\u91cf\u89e6\u624b\u53ef\u53ca\u3002</p> <p><code>Pipelines</code>\u7684\u5965\u79d8\u5728\u4e8e\u5176\u5c06\u9884\u5904\u7406\u3001\u6a21\u578b\u52a0\u8f7d\u3001\u63a8\u7406\u548c\u540e\u5904\u7406\u7b49\u6b65\u9aa4\u6574\u5408\u5728\u4e00\u8d77\uff0c\u5f62\u6210\u4e00\u4e2a\u5b8c\u6574\u7684\u6d41\u6c34\u7ebf\u3002\u5f00\u53d1\u8005\u53ea\u9700\u5c06\u6570\u636e\u8f93\u5165<code>Pipelines</code>\uff0c\u5373\u53ef\u83b7\u5f97\u5904\u7406\u7ed3\u679c\uff0c\u65e0\u9700\u5173\u5fc3\u5185\u90e8\u7ec6\u8282\uff0c\u5927\u5927\u964d\u4f4e\u4e86<code>NLP</code>\u5de5\u5177\u7684\u4f7f\u7528\u95e8\u69db\u3002</p> <p><code>Pipelines</code>\u7684\u4f18\u52bf\u8fdc\u4e0d\u6b62\u4e8e\u6b64\uff0c\u65e0\u8bba\u4f60\u662f<code>NLP</code>\u521d\u5b66\u8005\u8fd8\u662f\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5f00\u53d1\u8005\uff0c<code>Pipelines</code>\u90fd\u80fd\u5e2e\u52a9\u4f60\u66f4\u9ad8\u6548\u5730\u6784\u5efa<code>NLP</code>\u5e94\u7528\u3002</p>"},{"location":"chapter2/pipelines/pipelines/#_2","title":"\u4efb\u52a1\u7c7b\u578b","text":"<p>\u8ba9\u6211\u4eec\u628a\u8ba8\u8bba\u8303\u7574\u6682\u65f6\u9650\u5b9a\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u3002</p> <p></p> <p><code>HuggingFace</code>\u62e5\u6709\u4e00\u4e2a\u6d77\u91cf\u7684\u6a21\u578b\u5e93\uff0c\u4e0d\u540c\u7684\u6a21\u578b\u5b9e\u73b0\u4e0d\u540c\u7684\u529f\u80fd\uff0c\u4e0d\u540c\u7684\u529f\u80fd\u89e3\u51b3\u4e0d\u540c\u7684\u73b0\u5b9e\u4e16\u754c\u9700\u6c42\uff0c\u6211\u4eec\u53ef\u4ee5\u6307\u5b9a<code>pipelines</code>\u4efb\u52a1\u7c7b\u578b\u4ee5\u7cbe\u51c6\u8c03\u7528\u6a21\u578b\uff0c\u5316\u89e3\u73b0\u5b9e\u96be\u9898\u3002\u6240\u4ee5\u6df1\u5165\u4e86\u89e3<code>HuggingFace</code>\u6240\u652f\u6301\u7684\u4efb\u52a1\u7c7b\u578b\uff0c\u4fbf\u663e\u5f97\u5c24\u4e3a\u91cd\u8981\u3002</p> <p>\u5f00\u53d1\u8005\u53ef\u4ee5\u5728pipelines\u4efb\u52a1\u7c7b\u578b\u00a0\u29c9\u9875\u9762\u53f3\u4fa7\u5927\u7eb2\u67e5\u9605\u6240\u6709\u4efb\u52a1\u7ba1\u9053\u7c7b\u578b\u3002</p> <p>\u4ee5\u4e0b\u4e3a\u76ee\u524d\u6240\u652f\u6301\u7684\u4efb\u52a1\u7ba1\u9053\u3002</p> <p>\u597d\u7684\uff0c\u4ee5\u4e0b\u662f\u60a8\u63d0\u4f9b\u7684\u8868\u683c\u5408\u5e76\u6210\u4e00\u4e2a\u8868\u683c\uff1a</p> \u4efb\u52a1\u7c7b\u522b \u4efb\u52a1\u540d\u79f0 \u8c03\u7528\u5b57\u7b26\u4e32 \u81ea\u7136\u8bed\u8a00 \u63a9\u7801\u586b\u5145 <code>\"fill-mask\"</code> \u95ee\u7b54 <code>\"question-answering\"</code> \u6587\u672c\u6458\u8981 <code>\"summarization\"</code> \u8868\u683c\u95ee\u7b54 <code>\"table-question-answering\"</code> \u6587\u672c\u5206\u7c7b <code>\"text-classification\"</code> \u6587\u672c\u751f\u6210 <code>\"text-generation\"</code> \u6587\u672c\u5230\u6587\u672c\u751f\u6210 <code>\"text2text-generation\"</code> Token \u5206\u7c7b <code>\"token-classification\"</code> \u7ffb\u8bd1 <code>\"translation\"</code> \u96f6\u6837\u672c\u5206\u7c7b <code>\"zero-shot-classification\"</code> \u97f3\u9891 \u97f3\u9891\u5206\u7c7b <code>\"audio-classification\"</code> \u8bed\u97f3\u8bc6\u522b <code>\"automatic-speech-recognition\"</code> \u6587\u672c\u8f6c\u8bed\u97f3 <code>\"text-to-speech\"</code> \u6587\u672c\u8f6c\u97f3\u9891 <code>\"text-to-audio\"</code> \u96f6\u6837\u672c\u97f3\u9891\u5206\u7c7b <code>\"zero-shot-audio-classification\"</code> \u4efb\u52a1\u7c7b\u522b \u4efb\u52a1\u540d\u79f0 \u8c03\u7528\u5b57\u7b26\u4e32 \u8ba1\u7b97\u673a\u89c6\u89c9 \u6df1\u5ea6\u4f30\u8ba1 <code>\"depth-estimation\"</code> \u56fe\u50cf\u5206\u7c7b <code>\"image-classification\"</code> \u56fe\u50cf\u5206\u5272 <code>\"image-segmentation\"</code> \u56fe\u50cf\u5230\u56fe\u50cf\u8f6c\u6362 <code>\"image-to-image\"</code> \u76ee\u6807\u68c0\u6d4b <code>\"object-detection\"</code> \u89c6\u9891\u5206\u7c7b <code>\"video-classification\"</code> \u96f6\u6837\u672c\u56fe\u50cf\u5206\u7c7b <code>\"zero-shot-image-classification\"</code> \u96f6\u6837\u672c\u76ee\u6807\u68c0\u6d4b <code>\"zero-shot-object-detection\"</code> \u591a\u6a21\u6001 \u6587\u6863\u95ee\u7b54 <code>\"document-question-answering\"</code> \u7279\u5f81\u63d0\u53d6 <code>\"feature-extraction\"</code> \u56fe\u50cf\u7279\u5f81\u63d0\u53d6 <code>\"image-feature-extraction\"</code> \u56fe\u50cf\u5230\u6587\u672c <code>\"image-to-text\"</code> \u63a9\u7801\u751f\u6210 <code>\"mask-generation\"</code> \u89c6\u89c9\u95ee\u7b54 <code>\"visual-question-answering\"</code>"},{"location":"chapter2/pipelines/pipelines/#_3","title":"\u5e38\u89c1\u4efb\u52a1\u6f14\u793a","text":"<p>\u5bf9\u4e8e<code>pipelines</code>\uff0c\u901a\u5e38\u53ea\u662f\u505a\u9a8c\u8bc1\u4f7f\u7528\uff0c\u5b83\u53ef\u4ee5\u63a5\u6536\uff1a</p> <ul> <li>\u5355\u6837\u672c</li> <li>\u591a\u6837\u672c</li> <li><code>Datasets</code>\u7c7b\u5b9e\u4f8b</li> <li>\u751f\u6210\u5668</li> </ul> \u6587\u672c\u5206\u7c7b\u63a9\u7801\u586b\u5145\u95ee\u7b54\u7cfb\u7edf\u6587\u672c\u6458\u8981 text-classification\u5355\u6837\u672c<pre><code>from transformers import pipeline\ncls = pipeline(\"text-classification\")\ncls(\n    [\n        \"I've been waiting for a HuggingFace course my whole life.\"\n    ]\n)\n</code></pre> out<pre><code> [\n {'label': 'POSITIVE', 'score': 0.9598049521446228},\n ]\n</code></pre> text-classification\u591a\u6837\u672c<pre><code>from transformers import pipeline\ncls = pipeline(\"text-classification\")\ncls(\n    [\n        \"I've been waiting for a HuggingFace course my whole life.\",\n        \"wow, this model is amazing!\",\n    ]\n)\n</code></pre> out<pre><code> [\n {'label': 'POSITIVE', 'score': 0.9598049521446228},\n {'label': 'POSITIVE', 'score': 0.9998725652694702}\n ]\n</code></pre> fill-mask<pre><code>from transformers import pipeline\n\nunmasker = pipeline(\"fill-mask\")\nunmasker(\"This course will teach you all about &lt;mask&gt; models.\", top_k=2)\n</code></pre> output<pre><code>[\n\u00a0 \u00a0 {\n\u00a0 \u00a0 \u00a0 \u00a0 \"sequence\": \"This course will teach you all about mathematical models.\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"score\": 0.19619831442832947,\n\u00a0 \u00a0 \u00a0 \u00a0 \"token\": 30412,\n\u00a0 \u00a0 \u00a0 \u00a0 \"token_str\": \" mathematical\",\n\u00a0 \u00a0 },\n\n\u00a0 \u00a0 {\n\n\u00a0 \u00a0 \u00a0 \u00a0 \"sequence\": \"This course will teach you all about computational models.\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"score\": 0.04052725434303284,\n\u00a0 \u00a0 \u00a0 \u00a0 \"token\": 38163,\n\u00a0 \u00a0 \u00a0 \u00a0 \"token_str\": \" computational\",\n\u00a0 \u00a0 },\n]\n</code></pre> question-answering<pre><code>from transformers import pipeline\nquestion_answerer = pipeline(\"question-answering\")\nquestion_answerer(\n\u00a0 \u00a0 question=\"Where do I work?\",\n\u00a0 \u00a0 context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n)\n</code></pre> output<pre><code>{\"score\": 0.6949766278266907, \"start\": 33, \"end\": 45, \"answer\": \"Hugging Face\"}\n</code></pre> summarization<pre><code>from transformers import pipeline\n\nsummarizer = pipeline(\"summarization\")\nsummarizer(\n\u00a0 \u00a0 \"\"\"\n\u00a0 \u00a0 America has changed dramatically during recent years. Not only has the number of\n\u00a0 \u00a0 graduates in traditional engineering disciplines such as mechanical, civil,\n\u00a0 \u00a0 electrical, chemical, and aeronautical engineering declined, but in most of\n\u00a0 \u00a0 the premier American universities engineering curricula now concentrate on\n\u00a0 \u00a0 and encourage largely the study of engineering science. As a result, there\n\u00a0 \u00a0 are declining offerings in engineering subjects dealing with infrastructure,\n\u00a0 \u00a0 the environment, and related issues, and greater concentration on high\n\u00a0 \u00a0 technology subjects, largely supporting increasingly complex scientific\n\u00a0 \u00a0 developments. While the latter is important, it should not be at the expense\n\u00a0 \u00a0 of more traditional engineering.\n\n\u00a0 \u00a0 Rapidly developing economies such as China and India, as well as other\n\u00a0 \u00a0 industrial countries in Europe and Asia, continue to encourage and advance\n\u00a0 \u00a0 the teaching of engineering. Both China and India, respectively, graduate\n\u00a0 \u00a0 six and eight times as many traditional engineers as does the United States.\n\u00a0 \u00a0 Other industrial countries at minimum maintain their output, while America\n\u00a0 \u00a0 suffers an increasingly serious decline in the number of engineering graduates\n\u00a0 \u00a0 and a lack of well-educated engineers.\n\"\"\"\n)\n</code></pre> output<pre><code>[\n  {\n\"summary_text\": \"America has changed dramatically during recent years. The number of engineering graduates in the U.S. has declined in traditionalengineering disciplines such as mechanical, civil, electrical, chemical, and aeronautical engineering. Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering.\"\n  }\n]\n</code></pre>"},{"location":"chapter2/pipelines/pipelines/#_4","title":"\u81ea\u5b9a\u4e49\u5206\u8bcd\u5668\u4e0e\u6a21\u578b","text":"<p>\u7ba1\u9053\u5de5\u5177\u5728\u6267\u884c\u4efb\u52a1\u7684\u65f6\u5019\u4f1a\u81ea\u52a8\u5206\u914d\u4e00\u4e2a\u6a21\u578b\uff0c\u5982\u679c\u9700\u8981\u81ea\u5b9a\u4e49\u5206\u8bcd\u5668\u6216\u8005\u6a21\u578b\uff0c\u90a3\u4e48\u9700\u8981\u63d0\u524d\u52a0\u8f7d\u5206\u8bcd\u5668\u6216\u6a21\u578b\uff0c\u4f20\u5165<code>pipeline</code>\u4e2d\uff0c\u5c06\u5f62\u53c2<code>model</code>\u8bbe\u7f6e\u4e3a\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u5c06\u5f62\u53c2<code>tokenizer</code>\u8bbe\u7f6e\u4e3a\u81ea\u5b9a\u4e49\u7684\u5206\u8bcd\u5668\u3002</p> Python<pre><code>from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\npipes = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n</code></pre> output<pre><code>[{'label': 'positive (stars 4 and 5)', 'score': 0.9877167344093323}]\n</code></pre>"},{"location":"chapter2/tokenizer/tokenizer_detail/","title":"\u5206\u8bcd\u5668","text":""},{"location":"chapter2/tokenizer/tokenizer_detail/#_1","title":"\u52a0\u8f7d\u5206\u8bcd\u5668","text":"<p><code>from_pretrained()</code>\u65b9\u6cd5\u7528\u4e8e\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u5206\u8bcd\u5668\u3002\u4ee5\u4e0b\u662f\u8be5\u65b9\u6cd5\u5e38\u7528\u7684\u53c2\u6570\u53ca\u5176\u4ecb\u7ecd\u3002</p> Python<pre><code>from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('hfl/chinese-roberta-wwm-ext')\n</code></pre> \u53c2\u6570\u540d\u79f0 \u529f\u80fd <code>pretrained_model_name_or_path</code> \u6240\u8981\u52a0\u8f7d\u7684\u5206\u8bcd\u5668\uff0c\u5176\u503c\u4e3a\u9884\u8bad\u7ec3\u6a21\u578b\u540d\u79f0\u6216\u6a21\u578b\u5728\u672c\u5730\u7684\u8def\u5f84\u3002 <code>use_fast</code> \u662f\u5426\u4f7f\u7528\u57fa\u4e8e<code>Rust</code>\u7684\u5feb\u901f\u5206\u8bcd\u5668\u3002\u5982\u679c\u8bbe\u7f6e\u4e3a<code>True</code>\u4e14\u6a21\u578b\u652f\u6301\u5feb\u901f\u5206\u8bcd\u5668\uff0c\u5219\u5c06\u4f18\u5148\u4f7f\u7528\u5feb\u901f\u5206\u8bcd\u5668\u3002\u5426\u5219\uff0c\u5c06\u4f7f\u7528\u57fa\u4e8e<code>Python</code>\u7684\u6807\u51c6\u5206\u8bcd\u5668\u3002 <code>trust_remote_code</code> \u662f\u5426\u5141\u8bb8\u6267\u884c\u8fdc\u7a0b\u4ee3\u7801\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u4e3a\u4e86\u5b89\u5168\u8d77\u89c1\uff0c\u9ed8\u8ba4\u662f\u5173\u95ed\u7684\u3002\u5982\u679c\u5f00\u53d1\u8005\u5b8c\u5168\u4fe1\u4efb\u4ee3\u7801\u6765\u6e90\uff0c\u53ef\u4ee5\u542f\u7528\u5b83\u4ee5\u83b7\u5f97\u989d\u5916\u7684\u529f\u80fd\uff0c\u4f46\u8bf7\u8c28\u614e\u64cd\u4f5c\uff0c\u56e0\u4e3a\u8fd9\u4f1a\u589e\u52a0\u5b89\u5168\u98ce\u9669\u3002 <p>\u7ecf\u8fc7\u4e0a\u8ff0\u4ee3\u7801\uff0c\u4f1a\u4ea7\u751f\u4e00\u4e2a\u4e0e\u6240\u9884\u8bad\u7ec3\u6a21\u578b\u76f8\u5bf9\u5e94\u7684\u5206\u8bcd\u5668\u5b9e\u4f8b\u3002</p> <p>\u5907\u6ce8</p> <ul> <li>\u5982\u679c\u52a0\u8f7d\u7684\u662f<code>bert-base-uncased</code>\u00a0\u6a21\u578b\uff0c\u90a3\u4e48\u4ee3\u7801\u4f1a\u8fd4\u56de\u4e00\u4e2a<code>BertTokenizer</code>\u5b9e\u4f8b\u3002</li> <li>\u5982\u679c\u52a0\u8f7d\u7684\u662f<code>gpt2</code>\u6a21\u578b\uff0c\u90a3\u4e48\u4ee3\u7801\u4f1a\u8fd4\u56de\u4e00\u4e2a\u00a0<code>GPT2Tokenizer</code>\u00a0\u5b9e\u4f8b\u3002</li> <li>\\(\\cdots\\)</li> </ul>"},{"location":"chapter2/tokenizer/tokenizer_detail/#_2","title":"\u5206\u8bcd\u5668\u5c5e\u6027\u4e0e\u65b9\u6cd5","text":"<p>\u5206\u8bcd\u5668\u5b9e\u4f8b\u5e38\u7528\u7684\u65b9\u6cd5\u548c\u5c5e\u6027\u4f1a\u56e0\u5177\u4f53\u7684\u5206\u8bcd\u5668\u7c7b\u800c\u7565\u6709\u4e0d\u540c\uff0c\u4f46\u4e00\u822c\u90fd\u4f1a\u5305\u542b\u4ee5\u4e0b\u5e38\u7528\u65b9\u6cd5\u548c\u5c5e\u6027\uff1a</p> \u65b9\u6cd5 \u8bf4\u660e \u8f93\u5165\u793a\u4f8b \u8f93\u51fa\u793a\u4f8b <code>tokenize(text)</code> \u5c06\u6587\u672c\u5206\u5272\u6210\u8bcd\u6216\u5b50\u8bcd\u5217\u8868 <code>\"\u8fd9\u662f\u4e00\u4e2a\u53e5\u5b50\u3002\"</code> <code>['\u8fd9', '\u662f', '\u4e00', '\u4e2a', '\u53e5', '\u5b50', '\u3002']</code> <code>encode(text)</code> \u5c06\u6587\u672c\u7f16\u7801\u6210\u6570\u5b57\u5e8f\u5217 <code>\"\u8fd9\u662f\u4e00\u4e2a\u53e5\u5b50\u3002\"</code> <code>[101, 6821, 3221, 671, 702, 1368, 2094, 511, 102]</code> <code>decode(ids)</code> \u5c06\u6570\u5b57\u5e8f\u5217\u89e3\u7801\u56de\u6587\u672c <code>[101, 6821, 3221, 671, 702, 1368, 2094, 511, 102]</code> <code>'[CLS] \u8fd9\u662f\u4e00\u4e2a\u53e5\u5b50\u3002 [SEP]'</code> <code>add_special_tokens(token_ids)</code> \u6dfb\u52a0\u7279\u6b8a\u6807\u8bb0 <code>convert_tokens_to_ids(tokens)</code> \u5c06\u8bcd\u6216\u5b50\u8bcd\u5217\u8868\u8f6c\u6362\u4e3a\u6570\u5b57 ID \u5217\u8868 <code>['\u8fd9', '\u662f', '\u4e00']</code> <code>[6821, 3221, 671]</code> <code>convert_ids_to_tokens(ids)</code> \u5c06\u6570\u5b57 ID \u5217\u8868\u8f6c\u6362\u4e3a\u8bcd\u6216\u5b50\u8bcd\u5217\u8868 <code>[1368, 2094, 511]</code> <code>['\u53e5', '\u5b50', '\u3002']</code> <code>save_pretrained(save_directory)</code> \u4fdd\u5b58\u5206\u8bcd\u5668\u5230\u672c\u5730\u76ee\u5f55 <code>\"./local_chinese-roberta-wwm-ext\"</code> \u5c5e\u6027 \u8bf4\u660e \u793a\u4f8b <code>vocab_size</code> \u8bcd\u6c47\u8868\u5927\u5c0f <code>tokenizer.vocab_size</code> <code>21128</code> <code>bos_token</code> \u5f00\u5934\u6807\u8bb0 <code>tokenizer.bos_token</code> <code>None</code> <code>eos_token</code> \u7ed3\u5c3e\u6807\u8bb0 <code>tokenizer.eos_token</code> <code>None</code> <code>unk_token</code> \u672a\u77e5\u8bcd\u6807\u8bb0 <code>tokenizer.unk_token</code> <code>'[UNK]'</code> <code>sep_token</code> \u5206\u9694\u7b26\u6807\u8bb0 <code>tokenizer.sep_token</code> <code>'[SEP]'</code> <code>pad_token</code> \u586b\u5145\u6807\u8bb0 <code>tokenizer.pad_token</code> <code>'[PAD]'</code> <code>cls_token</code> \u5206\u7c7b\u6807\u8bb0 <code>tokenizer.cls_token</code> <code>'[CLS]'</code> <code>mask_token</code> \u63a9\u7801\u6807\u8bb0 <code>tokenizer.mask_token</code> <code>'[MASK]'</code> <code>vocab</code> \u8bcd\u6c47\u8868\uff0c\u8bcd\u6216\u5b50\u8bcd\u5230\u6570\u5b57\u7684\u6620\u5c04 <code>tokenizer.vocab['[CLS]']</code> <code>101</code>"},{"location":"chapter2/tokenizer/tokenizer_detail/#_3","title":"\u7f16\u7801\u51fd\u6570","text":"<p>\u5728\u5206\u8bcd\u5668\u7684\u4f7f\u7528\u4e2d\uff0c\u6700\u91cd\u8981\u7684\u65b9\u6cd5\u5c31\u662f\u7f16\u7801\u51fd\u6570\uff0c\u56e0\u6b64\u9700\u8981\u5355\u72ec\u4e86\u89e3\u7f16\u7801\u51fd\u6570\u3002</p> \u7f16\u7801<pre><code>def encode(\n    self,\n    text: Union[TextInput, PreTokenizedInput, EncodedInput],\n    text_pair: Optional[Union[TextInput, PreTokenizedInput, EncodedInput]] = None,\n    add_special_tokens: bool = True,\n    padding: Union[bool, str, PaddingStrategy] = False,\n    truncation: Union[bool, str, TruncationStrategy] = None,\n    max_length: Optional[int] = None,\n    stride: int = 0,\n    return_tensors: Optional[Union[str, TensorType]] = None,\n    **kwargs,\n) -&gt; List[int]:\n</code></pre> <p>\u4ee5\u4e0b\u662f\u7f16\u7801\u51fd\u6570\u5e38\u7528\u7684\u53c2\u6570\u3001\u53c2\u6570\u7c7b\u578b\u3001\u9ed8\u8ba4\u503c\u5bf9\u7167\u8868\u3002</p> \u53c2\u6570 \u7c7b\u578b \u9ed8\u8ba4\u503c \u8bf4\u660e <code>text</code> <code>Union[str, List[str], List[int]]</code> \u8fdb\u884c\u7f16\u7801\u65f6\u7b2c\u4e00\u4e2a\u53e5\u5b50\u3002 <code>text_pair</code> <code>Optional[Union[str, List[str], List[int]]]</code> <code>None</code> \u8fdb\u884c\u7f16\u7801\u65f6\u7b2c\u4e8c\u4e2a\u53e5\u5b50\u3002 <code>add_special_tokens</code> <code>bool</code> <code>True</code> \u7f16\u7801\u5e8f\u5217\u65f6\u662f\u5426\u6dfb\u52a0\u7279\u6b8a\u6807\u8bb0\u3002 <code>padding</code> <code>Union[bool, str, PaddingStrategy]</code> <code>False</code> \u63a7\u5236\u662f\u5426\u8fdb\u884c\u586b\u5145\u3002 <code>truncation</code> <code>Union[bool, str, TruncationStrategy]</code> <code>False</code> \u63a7\u5236\u5f53\u5e8f\u5217\u957f\u5ea6\u8d85\u8fc7 <code>max_length</code> \u65f6\u662f\u5426\u8fdb\u884c\u622a\u65ad\u3002 <code>max_length</code> <code>Optional[int]</code> <code>None</code> \u63a7\u5236\u622a\u65ad\u548c\u586b\u5145\u53c2\u6570\u4f7f\u7528\u7684\u6700\u5927\u957f\u5ea6\u3002 <code>return_tensors</code> <code>Optional[Union[str, TensorType]]</code> <code>None</code> \u9ed8\u8ba4\u4e3a\u5217\u8868\u6570\u636e\u7c7b\u578b\uff0c\u4e5f\u53ef\u4ee5\u8bbe\u7f6e\u4e3a <code>'tf'</code>\uff0c<code>'pt'</code>\uff0c<code>'np'</code>\uff0c\u5206\u522b\u8868\u793a\u8fd4\u56de\u7684\u7ed3\u679c\u4e3a <code>TensorFlow</code>\uff0c<code>PyTorch</code>\uff0c<code>Numpy</code> \u683c\u5f0f\u3002 \u662f\u5426\u6dfb\u52a0\u7279\u6b8a\u6807\u8bb0<pre><code>text = \"\u8fd9\u662f\u4e00\u4e2a\u6d4b\u8bd5\u53e5\u5b50\u3002\"\ntext_pair = \"\u8fd9\u662f\u7b2c\u4e8c\u4e2a\u53e5\u5b50\u3002\"\n\nencoded_inputs = tokenizer(text, text_pair, add_special_tokens=False)\nencoded_inputs = tokenizer(text, text_pair, add_special_tokens=True)\n</code></pre> \u4e0d\u6dfb\u52a0\u7279\u6b8a\u6807\u8bb0<pre><code>{\n    'input_ids': [\n        6821, 3221, 671, 702, 3844, 6407, 1368, 2094, 511,\n        6821, 3221, 5018, 753, 702, 1368, 2094, 511\n    ],\n    'token_type_ids': [\n        0, 0, 0, 0, 0, 0, 0, 0, 0,\n        1, 1, 1, 1, 1, 1, 1, 1\n    ],\n    'attention_mask': [\n        1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1\n    ]\n}\n</code></pre> \u6dfb\u52a0\u7279\u6b8a\u6807\u8bb0<pre><code>{\n    'input_ids': [\n        101, 6821, 3221, 671, 702, 3844, 6407, 1368, 2094, 511, 102,\n        6821, 3221, 5018, 753, 702, 1368, 2094, 511, 102,\n    ],\n    'token_type_ids': [\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n    ],\n    'attention_mask': [\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n    ]\n}\n</code></pre> <ul> <li><code>input_ids</code>: \u5c06\u8f93\u5165\u6587\u672c\u5206\u8bcd\u5e76\u8f6c\u6362\u540e\u5bf9\u5e94\u4e8e\u8bcd\u6c47\u8868\u7684\u7d22\u5f15\u3002</li> <li><code>token_type_ids</code>: \u533a\u5206\u4e24\u4e2a\u53e5\u5b50\uff0c\u7b2c\u4e00\u4e2a\u53e5\u5b50\u6240\u6709\u8bcd\u7684<code>ID</code>\u4e3a0\uff0c\u7b2c\u4e8c\u4e2a\u53e5\u5b50\u6240\u6709\u8bcd\u7684<code>ID</code>\u4e3a1\u3002</li> <li><code>attention_mask</code>: \u6807\u8bc6\u54ea\u4e9b\u662f\u771f\u5b9e\u8bcd\uff08\u503c\u4e3a1\uff09\uff0c\u54ea\u4e9b\u662f\u586b\u5145\u8bcd\uff08\u503c\u4e3a0\uff09\u3002\u8fd9\u91cc\u6ca1\u6709\u586b\u5145\uff0c\u6240\u4ee5\u5168\u662f1\u3002</li> <li>\u4e0e \"\u4e0d\u6dfb\u52a0\u7279\u6b8a\u6807\u8bb0\" \u76f8\u6bd4\uff0c\u8fd9\u91cc\u6dfb\u52a0\u4e86\uff1a</li> <li><code>[CLS]</code>\u00a0\u6807\u8bb0 (<code>ID</code>: 101) \u5728\u53e5\u5b50\u5f00\u5934\u3002</li> <li><code>[SEP]</code>\u00a0\u6807\u8bb0 (<code>ID</code>: 102) \u5728\u7b2c\u4e00\u4e2a\u53e5\u5b50\u672b\u5c3e\u548c\u6574\u4e2a\u8f93\u5165\u672b\u5c3e\u3002</li> </ul> \u662f\u5426\u8fdb\u884c\u586b\u5145<pre><code>encoded_inputs = tokenizer(\n\u00a0 \u00a0 [\"\u8fd9\u662f\u4e00\u4e2a\u6d4b\u8bd5\u53e5\u5b50\u3002\", \"\u8fd9\u3002\"],\n\u00a0 \u00a0 padding=\"max_length\", \u00a0# \u8bbe\u7f6e\u586b\u5145\u65b9\u5f0f\u4e3a 'max_length'\n\u00a0 \u00a0 truncation=True, \u00a0# \u53e5\u5b50\u957f\u5ea6\u8d85\u8fc7 max_length \u65f6\u8fdb\u884c\u622a\u65ad\n\u00a0 \u00a0 max_length=10, \u00a0# \u8bbe\u7f6e\u6700\u5927\u957f\u5ea6\n\u00a0 \u00a0 return_tensors=\"pt\", \u00a0# \u8fd4\u56de PyTorch \u5f20\u91cf\n)\n</code></pre> \u8fdb\u884c\u586b\u5145<pre><code>{\n    'input_ids': tensor(\n        [\n            [101, 6821, 3221, 671, 702, 3844, 6407, 1368, 2094, 102],\n            [101, 6821, 511, 102, 0, 0, 0, 0, 0, 0]\uff0c\n        ]\n    ),\n    'token_type_ids': tensor(\n        [\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        ]\n    ),\n    'attention_mask': tensor(\n        [\n            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n            [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]   # \u53ea\u5173\u6ce8\u524d4\u4e2atoken\n        ]\n    )\n}\n</code></pre> \u662f\u5426\u622a\u65ad<pre><code>encoded_inputs = tokenizer(text, text_pair, truncation=False)\nencoded_inputs = tokenizer(text, text_pair, max_length=10, truncation=True)\n</code></pre> \u4e0d\u8fdb\u884c\u622a\u65ad<pre><code>{\n    'input_ids': [\n        101, 6821, 3221, 671, 702, 3844, 6407, 1368, 2094, 511, 102,\n        6821, 3221, 5018, 753, 702, 1368, 2094, 511, 102\n    ],\n    'token_type_ids': [\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        1, 1, 1, 1, 1, 1, 1, 1, 1\n    ],\n    'attention_mask': [\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1\n    ]\n}\n</code></pre> \u8fdb\u884c\u622a\u65ad<pre><code>{\n  \"input_ids\": [101, 6821, 3221, 671, 702, 102, 6821, 3221, 5018, 102],\n  \"token_type_ids\": [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n  \"attention_mask\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n}\n</code></pre> <ul> <li>\u5c06\u8f93\u5165\u6587\u672c\u622a\u65ad\u5230\u6700\u5927\u957f\u5ea6\uff0c\u4fdd\u7559\u4e86\u00a0<code>[CLS]</code>\u00a0\u548c\u00a0<code>[SEP]</code>\u00a0\u6807\u8bb0\uff0c\u5e76\u622a\u53d6\u4e86\u90e8\u5206\u53e5\u5b50\u5185\u5bb9\u3002</li> </ul> \u8fd4\u56de\u7684\u6570\u636e\u7c7b\u578b<pre><code>encoded_inputs = tokenizer(text, text_pair, return_tensors=None)\nencoded_inputs = tokenizer(text, text_pair, return_tensors=\"pt\")\nencoded_inputs = tokenizer(text, text_pair, return_tensors=\"tf\")\nencoded_inputs = tokenizer(text, text_pair, return_tensors=\"np\")\n</code></pre> PyTorch\u5f20\u91cf<pre><code>{\n  'input_ids': tensor([[101, 6821, 3221, 671, 702, 3844, 6407, 1368, 2094, 511, 102,\n                       6821, 3221, 5018, 753, 702, 1368, 2094, 511, 102]]),\n  'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n}\n</code></pre> TensorFlow \u5f20\u91cf<pre><code>{\n    'input_ids': &lt;tf.Tensor: shape=(1, 20), dtype=int32, numpy=\n    array([[ 101, 6821, ...,  511,  102]])&gt;,\n    'token_type_ids': &lt;tf.Tensor: shape=(1, 20), dtype=int32, numpy=array([[0, 0, ..., 1, 1]])&gt;,\n    'attention_mask': &lt;tf.Tensor: shape=(1, 20), dtype=int32, numpy=array([[1, 1, ..., 1, 1]])&gt;\n}\n</code></pre> NumPy\u6570\u7ec4<pre><code>{\n    'input_ids': array([[101, 6821, ..., 511, 102]]),\n    'token_type_ids': array([[0, 0, ..., 1, 1]]),\n    'attention_mask': array([[1, 1, ..., 1, 1]])\n}\n</code></pre>"},{"location":"chapter2/tokenizer/tokenizer_tour/","title":"\u5206\u8bcd","text":""},{"location":"chapter2/tokenizer/tokenizer_tour/#_1","title":"\u524d\u8a00","text":"<p>\u5728<code>NLP</code>\u4efb\u52a1\u4e2d\uff0c\u5904\u7406\u7684\u6570\u636e\u662f\u5404\u79cd\u5404\u6837\u7684\u6587\u672c\u3002\u6bd4\u5982\u4e0b\u65b9\u6240\u793a\u7684\u53e4\u8bd7\uff0c\u4f46\u662f\uff0c\u6a21\u578b\u53ea\u8ba4\u6570\u5b57\uff0c\u5176\u5b83\u4e00\u6982\u4e0d\u8ba4\uff0c\u56e0\u6b64\u9700\u8981\u627e\u5230\u4e00\u79cd\u5c06\u539f\u59cb\u6587\u672c\u8f6c\u6362\u4e3a\u6570\u5b57\u7684\u65b9\u6cd5\u3002\u5f00\u95e8\u89c1\u5c71\u5730\u8bf4\uff0c\u8fd9\u5c31\u662f\u5206\u8bcd\u5668\uff08tokenizer\uff09\u7684\u804c\u8d23\u3002</p> \u300a\u671b\u5e90\u5c71\u7011\u5e03\u300b<pre><code>\u65e5\u7167\u9999\u7089\u751f\u7d2b\u70df\uff0c\u9065\u770b\u7011\u5e03\u6302\u524d\u5ddd\u3002\n\u98de\u6d41\u76f4\u4e0b\u4e09\u5343\u5c3a\uff0c\u7591\u662f\u94f6\u6cb3\u843d\u4e5d\u5929\u3002\n</code></pre> <p>\u5728\u5206\u8bcd\u8fd9\u5757\uff0c\u4e0d\u540c\u7684\u8bed\u8a00\u4e4b\u95f4\u5b58\u5728\u7740\u5929\u7136\u7684\u5dee\u5f02\uff0c\u672c\u6559\u7a0b\u4e3b\u8981\u4ecb\u7ecd\u4e2d\u82f1\u6587\u5206\u8bcd\u3002</p> <p>\u57fa\u4e8e\u8f6c\u6362\u65b9\u5f0f\u7684\u4e0d\u540c\uff0c\u4ecb\u7ecd\u4e24\u79cd\u8bed\u8a00\u4e0b\u7684\u4e24\u79cd\u7c92\u5ea6\u7684\u5206\u8bcd\u5668\u3002</p>"},{"location":"chapter2/tokenizer/tokenizer_tour/#_2","title":"\u4e2d\u6587\u5206\u8bcd","text":""},{"location":"chapter2/tokenizer/tokenizer_tour/#_3","title":"\u57fa\u4e8e\u5b57\u7684\u5206\u8bcd\u5668","text":"<p>\u57fa\u4e8e\u5b57\u7684\u5206\u8bcd\u5668\u5c06\u6587\u672c\u62c6\u5206\u4e3a\u5355\u4e2a\u5b57\u3002</p> <p>\u4f18\u70b9\uff1a</p> <ul> <li>\u5b57\u5178\u8981\u5c0f\u5f97\u591a\u3002\u867d\u7136\u6c49\u5b57\u7684\u5b57\u6570\u57fa\u6570\u975e\u5e38\u5e9e\u5927\uff0c\u4f46\u662f\u9762\u5bf9\u4ee5\u5b57\u4e3a\u57fa\u7840\uff0c\u6d69\u5982\u70df\u6d77\u7684\u8bcd\u8bed\u7b97\u662f\u5c0f\u5deb\u89c1\u5927\u5deb\u3002</li> <li>\u672a\u767b\u8bb0\u5b57\u8bcd\uff08OOV\uff09\u8981\u5c11\u5f97\u591a\u3002</li> </ul> \u5206\u8bcd \u7ed3\u679c \u65e5 \u7167 \u9999 \u7089 \u751f \u7d2b \u70df \uff0c \u9065 \u770b \u7011 \u5e03 \u6302 \u524d \u5ddd \u3002 \u98de \u6d41 \u76f4 \u4e0b \u4e09 \u5343 \u5c3a \uff0c \u7591 \u662f \u94f6 \u6cb3 \u843d \u4e5d \u5929 \u3002 <p>\u8fd9\u79cd\u65b9\u6cd5\u5728\u5b9e\u8df5\u4e2d\u5e76\u4e0d\u662f\u5b8c\u7f8e\u7684\u3002\u60f3\u8c61\u4e00\u4e0b\u4eba\u4e0e\u4eba\u4e4b\u95f4\u4ea4\u6d41\uff0c\u80af\u5b9a\u66f4\u503e\u5411\u4e8e\u4ee5\u8bcd\u4e3a\u5355\u4f4d\u8fdb\u884c\u7406\u89e3\u548c\u8868\u8fbe\u3002</p> <p>\u5018\u82e5\u5728\u4ea4\u6d41\u65f6\u53ea\u8bf4\u4e00\u4e2a\u5b57\uff0c\u5bf9\u65b9\u4e5f\u53ea\u56de\u5e94\u4e00\u4e2a\u5b57\uff0c\u5bf9\u8bdd\u53cc\u65b9\u5f80\u5f80\u5bf9\u5f7c\u6b64\u6240\u8981\u8868\u8fbe\u7684\u610f\u601d\u4e91\u91cc\u96fe\u91cc\u3002\u6240\u4ee5\u7ed3\u5408\u73b0\u5b9e\u6765\u8bf4\u5355\u4e2a\u5b57\u7684\u610f\u4e49\u5f80\u5f80\u4e0d\u5927\u3002</p>"},{"location":"chapter2/tokenizer/tokenizer_tour/#_4","title":"\u57fa\u4e8e\u8bcd\u7684\u5206\u8bcd","text":"<p>\u57fa\u4e8e\u8bcd\u7684\u5206\u8bcd\u5668\u5c06\u6587\u672c\u62c6\u5206\u4e3a\u591a\u4e2a\u8bcd\u7ec4\u3002</p> <p>\u4f18\u70b9\uff1a</p> <ol> <li>\u76f4\u89c2\u6613\u61c2\uff0c\u5206\u8bcd\u7ed3\u679c\u4e0e\u4eba\u7c7b\u7684\u8bed\u8a00\u4e60\u60ef\u76f8\u7b26\uff0c\u6613\u4e8e\u7406\u89e3\u3002</li> <li>\u5904\u7406\u5e38\u89c1\u8bcd\u8bed\u6548\u679c\u597d\uff0c\u5bf9\u4e8e\u8bcd\u5178\u4e2d\u5df2\u6709\u7684\u8bcd\u8bed\uff0c\u80fd\u591f\u51c6\u786e\u5730\u8fdb\u884c\u5206\u8bcd\u3002</li> </ol> <p>\u7f3a\u70b9\uff1a</p> <ol> <li>\u5904\u7406\u672a\u767b\u5f55\u8bcd\u6548\u679c\u5dee\uff0c\u5bf9\u4e8e\u8bcd\u5178\u4e2d\u6ca1\u6709\u6536\u5f55\u7684\u65b0\u8bcd\u3001\u4e13\u4e1a\u672f\u8bed\u3001\u7f51\u7edc\u7528\u8bed\u7b49\uff0c\u65e0\u6cd5\u8fdb\u884c\u6709\u6548\u5206\u8bcd\uff0c\u53ef\u80fd\u4f1a\u5c06\u5b83\u4eec\u9519\u8bef\u5730\u5207\u5206\u6216\u8bc6\u522b\u4e3a\u4e00\u4e2a\u8bcd\u3002</li> <li>\u8bcd\u5178\u6784\u5efa\u6210\u672c\u9ad8\uff0c\u9700\u8981\u4eba\u5de5\u6784\u5efa\u548c\u7ef4\u62a4\u5e9e\u5927\u7684\u8bcd\u5178\uff0c\u6210\u672c\u8f83\u9ad8\u3002</li> </ol> \u5206\u8bcd\u7ed3\u679c \u65e5\u7167 \u9999\u7089 \u751f \u7d2b\u70df \uff0c \u9065\u770b \u7011\u5e03 \u6302 \u524d\u5ddd \u3002 \u98de\u6d41 \u76f4\u4e0b \u4e09\u5343\u5c3a \uff0c \u7591\u662f \u94f6\u6cb3 \u843d \u4e5d\u5929 \u3002"},{"location":"chapter2/tokenizer/tokenizer_tour/#_5","title":"\u82f1\u6587\u5206\u8bcd","text":""},{"location":"chapter2/tokenizer/tokenizer_tour/#_6","title":"\u57fa\u4e8e\u5b57\u7b26\u7684\u5206\u8bcd\u5668","text":"<p>\u57fa\u4e8e\u5b57\u7b26\u7684\u5206\u8bcd\u5668\u5c06\u6587\u672c\u62c6\u5206\u4e3a\u5355\u4e2a\u5b57\u7b26\u3002</p> <p>\u4f18\u70b9\uff1a</p> <ul> <li>\u8bcd\u6c47\u91cf\u8981\u5c0f\u5f97\u591a\u3002\u82f1\u6587\u603b\u5171 26 \u4e2a\u5b57\u7b26\uff0c\u5916\u52a0\u5c48\u6307\u53ef\u6570\u7684\u6807\u70b9\u7b26\u53f7\u3002</li> <li>\u672a\u767b\u8bb0\u5b57\u8bcd\uff08OOV\uff09\u8981\u5c11\u5f97\u591a\u3002</li> </ul> \u5206\u8bcd\u7ed3\u679c L e t ' s d o t o k e n i z a t i o n ! <p>\u8fd9\u79cd\u65b9\u6cd5\u548c\u4e2d\u6587\u7684\u5355\u4e2a\u5b57\u5b58\u5728\u4e00\u6837\u7684\u7f3a\u9677\u3002</p>"},{"location":"chapter2/tokenizer/tokenizer_tour/#_7","title":"\u57fa\u4e8e\u8bcd\u7684\u5206\u8bcd","text":"<p>\u57fa\u4e8e\u8bcd\u7684\u5206\u8bcd\u5668\u5c06\u6587\u672c\u62c6\u5206\u4e3a\u591a\u4e2a\u8bcd\u7ec4\u3002\u5176\u4f18\u7f3a\u70b9\u548c\u4e2d\u6587\u57fa\u4e8e\u8bcd\u7684\u5206\u8bcd\u65b9\u6cd5\u76f8\u540c\u3002</p> \u5206\u8bcd \u7ed3\u679c Let's do tokenization ! <p>\u9009\u62e9\u5408\u9002\u7684\u5206\u8bcd\u65b9\u6cd5</p> <p>\u4e24\u79cd\u65b9\u6cd5\u5e76\u975e\u90fd\u662f\u5b8c\u7f8e\uff0c\u4e0d\u540c\u7684\u4efb\u52a1\u573a\u666f\u9700\u8981\u4f7f\u7528\u4e0d\u540c\u7684\u5206\u8bcd\u65b9\u6cd5\u3002</p> <ul> <li>\u9762\u5bf9\u53e4\u8bd7\u8bcd\u751f\u6210\u4efb\u52a1\uff0c\u5f00\u53d1\u8005\u53ef\u80fd\u9700\u8981\u4f7f\u7528\u57fa\u4e8e\u5b57\u7684\u5206\u8bcd\u65b9\u6cd5\uff1b</li> <li>\u9762\u5bf9\u65e5\u5e38\u7684\u5bf9\u8bdd\u4efb\u52a1\u65f6\uff0c\u53ef\u80fd\u9700\u8981\u4f7f\u7528\u57fa\u4e8e\u8bcd\u8bed\u7684\u5206\u8bcd\u65b9\u6cd5\u3002</li> </ul>"},{"location":"chapter2/tokenizer/tokenizer_tour/#_8","title":"\u5b50\u8bcd\u6807\u8bb0\u5316","text":"<p>\u5206\u8bcd\u7b97\u6cd5\u5e94\u8be5\u4f9d\u8d56\u4e8e\u8fd9\u6837\u4e00\u4e2a\u539f\u5219\uff0c\u5373\u4e0d\u5e94\u5c06\u5e38\u7528\u8bcd\u62c6\u5206\u4e3a\u66f4\u5c0f\u7684\u5b50\u8bcd\uff0c\u540c\u65f6\u5e94\u5c06\u7a00\u6709\u8bcd\u5206\u89e3\u4e3a\u6709\u610f\u4e49\u7684\u5b50\u8bcd\u3002</p> <p>\u4f8b\u5982\uff0c\u201c\u4eba\u5de5\u667a\u80fd\u201c \u53ef\u80fd\u88ab\u8ba4\u4e3a\u662f\u4e00\u4e2a\u7f55\u89c1\u7684\u8bcd\uff0c\u53ef\u4ee5\u5206\u89e3\u4e3a\u201c\u4eba\u5de5\u201d\u548c\u201c\u667a\u80fd\u201d\u3002\u8fd9\u4e24\u8005\u90fd\u53ef\u80fd\u4f5c\u4e3a\u72ec\u7acb\u7684\u5b50\u8bcd\u51fa\u73b0\u5f97\u66f4\u9891\u7e41\uff0c\u540c\u65f6\u201c\u4eba\u5de5\u667a\u80fd\u201d\u7684\u542b\u4e49\u5e76\u4e0d\u662f\u201c\u4eba\u5de5\u201d\u548c\u201c\u667a\u80fd\u201d\u8fd9\u4fe9\u5b50\u8bcd\u7684\u542b\u4e49\u7b80\u5355\u62fc\u63a5\u800c\u6210\u7684\uff0c\u800c\u662f\u7531\u201c\u4eba\u5de5\u201d\u548c\u201c\u667a\u80fd\u201d\u7684\u590d\u5408\u542b\u4e49\u4fdd\u6301\u3002</p> <p>\u518d\u6bd4\u5982\uff0c\u201cannoyingly\u201d\u53ef\u80fd\u88ab\u8ba4\u4e3a\u662f\u4e00\u4e2a\u7f55\u89c1\u7684\u8bcd\uff0c\u53ef\u4ee5\u5206\u89e3\u4e3a\u201cannoying\u201d\u548c\u201cly\u201d\u3002\u8fd9\u4e24\u8005\u90fd\u53ef\u80fd\u4f5c\u4e3a\u72ec\u7acb\u7684\u5b50\u8bcd\u51fa\u73b0\u5f97\u66f4\u9891\u7e41\uff0c\u540c\u65f6\u201cannoyingly\u201d\u7684\u542b\u4e49\u7531\u201cannoying\u201d\u548c\u201cly\u201d\u7684\u590d\u5408\u542b\u4e49\u4fdd\u6301\u3002</p> <p>\u90a3\u5982\u4f55\u8ba9\u8fd9\u79cd\u8bcd\u8bed\u88ab\u4fdd\u7559\u4e0b\u6765\u5462\uff1f\u6587\u672c\u7ecf\u8fc7\u5206\u8bcd\u540e\uff0c\u53ef\u4ee5\u6dfb\u52a0\u5b50\u8bcd\u6807\u8bb0\u6765\u6807\u8bb0\u5206\u8bcd\u540e\u7684\u5e8f\u5217\u3002</p> \u5206\u8bcd\u7ed3\u679c Let's &lt;/w&gt; do&lt;/w&gt; token ization&lt;/w&gt; !&lt;/w&gt; <p>\u5b50\u8bcd\u6807\u8bb0\u5316\u5728\u571f\u8033\u5176\u8bed\u7b49\u7c98\u7740\u578b\u8bed\u8a00(agglutinative languages)\u4e2d\u7279\u522b\u6709\u7528\uff0c\u60a8\u53ef\u4ee5\u901a\u8fc7\u5c06\u5b50\u8bcd\u4e32\u5728\u4e00\u8d77\u6765\u5f62\u6210\uff08\u51e0\u4e4e\uff09\u4efb\u610f\u957f\u7684\u590d\u6742\u8bcd\u3002</p>"},{"location":"chapter2/tokenizer/tokenizer_tour/#_9","title":"\u5e38\u89c1\u5b50\u8bcd\u6807\u8bb0\u5316\u65b9\u6cd5","text":"\u5b57\u8282\u5bf9\u7f16\u7801 (BPE)WordPieceSentencePiece \u6216 Unigram <p><code>BPE</code>\u4ece\u5904\u7406\u8bcd\u6c47\u8868\u4e2d\u7684\u5355\u4e2a\u5b57\u7b26\u5f00\u59cb\uff0c\u7136\u540e\u8fed\u4ee3\u5730\u5408\u5e76\u6700\u9891\u7e41\u7684\u5b57\u7b26\u5bf9\uff0c\u76f4\u5230\u8fbe\u5230\u6240\u9700\u7684\u8bcd\u6c47\u8868\u5927\u5c0f\u3002</p> <ul> <li> <p>\u4f18\u70b9\uff1a</p> <ol> <li>\u901a\u8fc7\u5c06\u4e0d\u5e38\u89c1\u7684\u8bcd\u5206\u89e3\u6210\u66f4\u5c0f\u7684\u5355\u5143\u6765\u6709\u6548\u5730\u5904\u7406\u7f55\u89c1\u8bcd\u3002</li> <li>\u4e0e\u57fa\u4e8e\u5b57\u7b26\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u53ef\u4ee5\u751f\u6210\u66f4\u77ed\u7684\u8bcd\u8868\u793a\uff0c\u4ece\u800c\u63d0\u9ad8\u6548\u7387\u3002</li> </ol> </li> <li> <p>\u7f3a\u70b9\uff1a</p> <ol> <li>\u5728\u5904\u7406\u5177\u6709\u590d\u6742\u5f62\u6001\u6216\u5927\u91cf\u672a\u77e5\u8bcd\u7684\u8bed\u8a00\u65f6\uff0c\u53ef\u80fd\u4f1a\u9047\u5230\u56f0\u96be\u3002</li> </ol> </li> </ul> <p><code>WordPiece</code>\u662f<code>BERT</code>\u4f7f\u7528\u7684\u4e00\u79cd\u6807\u8bb0\u5316\u65b9\u6cd5\uff0c\u5b83\u4e0e<code>BPE</code>\u975e\u5e38\u76f8\u4f3c\uff0c\u4f46\u5b83\u57fa\u4e8e\u5408\u5e76\u540e\u7684\u8bcd\u5757\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u7684\u4f3c\u7136\u6027\u6765\u5408\u5e76\u8bcd\u5757\u3002</p> <ul> <li> <p>\u4f18\u70b9\uff1a</p> <ol> <li>\u4e0e<code>BPE</code>\u7c7b\u4f3c\uff0c\u5b83\u53ef\u4ee5\u5f88\u597d\u5730\u5904\u7406\u7f55\u89c1\u8bcd\u548c\u672a\u77e5\u8bcd\u3002</li> <li>\u901a\u5e38\u53ef\u4ee5\u751f\u6210\u6bd4<code>BPE</code>\u66f4\u7d27\u51d1\u7684\u8868\u793a\u3002</li> </ol> </li> <li> <p>\u7f3a\u70b9\uff1a</p> <ol> <li>\u4e0e<code>BPE</code>\u4e00\u6837\uff0c\u5728\u5904\u7406\u5f62\u6001\u590d\u6742\u7684\u8bed\u8a00\u65f6\u53ef\u80fd\u4f1a\u9047\u5230\u56f0\u96be\u3002</li> </ol> </li> </ul> <p><code>SentencePiece</code>\u6216<code>Unigram</code>\uff08\u901a\u5e38\u5728\u591a\u8bed\u8a00\u6a21\u578b\u4e2d\u4f7f\u7528\uff09\u5c06\u6587\u672c\u89c6\u4e3a\u539f\u59cb\u5b57\u7b26\u5e8f\u5217\uff0c\u5e76\u5b66\u4e60\u5c06\u5b57\u7b26\u5e8f\u5217\u5206\u5272\u6210\u5355\u8bcd\u6216\u5b50\u8bcd\u5355\u5143\u7684\u6982\u7387\u5206\u5e03\u3002</p> <ul> <li> <p>\u4f18\u70b9\uff1a</p> <ol> <li>\u8bed\u8a00\u65e0\u5173\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u591a\u8bed\u8a00\u6a21\u578b\u3002</li> <li>\u4e0d\u9700\u8981\u9884\u5b9a\u4e49\u7684\u8bcd\u6c47\u8868\uff0c\u8fd9\u4f7f\u5176\u5bf9\u672a\u77e5\u8bcd\u5177\u6709\u9c81\u68d2\u6027\u3002</li> </ol> </li> <li> <p>\u7f3a\u70b9\uff1a</p> <ol> <li>\u4e0e<code>BPE</code>\u6216<code>WordPiece</code>\u76f8\u6bd4\uff0c\u751f\u6210\u7684\u8bcd\u8868\u793a\u53ef\u80fd\u66f4\u957f\u3002</li> <li>\u53ef\u80fd\u96be\u4ee5\u6355\u83b7\u7279\u5b9a\u4e8e\u8bed\u8a00\u7684\u5f62\u6001\u4fe1\u606f\u3002</li> </ol> </li> </ul> <p>\u9009\u62e9\u5408\u9002\u7684\u5206\u8bcd\u65b9\u6cd5</p> <p>\u6700\u4f73\u6807\u8bb0\u5316\u65b9\u6cd5\u53d6\u51b3\u4e8e\u5177\u4f53\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u548c\u6240\u4f7f\u7528\u7684\u8bed\u8a00\u3002<code>BPE</code>\u548c<code>WordPiece</code>\u975e\u5e38\u9002\u5408\u50cf\u82f1\u8bed\u8fd9\u6837\u7684\u5206\u6790\u578b\u8bed\u8a00\uff0c\u800c<code>SentencePiece</code>\u5219\u662f\u591a\u8bed\u8a00\u6a21\u578b\u7684\u66f4\u597d\u9009\u62e9\u3002</p>"},{"location":"chapter2/trainer/callbacks/callbacks/","title":"\u56de\u8c03\u51fd\u6570","text":""},{"location":"chapter2/trainer/callbacks/callbacks/#_1","title":"\u524d\u8a00","text":"<p>\u56de\u8c03\u51fd\u6570\u662f\u7528\u4e8e\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u67e5\u770b\uff08read only\uff09\u8bad\u7ec3\u5668\u884c\u4e3a\u7684\u5de5\u5177\u3002\u5b83\u5141\u8bb8\u5f00\u53d1\u8005\u5728\u8bad\u7ec3\u7684\u4e0d\u540c\u9636\u6bb5\u6267\u884c\u81ea\u5b9a\u4e49\u64cd\u4f5c\uff0c\u5728\u8fd9\u91cc\uff0c\u5f00\u53d1\u8005\u5f80\u5f80\u642d\u914d<code>Tensorboard</code>\u8fdb\u884c\u8bb0\u5f55\u6307\u6807\u3001\u53ef\u89c6\u5316\u6570\u636e\u3001\u8c03\u6574\u8d85\u53c2\u6570\u6216\u8fdb\u884c\u65e9\u505c\u7b49\u884c\u4e3a\u3002</p>"},{"location":"chapter2/trainer/callbacks/callbacks/#_2","title":"\u56de\u8c03\u65b9\u6cd5","text":"<p>HuggingFace\u793e\u533a\u6709\u5f88\u591a\u79cd\u56de\u8c03\u65b9\u6cd5\uff0c\u8fd9\u91cc\u4e3b\u8981\u4ecb\u7ecd<code>TrainerCallback</code>\u00a0\u29c9\u3002</p> <p>\u5728\u81ea\u5b9a\u4e49\u56de\u8c03\u51fd\u6570\u7684\u65f6\u5019\uff1a</p> <ol> <li>\u7ee7\u627f<code>TrainerCallback</code>\u7c7b\uff1b</li> <li>\u6839\u636e\u5b9e\u9645\u9700\u6c42\uff0c\u91cd\u8f7d\u4e0b\u65b9\u7b2c\u4e00\u4e2a\u8868\u5185\u5bf9\u5e94\u7684\u65b9\u6cd5\uff1b</li> <li>\u91cd\u8f7d\u7684\u65b9\u6cd5\u7684\u5f62\u53c2\u5e94\u8be5\u4e3a\u4e0b\u65b9\u7b2c\u4e8c\u4e2a\u8868\u5185\u7684\u53c2\u6570\u540d\u79f0\uff1b</li> <li>\u7f16\u5199\u5177\u4f53\u7684\u903b\u8f91\u3002</li> </ol> \u65b9\u6cd5\u540d\u79f0 \u89e6\u53d1\u65f6\u95f4 <code>on_train_begin</code> \u8bad\u7ec3\u5f00\u59cb\u524d <code>on_train_end</code> \u8bad\u7ec3\u7ed3\u675f\u540e <code>on_epoch_begin</code> \u6bcf\u4e2a epoch \u5f00\u59cb\u524d <code>on_epoch_end</code> \u6bcf\u4e2a epoch \u7ed3\u675f\u540e <code>on_step_begin</code> \u6bcf\u4e2a\u8bad\u7ec3\u6b65\u9aa4\u5f00\u59cb\u524d <code>on_step_end</code> \u6bcf\u4e2a\u8bad\u7ec3\u6b65\u9aa4\u7ed3\u675f\u540e <code>on_substep_end</code> \u68af\u5ea6\u7d2f\u79ef\u8fc7\u7a0b\u4e2d\u6bcf\u4e2a\u5b50\u6b65\u9aa4\u7ed3\u675f\u540e <code>on_optimizer_step</code> \u4f18\u5316\u5668\u6b65\u9aa4\u5b8c\u6210\u540e\uff0c\u68af\u5ea6\u6e05\u96f6\u524d <code>on_pre_optimizer_step</code> \u4f18\u5316\u5668\u6b65\u9aa4\u524d\uff0c\u68af\u5ea6\u88c1\u526a\u540e <code>on_save</code> \u4fdd\u5b58\u68c0\u67e5\u70b9\u540e <code>on_log</code> \u6700\u540e\u4e00\u6b21\u65e5\u5fd7\u8bb0\u5f55\u540e <code>on_evaluate</code> \u8bc4\u4f30\u9636\u6bb5\u7ed3\u675f\u540e <code>on_predict</code> \u6210\u529f\u9884\u6d4b\u540e <code>on_prediction_step</code> \u9884\u6d4b\u6b65\u9aa4\u5b8c\u6210\u540e <code>on_init_end</code> Trainer \u521d\u59cb\u5316\u7ed3\u675f\u540e \u53c2\u6570\u540d\u79f0 \u63cf\u8ff0 <code>args</code> <code>TrainingArguments</code> \u5bf9\u8c61 <code>state</code> <code>TrainerState</code> \u5bf9\u8c61\uff0c\u5305\u542b\u8bad\u7ec3\u72b6\u6001\u4fe1\u606f <code>control</code> <code>TrainerControl</code> \u5bf9\u8c61\uff0c\u7528\u4e8e\u63a7\u5236\u8bad\u7ec3\u6d41\u7a0b <code>model</code> \u8bad\u7ec3\u9636\u6bb5\u7684\u6a21\u578b <code>tokenizer</code> \u7f16\u7801\u6570\u636e\u7684\u5206\u8bcd\u5668 <code>optimizer</code> \u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u7684\u4f18\u5316\u5668 <code>lr_scheduler</code> \u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u5668 <code>train_dataloader</code> \u8bad\u7ec3\u9636\u6bb5\u7684\u8bad\u7ec3\u96c6\u751f\u6210\u5668 <code>eval_dataloader</code> \u9a8c\u8bc1\u9636\u6bb5\u7684\u9a8c\u8bc1\u96c6\u751f\u6210\u5668 <code>metrics</code> \u4e0a\u4e2a\u9636\u6bb5\u4ea7\u751f\u7684\u8bc4\u4f30\u6307\u6807 <code>logs</code> \u65e5\u5fd7\u4fe1\u606f <p>\u4e0b\u9762\u662f\u4e00\u5219\u5728<code>Trainer</code>\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u6ce8\u518c\u81ea\u5b9a\u4e49\u56de\u8c03\u51fd\u6570\u7684\u793a\u4f8b\u3002</p> <p>\u5728\u4f7f\u7528<code>Trainer</code>\u8fdb\u884c\u8bad\u7ec3\u65f6\uff0c\u8bad\u7ec3\u5f00\u59cb\u4f1a\u8f93\u51fa<code>Starting training</code>\uff0c\u8bad\u7ec3\u7ed3\u675f\u4f1a\u8f93\u51fa<code>Finishing training</code>:</p> Python<pre><code>class MyCallback(TrainerCallback):\n    def on_train_begin(self, args, state, control, **kwargs):\n        print(\"Starting training\")\n\n    def on_train_end(self, args, state, control, **kwargs):\n        print('Finishing training')\n\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    callbacks=[MyCallback],\n)\n</code></pre>"},{"location":"chapter2/trainer/callbacks/callbacks/#trainerstate","title":"TrainerState","text":"<p><code>TrainerState</code>\uff1a\u5305\u542b\u8bad\u7ec3\u72b6\u6001\u4fe1\u606f\u7684\u5bf9\u8c61\u3002</p> \u53c2\u6570\u540d\u79f0 \u7c7b\u578b \u9ed8\u8ba4\u503c \u63cf\u8ff0 <code>epoch</code> <code>float</code> <code>None</code> \u4ec5\u5728\u8bad\u7ec3\u671f\u95f4\u8bbe\u7f6e\uff0c\u8868\u793a\u5f53\u524d\u8bad\u7ec3\u6240\u5728\u7684<code>epoch</code>\uff08\u5c0f\u6570\u90e8\u5206\u8868\u793a\u5f53\u524d\u5b8c\u6210\u7684\u767e\u5206\u6bd4\uff09\u3002 <code>global_step</code> <code>int</code> <code>0</code> \u8bad\u7ec3\u671f\u95f4\uff0c\u8868\u793a\u5df2\u5b8c\u6210\u7684\u6b65\u9aa4\u6570\u3002 <code>max_steps</code> <code>int</code> <code>0</code> \u5f53\u524d\u8bad\u7ec3\u671f\u95f4\u8981\u6267\u884c\u7684\u66f4\u65b0\u6b65\u9aa4\u6570\u91cf\u3002 <code>logging_steps</code> <code>int</code> <code>500</code> \u6bcf<code>X</code>\u4e2a\u66f4\u65b0\u6b65\u9aa4\u8bb0\u5f55\u4e00\u6b21\u65e5\u5fd7\u3002 <code>eval_steps</code> <code>int</code> <code>500</code> \u6bcf<code>X</code>\u4e2a\u6b65\u9aa4\u6267\u884c\u4e00\u6b21\u8bc4\u4f30\u3002 <code>save_steps</code> <code>int</code> <code>500</code> \u6bcf<code>X</code>\u4e2a\u66f4\u65b0\u6b65\u9aa4\u4fdd\u5b58\u4e00\u6b21\u68c0\u67e5\u70b9\u3002 <code>train_batch_size</code> <code>int</code> <code>None</code> \u8bad\u7ec3\u6570\u636e\u52a0\u8f7d\u5668\u7684\u6279\u6b21\u5927\u5c0f\u3002 <code>num_input_tokens_seen</code> <code>int</code> <code>0</code> \u8bad\u7ec3\u671f\u95f4\u770b\u5230\u7684\u4ee4\u724c\u6570\u91cf\uff08\u8f93\u5165\u4ee4\u724c\u6570\u91cf\uff0c\u800c\u4e0d\u662f\u9884\u6d4b\u4ee4\u724c\u6570\u91cf\uff09\u3002 <code>total_flos</code> <code>float</code> <code>0</code> \u6a21\u578b\u4ece\u8bad\u7ec3\u5f00\u59cb\u5230\u73b0\u5728\u7684\u603b\u6d6e\u70b9\u8fd0\u7b97\u6b21\u6570\uff08\u5b58\u50a8\u4e3a\u6d6e\u70b9\u6570\u4ee5\u907f\u514d\u6ea2\u51fa\uff09\u3002 <code>log_history</code> <code>List[Dict[str, float]]</code> <code>None</code> \u4ece\u8bad\u7ec3\u5f00\u59cb\u5230\u73b0\u5728\u7684\u65e5\u5fd7\u5217\u8868\u3002 <code>best_metric</code> <code>float</code> <code>None</code> \u8ddf\u8e2a\u6700\u4f73\u6a21\u578b\u65f6\u7684\u6700\u4f73\u6307\u6807\u503c\u3002 <code>best_model_checkpoint</code> <code>str</code> <code>None</code> \u8ddf\u8e2a\u6700\u4f73\u6a21\u578b\u65f6\u7684\u6700\u4f73\u6a21\u578b\u3002 <code>is_local_process_zero</code> <code>bool</code> <code>True</code> \u6b64\u8fdb\u7a0b\u662f\u5426\u4e3a\u672c\u5730\uff08\u4f8b\u5982\uff0c\u5982\u679c\u5728\u591a\u53f0\u673a\u5668\u4e0a\u4ee5\u5206\u5e03\u5f0f\u65b9\u5f0f\u8fdb\u884c\u8bad\u7ec3\uff0c\u5219\u5728\u4e00\u53f0\u673a\u5668\u4e0a\uff09\u4e3b\u8fdb\u7a0b\u3002 <code>is_world_process_zero</code> <code>bool</code> <code>True</code> \u6b64\u8fdb\u7a0b\u662f\u5426\u4e3a\u5168\u5c40\u4e3b\u8fdb\u7a0b\uff08\u5728\u591a\u53f0\u673a\u5668\u4e0a\u4ee5\u5206\u5e03\u5f0f\u65b9\u5f0f\u8fdb\u884c\u8bad\u7ec3\u65f6\uff0c\u8fd9\u4ec5\u5bf9\u4e00\u4e2a\u8fdb\u7a0b\u4e3a<code>True</code>\uff09\u3002 <code>is_hyper_param_search</code> <code>bool</code> <code>False</code> \u6211\u5426\u6b63\u5728\u4f7f\u7528 <code>Trainer.hyperparameter_search</code> \u8fdb\u884c\u8d85\u53c2\u6570\u641c\u7d22\u3002\u8fd9\u5c06\u5f71\u54cd\u6570\u636e\u5728<code>TensorBoard</code>\u4e2d\u7684\u8bb0\u5f55\u65b9\u5f0f\u3002 <code>stateful_callbacks</code> <code>List[StatefulTrainerCallback]</code> <code>None</code> \u9644\u52a0\u5230<code>Trainer</code>\u7684\u56de\u8c03\u51fd\u6570\uff0c\u8fd9\u4e9b\u56de\u8c03\u51fd\u6570\u5e94\u8be5\u4fdd\u5b58\u6216\u6062\u590d\u5176\u72b6\u6001\u3002\u76f8\u5173\u7684\u56de\u8c03\u51fd\u6570\u5e94\u8be5\u5b9e\u73b0<code>state</code>\u548c<code>from_state</code>\u51fd\u6570\u3002"},{"location":"chapter2/trainer/callbacks/callbacks/#trainercontrol","title":"<code>TrainerControl</code>","text":"<p><code>TrainerControl</code>\uff1a\u7528\u4e8e\u63a7\u5236\u8bad\u7ec3\u6d41\u7a0b\u7684\u5bf9\u8c61\u3002</p> \u53c2\u6570\u540d\u79f0 \u63cf\u8ff0 \u9ed8\u8ba4\u503c <code>should_training_stop</code> \u662f\u5426\u4e2d\u65ad\u8bad\u7ec3\u3002\u5982\u679c\u4e3a<code>True</code>\uff0c\u6b64\u53d8\u91cf\u5c06\u4e0d\u4f1a\u88ab\u91cd\u7f6e\u4e3a<code>False</code>\uff0c\u8bad\u7ec3\u5c06\u76f4\u63a5\u505c\u6b62\u3002 <code>False</code> <code>should_epoch_stop</code> \u662f\u5426\u4e2d\u65ad\u5f53\u524d<code>epoch</code>\u3002\u5982\u679c\u4e3a<code>True</code>\uff0c\u6b64\u53d8\u91cf\u5c06\u5728\u4e0b\u4e00\u4e2a<code>epoch</code>\u5f00\u59cb\u65f6\u91cd\u7f6e\u4e3a<code>False</code>\u3002 <code>False</code> <code>should_save</code> \u662f\u5426\u5728\u5f53\u524d\u6b65\u9aa4\u4fdd\u5b58\u6a21\u578b\u3002\u5982\u679c\u4e3a<code>True</code>\uff0c\u6b64\u53d8\u91cf\u5c06\u5728\u4e0b\u4e00\u4e2a\u6b65\u9aa4\u5f00\u59cb\u65f6\u91cd\u7f6e\u4e3a<code>False</code>\u3002 <code>False</code> <code>should_evaluate</code> \u662f\u5426\u5728\u5f53\u524d\u6b65\u9aa4\u8bc4\u4f30\u6a21\u578b\u3002\u5982\u679c\u4e3a<code>True</code>\uff0c\u6b64\u53d8\u91cf\u5c06\u5728\u4e0b\u4e00\u4e2a\u6b65\u9aa4\u5f00\u59cb\u65f6\u91cd\u7f6e\u4e3a<code>False</code>\u3002 <code>False</code> <code>should_log</code> \u662f\u5426\u5728\u5f53\u524d\u6b65\u9aa4\u62a5\u544a\u65e5\u5fd7\u3002\u5982\u679c\u4e3a<code>True</code>\uff0c\u6b64\u53d8\u91cf\u5c06\u5728\u4e0b\u4e00\u4e2a\u6b65\u9aa4\u5f00\u59cb\u65f6\u91cd\u7f6e\u4e3a<code>False</code>\u3002 <code>False</code>"},{"location":"chapter2/trainer/callbacks/callbacks/#_3","title":"\u53c2\u8003\u8d44\u6599","text":"<ul> <li>HuggingFace API callbacks\u56de\u8c03\u51fd\u6570\u00a0\u29c9</li> <li>\u4ec0\u4e48\u662f\u8bad\u7ec3\u5668\u548c\u56de\u8c03\u51fd\u6570\uff1f\u00a0\u29c9</li> </ul>"},{"location":"chapter2/trainer/module2trainer/module2trainer/","title":"Trainer\u8bad\u7ec3\u81ea\u5b9a\u4e49\u6a21\u578b","text":""},{"location":"chapter2/trainer/module2trainer/module2trainer/#_1","title":"\u524d\u8a00","text":"<p>\u7406\u8bba\u4e0a\u6765\u8bb2\uff0c\u57fa\u4e8e<code>torch</code>\u6216<code>tensorflow</code>\u5b9e\u73b0\u7684\u6a21\u578b\uff0c\u5e76\u4e14\u6b63\u786e\u91cd\u8f7d\u5bf9\u5e94\u65b9\u6cd5\uff08<code>forward</code>\u3001<code>from_pretrained</code>\u7b49\u65b9\u6cd5\uff09\uff0c\u90a3\u4e48\u5c31\u53ef\u4ee5\u501f\u52a9<code>Trainer</code>\u8fd9\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\u907f\u5f00\u7e41\u7410\u7684\u4ee3\u7801\u7f16\u5199\uff0c\u63d0\u9ad8\u5de5\u4f5c\u6548\u7387\u3002</p> <p>\u4e0b\u9762\u5c06\u501f\u7528\u52a8\u624b\u5b66\u6df1\u5ea6\u5b66\u4e60\u5185\u7684\u7ebf\u6027\u56de\u5f52\u7684\u7b80\u6d01\u5b9e\u73b0\u6765\u5c01\u88c5\u57fa\u4e8e<code>nn.Module</code>\u5b9e\u73b0\u7684\u6a21\u578b\uff0c\u4ee5\u8fdb\u4e00\u6b65\u4f7f\u7528<code>Trainer</code>\u3002\u5c06\u91cd\u70b9\u8bb2\u89e3\u5c01\u88c5\u6b65\u9aa4\uff0c<code>d2l</code>\u90e8\u5206\u4e0d\u518d\u5c55\u5f00\u3002</p>"},{"location":"chapter2/trainer/module2trainer/module2trainer/#_2","title":"\u4ee3\u7801","text":""},{"location":"chapter2/trainer/module2trainer/module2trainer/#_3","title":"\u5f15\u5165\u51fd\u6570\u5e93","text":"Python<pre><code>import torch\nfrom torch import nn\nfrom d2l import torch as d2l\nfrom transformers import Trainer, TrainingArguments\n\ntrue_w = torch.tensor([2, -3.4])\ntrue_b = 4.2\n</code></pre> <p>\u5728\u8fd9\u91cc\u4eba\u4e3a\u8bbe\u5b9a\u7ebf\u6027\u56de\u5f52\u7684\u771f\u5b9e\u6743\u91cd\u4e3a<code>2</code>\u548c<code>-3.4</code>\uff0c\u504f\u7f6e\u4e3a<code>4.2</code>\uff0c\u63a5\u4e0b\u6765\u7684\u76ee\u6807\u662f\u8ba9\u795e\u7ecf\u7f51\u7edc\u65e0\u9650\u903c\u8fd1\u8fd9\u4e2a\u6743\u91cd\u3002</p>"},{"location":"chapter2/trainer/module2trainer/module2trainer/#_4","title":"\u5b9a\u4e49\u6570\u636e\u96c6","text":"Python<pre><code>class CustDatasetForRegression(torch.utils.data.Dataset):\n    def __init__(self, true_w, true_b, num_samples):\n        self.true_w = true_w\n        self.true_b = true_b\n        self.num_samples = num_samples\n\n        self.features, self.labels = d2l.synthetic_data(true_w, true_b, num_samples)\n\n    def __getitem__(self, idx):\n        item = {\"inputs\": self.features[idx], \"labels\": self.labels[idx]}\n        return item\n\n    def __len__(self):\n        return len(self.features)\n</code></pre> <p>\u5b9a\u4e49\u6570\u636e\u96c6\u65f6\uff0c\u786e\u4fdd\u91cd\u8f7d\u540e\u7684<code>__getitem__</code>\u65b9\u6cd5\u8fd4\u56de\u7684\u5b57\u5178\u7684<code>key</code>\u5bf9\u5e94\u4e8e\u6a21\u578b\u91cd\u8f7d\u540e\u7684<code>forward</code>\u65b9\u6cd5\u91cc\u9762\u7684\u5f62\u53c2\u540d\u79f0\u3002</p> Python<pre><code>data = CustDatasetForRegression(true_w, true_b, 1000)\n</code></pre>"},{"location":"chapter2/trainer/module2trainer/module2trainer/#_5","title":"\u5b9a\u4e49\u6a21\u578b","text":"Python<pre><code>class CustomModelForRegression(nn.Module):\n    def __init__(self):\n        super(CustomModelForRegression, self).__init__()\n        self.net = nn.Sequential(nn.Linear(2, 1))\n\n    def forward(self, inputs, labels=None):\n        logits = self.net(inputs)\n\n        if labels is not None:\n            loss_fn = nn.MSELoss()\n            loss = loss_fn(logits, labels)\n            return {\"logits\": logits, \"loss\": loss}\n        else:\n            return {\"logits\": logits}\n\n    @classmethod\n    def from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs):\n        model = cls(*model_args, **kwargs)\n        state_dict = torch.load(f\"{pretrained_model_name_or_path}/model.bin\")\n        model.load_state_dict(state_dict)\n        return model\n\n    def save_pretrained(self, save_directory):\n        self.to(torch.device(\"cpu\"))\n        torch.save(self.state_dict(), f\"{save_directory}/model.bin\")\n\n    def predict(self, inputs, device):\n        device = device or self.device\n        with torch.no_grad():\n            inputs = inputs.to(device)\n            out = self(inputs, None)\n            return out[\"logits\"].flatten()\n</code></pre> <p>\u81ea\u5b9a\u4e49\u6a21\u578b\u7684\u6b65\u9aa4\uff1a</p> <ol> <li>\u91cd\u8f7d\u524d\u5411\u4f20\u64ad\u903b\u8f91\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5e94\u5f53\u6709\u662f\u5426\u4f20\u5165<code>labels</code>\u7684\u5224\u65ad\uff0c\u65e0\u8bba\u8fd4\u56de\u7684\u662f<code>ModelOutput</code>\u7c7b\uff0c\u8fd8\u662f<code>Python</code>\u7684\u5b57\u5178\uff0c\u90fd\u5e94\u5305\u542b<code>logits</code>\uff0c\u5f53\u6709\u6807\u7b7e\u4f20\u5165\u65f6\uff0c\u8fd8\u5e94\u6709<code>loss</code>\u5b57\u6bb5\u3002</li> <li>\u91cd\u8f7d\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5\u3002</li> <li>\u91cd\u8f7d\u4fdd\u5b58\u6a21\u578b\u7684\u65b9\u6cd5\u3002</li> <li>\u91cd\u8f7d\u7528\u4e8e\u9884\u6d4b\u7684\u65b9\u6cd5\u3002</li> </ol>"},{"location":"chapter2/trainer/module2trainer/module2trainer/#_6","title":"\u521b\u5efa\u6a21\u578b","text":"Python<pre><code>model = CustomModelForRegression()\n</code></pre> model<pre><code>CustomModelForRegression(\n  (net): Sequential(\n    (0): Linear(in_features=2, out_features=1, bias=True)\n  )\n)\n</code></pre>"},{"location":"chapter2/trainer/module2trainer/module2trainer/#_7","title":"\u521b\u5efa\u8bad\u7ec3\u5668","text":"Python<pre><code>optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n</code></pre> Python<pre><code>training_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=20,\n    logging_strategy=\"epoch\",\n    per_device_train_batch_size=512,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=data,\n    optimizers=(optimizer, None),\n)\n\ntrainer.train()\n</code></pre> Step Training Loss Step Training Loss Step Training Loss Step Training Loss 2 31.782100 12 1.636300 22 0.000100 32 0.000100 4 21.786800 14 0.325800 24 0.000100 34 0.000100 6 14.083900 16 0.008600 26 0.000100 36 0.000100 8 8.247200 18 0.000300 28 0.000100 38 0.000100 10 4.171000 20 0.000100 30 0.000100 40 0.000100"},{"location":"chapter2/trainer/module2trainer/module2trainer/#_8","title":"\u4fdd\u5b58\u4e0e\u52a0\u8f7d","text":"Python<pre><code>model.save_pretrained(\"./model/\")\n\nmodel.from_pretrained(\"./model/\")\n</code></pre>"},{"location":"chapter2/trainer/module2trainer/module2trainer/#_9","title":"\u63a8\u7406","text":"print(model.net[0].weight, \"\\n\", model.net[0].bias)<pre><code>Parameter containing:\ntensor([[ 1.9996, -3.4005]], requires_grad=True)\n Parameter containing:\ntensor([4.2004], requires_grad=True)\n</code></pre> Python<pre><code>model.predict(torch.tensor([[2.0, 3.0], [6.0, 7.0]]), torch.device(\"cpu\"))\n</code></pre> Python<pre><code>tensor([-2.0019, -7.6055])\n</code></pre> <p>\u53ef\u4ee5\u770b\u5230\u57fa\u672c\u548c\u7b54\u6848\u543b\u5408\u4e86\u3002</p>"},{"location":"chapter2/trainer/module2trainer/module2trainer/#_10","title":"\u53c2\u8003\u8d44\u6599","text":"<ul> <li> <p>\u52a8\u624b\u5b66\u6df1\u5ea6\u5b66\u4e60</p> <p>\u7ebf\u6027\u56de\u5f52\u7684\u7b80\u5355\u5b9e\u73b0\u00a0\u29c9</p> </li> <li> <p>\u6607\u817e\u793e\u533a</p> <p>\u5c01\u88c5nn.Module\u5e76\u9001\u5165Trainer\u00a0\u29c9</p> </li> <li> <p>\u535a\u5ba2\u56ed</p> <p>HuggingFace\u9047\u5230\u7684\u5751\u00a0\u29c9</p> </li> <li> <p>DBGPT</p> <p>\u8d22\u52a1\u62a5\u8868\u5546\u52a1\u5206\u6790\u673a\u5668\u4eba\u00a0\u29c9</p> </li> </ul>"},{"location":"chapter2/trainer/trainer/trainer/","title":"Trainer\u5de5\u5177\u4ecb\u7ecd","text":""},{"location":"chapter2/trainer/trainer/trainer/#_1","title":"\u524d\u8a00","text":"<p><code>HuggingFace</code>\u7684<code>Trainer</code>\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u5b83\u7b80\u5316\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u63a5\u53e3\uff0c\u53ef\u4ee5\u8f7b\u677e\u5730\u8bad\u7ec3\u5404\u79cd\u6a21\u578b\u3002</p> <p>\u4f20\u7edf\u4e0a\uff0c\u8bad\u7ec3\u6a21\u578b\u5305\u542b\u4ee5\u4e0b\u57fa\u672c\u6b65\u9aa4\uff1a</p> <ul> <li>\u5b9a\u4e49\u635f\u5931\u51fd\u6570</li> <li>\u8bbe\u7f6e\u8bad\u7ec3\u6a21\u5f0f</li> <li>\u8fed\u4ee3\u6570\u636e\u96c6</li> <li>\u8ba1\u7b97\u635f\u5931</li> <li>\u6267\u884c\u53cd\u5411\u4f20\u64ad</li> <li>\u8f93\u51fa\u8bad\u7ec3\u65e5\u5fd7</li> </ul> <p>\u7136\u800c\uff0c\u968f\u7740\u8bad\u7ec3\u6280\u5de7\u9700\u6c42\u7684\u589e\u52a0\uff0c\u4f8b\u5982\u4ee5\u4e0b\u9700\u6c42\uff1a</p> <ul> <li>\u6743\u91cd\u8870\u51cf</li> <li>\u5206\u5e03\u5f0f\u8bad\u7ec3</li> <li>\u52a8\u6001\u6b65\u957f</li> <li>\u52a8\u6001\u5b66\u4e60\u7387</li> <li>\\(\\cdots\\)</li> </ul> <p>\u5f00\u53d1\u8005\u9700\u8981\u7f16\u5199\u5927\u91cf\u7684\u4ee3\u7801\uff0c\u8fd9\u4f1a\u8ba9\u5de5\u7a0b\u53d8\u5f97\u975e\u5e38\u590d\u6742\u3002</p> <p>Trainer</p> <p><code>Trainer</code> \u7684\u4f18\u52bf\u5728\u4e8e\u5176\u5c01\u88c5\u4e86\u8fd9\u4e9b\u590d\u6742\u7684\u64cd\u4f5c\uff0c\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u4e13\u6ce8\u4e8e\u6a21\u578b\u672c\u8eab\uff0c\u800c\u65e0\u9700\u62c5\u5fc3\u5e95\u5c42\u5b9e\u73b0\u7ec6\u8282\u3002\u6240\u4ee5\u629b\u5f00\u7e41\u6742\u7684\u8bad\u7ec3\u4ee3\u7801\uff0c\u4f7f\u7528<code>Trainer</code>\u662f\u4e00\u4ef6\u591a\u4e48\u7701\u65f6\u7701\u529b\u7684\u4e8b\u60c5\uff0c\u6240\u4ee5\u6295\u5165<code>Trainer</code>\u7684\u6000\u62b1\u5427\u3002</p>"},{"location":"chapter2/trainer/trainer/trainer/#trainer-api","title":"Trainer API","text":"<p><code>Trainer</code>\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\u90fd\u53ef\u4ee5\u5728Trainer API\u00a0\u29c9\u8fdb\u884c\u67e5\u9605\u3002</p> \u53c2\u6570\u540d\u79f0 \u6570\u636e\u7c7b\u578b \u6ce8\u91ca <code>model</code> <code>PreTrainedModel</code> \u6a21\u578b\u5b9e\u4f8b <code>nn.Module</code> <code>args</code> <code>TrainingArguments</code> \u8bad\u7ec3\u65f6\u7684\u8d85\u53c2\u6570 <code>data_collator</code> <code>DataCollator</code> \u6570\u636e\u6574\u7406\u5668 <code>train_dataset</code> <code>torch.utils.data.Dataset</code> \u8bad\u7ec3\u96c6\u3002\u5982\u679c\u63a5\u6536\u7684\u662f<code>datasets.Dataset</code>\uff0c\u8bad\u7ec3\u9636\u6bb5\u6570\u636e\u96c6\u4e2d\u4e0d\u88ab\u4f7f\u7528\u7684\u5217\u90fd\u4f1a\u88ab\u5220\u9664 <code>torch.utils.data.IterableDataset</code> <code>datasets.Dataset</code> <code>eval_dataset</code> <code>torch.utils.data.Dataset</code> \u8bc4\u4f30\u96c6\u3002\u5982\u679c\u63a5\u6536\u7684\u662f<code>datasets.Dataset</code>\uff0c\u8bc4\u4f30\u9636\u6bb5\u6570\u636e\u96c6\u4e2d\u4e0d\u88ab\u4f7f\u7528\u7684\u5217\u90fd\u4f1a\u88ab\u5220\u9664 <code>datasets.Dataset</code> <code>tokenizer</code> <code>PreTrainedTokenizerBase</code> \u5206\u8bcd\u5668\u5b9e\u4f8b\u3002\u5728\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u6279\u6b21\u65f6\uff0c\u5206\u8bcd\u5668\u4f1a\u5c06\u6570\u636e\u586b\u5145\u5230\u6700\u5927\u957f\u5ea6\uff1b\u5728\u4fdd\u5b58\u6a21\u578b\u65f6\uff0c\u5206\u8bcd\u5668\u6587\u4ef6\u4e5f\u5c06\u88ab\u540c\u65f6\u4fdd\u5b58 <code>model_init</code> <code>Callable</code> \u7528\u4e8e\u521d\u59cb\u5316\u6a21\u578b\u7684\u51fd\u6570 <code>compute_metrics</code> <code>Callable[[EvalPrediction], Dict]</code> \u7528\u4e8e\u8ba1\u7b97\u8bc4\u4f30\u6307\u6807\u7684\u51fd\u6570\u3002\u8be5\u51fd\u6570\u8f93\u5165\u4e3a<code>EvalPrediction</code>\u7c7b\uff0c\u8fd4\u56de\u7ed3\u679c\u5fc5\u987b\u4e3a\u5305\u542b\u6307\u6807\u53ca\u5176\u5177\u4f53\u6570\u503c\u7684\u5b57\u5178 <code>callbacks</code> <code>List[TrainerCallback]</code> \u56de\u8c03\u51fd\u6570\u5217\u8868 <code>optimizers</code> <code>Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]</code> \u7528\u4e8e\u8bad\u7ec3\u7684\u4f18\u5316\u5668\u548c\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u3002\u9ed8\u8ba4\u4e3a(<code>None</code>, <code>None</code>)\uff0c\u5373\u5bf9\u5e94\uff08<code>AdamW</code>\u4f18\u5316\u5668\u5b9e\u4f8b\uff0c\u7ebf\u6027\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\uff09 <code>preprocess_logits_for_metrics</code> <code>Callable[[torch.Tensor, torch.Tensor], torch.Tensor]</code> \u7528\u4e8e\u5728\u8bc4\u4f30\u6b65\u9aa4\u4e2d\u5bf9\u6a21\u578b\u8f93\u51fa\u7684\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u9884\u5904\u7406\u7684\u51fd\u6570\u3002\u8be5\u51fd\u6570\u6700\u540e\u8fd4\u56de\u8fd0\u7b97\u8fc7\u540e\u7684\u7f6e\u4fe1\u5ea6\uff0c\u5e76\u5c06\u7f6e\u4fe1\u5ea6\u548c\u6807\u7b7e\u4f20\u9012\u7ed9<code>compute_metrics</code>"},{"location":"chapter2/trainer/trainer/trainer/#_2","title":"\u4f7f\u7528\u6848\u4f8b","text":"<p>\u5f85\u8865\u5145</p>"},{"location":"chapter2/trainer/trainer/trainer/#_3","title":"\u53c2\u8003\u8d44\u6599","text":"<ol> <li>HuggingFace API Trainer\u00a0\u29c9</li> <li>\u56de\u8c03\u51fd\u6570</li> </ol>"},{"location":"chapter2/trainer/trainer_example/trainer_example/","title":"Trainer\u5de5\u5177\u5b9e\u6218","text":""},{"location":"chapter2/trainer/trainer_example/trainer_example/#_1","title":"\u524d\u8a00","text":"<p>\u57fa\u4e8e\u76f8\u5bf9\u72ec\u7acb\u7684\u5404\u4e2a\u524d\u6587\uff1a</p> <ol> <li>Trainer\u5de5\u5177\u4ecb\u7ecd</li> <li>Trainer\u8bad\u7ec3\u81ea\u5b9a\u4e49\u6a21\u578b</li> <li>Callbacks\u56de\u8c03\u51fd\u6570</li> </ol> <p>\u672c\u6587\u5e0c\u671b\u7efc\u5408\u524d\u6587\u501f\u52a9\u4f7f\u7528<code>Word2Vec</code>\u7684\u5177\u4f53\u6848\u4f8b\u8fdb\u884c<code>Trainer</code>\u5de5\u5177\u5b9e\u6218\u3002</p>"},{"location":"chapter2/trainer/trainer_example/trainer_example/#_2","title":"\u4ee3\u7801","text":""},{"location":"chapter2/trainer/trainer_example/trainer_example/#_3","title":"\u5bfc\u5165\u51fd\u6570\u5e93","text":"Python<pre><code>import jieba\nimport pandas as pd\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom transformers import TrainingArguments, Trainer, TrainerCallback\nfrom torch.utils.tensorboard import SummaryWriter\n</code></pre>"},{"location":"chapter2/trainer/trainer_example/trainer_example/#_4","title":"\u5b9a\u4e49\u8bcd\u5178","text":"Python<pre><code>class Vocab:\n    def __init__(self, vocab_file, stop_words_file=None):\n        self.stop_words_file = self.load_stop_words(stop_words_file)\n        self.idx2word, self.word2idx, self.words = self.load_vocab(vocab_file)\n        self.word_size = len(self.words)\n        self.vocab_size = len(self.idx2word)\n\n    def load_vocab(self, vocab_file):\n        idx2word = {}\n        word2idx = {}\n\n        words = []\n        contents = pd.read_csv(vocab_file, encoding=\"GBK\", header=None)\n\n        for idx, row in contents.iterrows():\n            line = row[0]\n            if not self.stop_words_file:\n                current_line_words = [\n                    word for word in jieba.cut(line) if word not in self.stop_words_file\n                ]\n            else:\n                current_line_words = list(jieba.cut(line))\n            words.extend(current_line_words)\n\n        for idx, word in enumerate(set(words)):\n            idx2word[idx] = word\n            word2idx[word] = idx\n        return idx2word, word2idx, words\n\n    def load_stop_words(self, stop_words_file):\n        if stop_words_file is None:\n            return set()\n        else:\n            with open(stop_words_file, \"r\") as f:\n                return set(f.read().splitlines())\n\n    def get_idx(self, word):\n        return self.word2idx[word]\n\n    def get_word(self, idx):\n        return self.idx2word[idx]\n</code></pre> <p>\u8be5\u5b57\u5178\u7c7b\u5b9e\u73b0\u4e86\uff1a</p> <ol> <li><code>load_vocab</code>\u65b9\u6cd5\u8fd4\u56de\uff1a<ol> <li><code>idx2word</code>\uff1a\u7d22\u5f15\u5230\u8bcd\u5bf9\u3002</li> <li><code>word2idx</code>\uff1a\u8bcd\u5230\u7d22\u5f15\u5bf9\u3002</li> <li><code>words</code>\uff1a\u6570\u636e\u96c6\u4e2d\u6309\u8bcd\u51fa\u73b0\u7684\u987a\u5e8f\u6392\u5217\u7684\u6240\u6709\u8bcd\u3002</li> </ol> </li> <li><code>load_stop_words</code>\u65b9\u6cd5\u8fd4\u56de\u6240\u6709\u505c\u7528\u8bcd\u7ec4\u6210\u7684\u5143\u7ec4\u3002</li> <li><code>get_idx</code>\u65b9\u6cd5\u6839\u636e\u8bcd\u8fd4\u56de\u5bf9\u5e94\u7684<code>idx</code>\u3002</li> <li><code>get_word</code>\u65b9\u6cd5\u6839\u636e<code>idx</code>\u8fd4\u56de\u5bf9\u5e94\u7684\u8bcd\u3002</li> </ol> Python<pre><code>vocab = Vocab(\"./\u6570\u5b66\u539f\u59cb\u6570\u636e.csv\", \"./stopwords.txt\")\n</code></pre> vocab.word_size, vocab.vocab_size<pre><code>(152832, 5296)\n</code></pre>"},{"location":"chapter2/trainer/trainer_example/trainer_example/#_5","title":"\u5b9a\u4e49\u6570\u636e\u96c6","text":"Python<pre><code>class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, ngram: int, vocab: Vocab):\n        self.ngram = ngram\n        self.vocab = vocab\n        self.word_size = vocab.word_size\n        self.vocab_size = vocab.vocab_size\n\n    def __len__(self):\n        return self.word_size - 2 * self.ngram - 1\n\n    def __getitem__(self, idx):\n        left_idx = idx\n        right_idx = idx + 2 * self.ngram + 1\n        words = self.vocab.words[left_idx:right_idx]\n        current_word = words.pop(self.ngram)\n        label = self.vocab.get_idx(current_word)\n\n        another_word = [self.vocab.get_idx(word) for word in words]\n        return {\n            \"inputs\": torch.tensor(another_word, dtype=torch.long),\n            \"labels\": torch.tensor(label, dtype=torch.long),\n        }\n</code></pre> Python<pre><code>data = MyDataset(2, vocab)\ndata_iter = torch.utils.data.DataLoader(data, batch_size=512, shuffle=True)\n</code></pre>"},{"location":"chapter2/trainer/trainer_example/trainer_example/#_6","title":"\u5b9a\u4e49\u795e\u7ecf\u7f51\u7edc","text":"Python<pre><code>class Net(nn.Module):\n    def __init__(self, vocab_size, embedding_size):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.embedding_size = embedding_size\n\n        self.model = nn.Sequential(\n            nn.Embedding(\n                vocab_size,\n                embedding_size,\n            ),\n            nn.Linear(\n                embedding_size,\n                vocab_size,\n                bias=True,\n            ),\n        )\n\n    def forward(self, inputs, labels=None):\n\n        loss_fn = nn.CrossEntropyLoss()\n        batch_size, ngram = inputs.shape\n        # [batch_size, ngram] -&gt; [batch_size * ngram]\n        inputs = inputs.flatten()\n        # [batch_size * ngram] -&gt; [batch_size * ngram, vocab_size]\n        inputs_logits = self.model(inputs)\n        # [batch_size * ngram, vocab_size] -&gt; [batch_size, ngram, vocab_size]\n        inputs_logits = inputs_logits.reshape(batch_size, ngram, self.vocab_size)\n        # [batch_size, ngram, vocab_size] -&gt; [batch_size, vocab_size]\n        inputs_logits = torch.mean(inputs_logits, dim=1)\n        if labels is not None:\n            # [batch_size, vocab_size] \u548c [batch_size, vocab_size]\n            loss = loss_fn(inputs_logits, labels)\n            return {\"logits\": inputs_logits, \"loss\": loss}\n        else:\n            return {\"logits\": inputs_logits}\n</code></pre> Python<pre><code>model = Net(vocab.vocab_size, 512)\n</code></pre>"},{"location":"chapter2/trainer/trainer_example/trainer_example/#_7","title":"\u5b9a\u4e49\u56de\u8c03\u51fd\u6570","text":"Python<pre><code>class MyCallBacks(TrainerCallback):\n\n    def on_train_begin(self, args, state, control, model, optimizer, lr_scheduler, **kwargs):\n        with SummaryWriter('./word2vec/run') as writer:\n            writer.add_graph(model, torch.rand(1, 4))\n        print(\"\\nStarting training\")\n        print(f\"\\nUsing optimizer: {optimizer}\")\n        print(f\"\\nUsing lr_scheduler: {lr_scheduler}\")\n\n    def on_train_end(self, args, state, control, optimizer, **kwargs):\n        print(f\"\\nlr: {optimizer.param_groups[0]['lr']}\")\n\n    def on_save(self, args, state, control, **kwargs):\n        print(\"\\nSaving model\")\n</code></pre> <ol> <li>\u5728\u8bad\u7ec3\u5f00\u59cb\u65f6\uff1a<ol> <li>\u4f7f\u7528<code>TensorBoard</code>\u5de5\u5177\u8bb0\u5f55\u56fe\u7ed3\u6784\u3002</li> <li>\u8f93\u51fa<code>Starting training</code>\u3002</li> <li>\u8f93\u51fa\u4f18\u5316\u5668\u5b9e\u4f8b\u3002</li> <li>\u8f93\u51fa\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u5b9e\u4f8b\u3002</li> </ol> </li> <li>\u5728\u8bad\u7ec3\u7ed3\u675f\u65f6\uff1a\u8f93\u51fa\u5f53\u524d\u5b66\u4e60\u7387\u3002</li> <li>\u5728\u4fdd\u5b58\u6a21\u578b\u65f6\uff1a\u8f93\u51fa<code>Saving model</code>\u3002</li> </ol>"},{"location":"chapter2/trainer/trainer_example/trainer_example/#_8","title":"\u5b9a\u4e49\u8d85\u53c2","text":"Python<pre><code>training_args = TrainingArguments(\n    output_dir=\"./word2vec\",\n    num_train_epochs=3,\n    logging_strategy=\"steps\",\n    logging_dir='./word2vec/run'\n    save_strategy=\"epoch\",\n    use_cpu=False,\n    save_total_limit=3,\n)\n</code></pre>"},{"location":"chapter2/trainer/trainer_example/trainer_example/#_9","title":"\u5b9a\u4e49\u8bad\u7ec3\u5668","text":"Python<pre><code>trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=data,\n    optimizers=(torch.optim.SGD(model.parameters(), 0.05), None),\n    callbacks=[MyCallBacks],\n)\n</code></pre> Python<pre><code>trainer.train()\n</code></pre> Python<pre><code>Starting training\n\nUsing optimizer: AcceleratedOptimizer (\nParameter Group 0\n    dampening: 0\n    differentiable: False\n    foreach: None\n    fused: None\n    initial_lr: 0.05\n    lr: 0.05\n    maximize: False\n    momentum: 0\n    nesterov: False\n    weight_decay: 0\n)\n\nUsing lr_scheduler: &lt;torch.optim.lr_scheduler.LambdaLR object at 0xffff4bcb5520&gt;\n</code></pre> \u53d8\u91cf\u53ef\u89c6\u5316\u7f51\u7edc\u7ed3\u6784\u5386\u53f2\u8bb0\u5f55"},{"location":"chapter2/trainer/trainer_example/trainer_example/#_10","title":"\u4fdd\u5b58\u6a21\u578b","text":"Python<pre><code>torch.save(model.state_dict(), \"./word2vec.pth\")\n</code></pre>"},{"location":"chapter2/trainer/trainer_example/trainer_example/#_11","title":"\u63a8\u7406","text":"Python<pre><code>model.eval()\n</code></pre> Python<pre><code>def cos(a, b):\n    return a.dot(b) / (a.norm() * b.norm())\n</code></pre> <p>\u5728\u8fd9\u91cc\u8bcd\u5411\u91cf\u7684\u76f8\u4f3c\u5ea6\u91cf\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u3002</p> Python<pre><code>encoder = model.model[0]\n\ntoken = \"\u7b97\u672f\"\nembedding1 = encoder(torch.tensor([vocab.get_idx(token)], device=\"cpu\"))\n\ntoken2similarity = {}\n</code></pre> Python<pre><code>for idx, word in vocab.idx2word.items():\n    embedding2 = encoder(torch.tensor([idx], device=\"cpu\"))\n    cos_similarity = cos(embedding1.flatten(), embedding2.flatten()).item()\n    token2similarity[word] = cos_similarity\n\nsorted(token2similarity, key=token2similarity.get, reverse=True)[:10]\n</code></pre> Python<pre><code>['\u7b97\u672f', '\u4e00\u5143\u65b9\u7a0b', '\u5bfc\u6570', '\u5efa\u6a21', '\u53ea\u53d6', 'p1', '\u7c7b\u578b', '\u8868\u8ff0', '\u5404\u7c7b', '\u6247\u5f62']\n</code></pre>"},{"location":"chapter2/trainer/trainer_example/trainer_example/#_12","title":"\u53c2\u8003\u8d44\u6599","text":"<ol> <li>word2vec \u8bcd\u5411\u91cf!\u624b\u5199\u4ee3\u7801!\u00a0\u29c9</li> </ol>"},{"location":"chapter3/peft_index/","title":"\u7d22\u5f15","text":"<p>\u4e3b\u9875</p> <ul> <li><code>PEFT</code>\u7b80\u4ecb</li> <li><code>LORA</code>\u4f4e\u79e9\u5fae\u8c03\u539f\u7406\u4ecb\u7ecd</li> <li><code>AdaLoRA</code>\u4ecb\u7ecd</li> <li><code>IA3</code>\u4ecb\u7ecd</li> <li><code>Prefix-Tuning</code>\u4ecb\u7ecd</li> <li><code>Prompt-Tuning</code>\u4ecb\u7ecd</li> <li><code>P-Tuning</code>\u4ecb\u7ecd</li> </ul>"},{"location":"chapter3/adalora_tour/adalora_tour/","title":"AdaLoRA: \u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u9002\u5e94\u4f4e\u79e9\u9002\u914d","text":""},{"location":"chapter3/adalora_tour/adalora_tour/#_1","title":"\u524d\u8a00","text":"<p>\u5728 LoRA \u7684\u57fa\u7840\u4e0a\uff0c\u5fae\u8f6f\u7814\u7a76\u9662\u4e0e\u666e\u6797\u65af\u987f\u5927\u5b66\u3001\u4f50\u6cbb\u4e9a\u7406\u5de5\u5b66\u9662\u7684\u7814\u7a76\u8005\u4eec\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86AdaLoRA (Adaptive Low-Rank Adaptation)\u00a0\u29c9\u65b9\u6cd5\u3002</p>"},{"location":"chapter3/adalora_tour/adalora_tour/#_2","title":"\u6838\u5fc3\u601d\u60f3","text":"<p>AdaLoRA\u65e8\u5728\u89e3\u51b3 LoRA \u4e2d\u5b58\u5728\u7684\u4e00\u4e9b\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4e0d\u540c\u6743\u91cd\u77e9\u9635\u7684\u79e9\u6765\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u53c2\u6570\u9002\u914d\u3002</p>"},{"location":"chapter3/adalora_tour/adalora_tour/#_3","title":"\u6280\u672f\u7ec6\u8282","text":""},{"location":"chapter3/adalora_tour/adalora_tour/#svd","title":"<code>SVD</code> \u77e9\u9635\u4f4e\u79e9\u5206\u89e3","text":"<ul> <li> <p>\u5b9a\u4e49</p> <ul> <li>\u5947\u5f02\u503c\u5206\u89e3\uff08Singular Value Decomposition, SVD\uff09\u662f\u4e00\u79cd\u5728\u6570\u5b66\u548c\u4fe1\u53f7\u5904\u7406\u4e2d\u5e38\u7528\u7684\u77e9\u9635\u5206\u89e3\u6280\u672f\u3002</li> <li>\u5b83\u5c06\u4efb\u610f\u4e00\u4e2a\u77e9\u9635\u5206\u89e3\u4e3a\u4e09\u4e2a\u7279\u5b9a\u7684\u77e9\u9635\u4e4b\u95f4\u7684\u4e58\u79ef\uff1a\u5de6\u5947\u5f02\u5411\u91cf\u77e9\u9635\u3001\u5947\u5f02\u503c\u77e9\u9635\u548c\u53f3\u5947\u5f02\u5411\u91cf\u77e9\u9635\u3002</li> <li>\u8be5\u8fc7\u7a0b\u5982\u4e0a\u56fe\u6240\u793a\u3002</li> </ul> </li> <li> <p>\u6570\u5b66\u8868\u793a\uff1a\u5bf9\u4e8e\u4efb\u610f\u4e00\u4e2a\u77e9\u9635 \\(A\\) , SVD \u8868\u793a\u4e3a\u4e0b\u5f0f\uff0c\u5176\u4e2d\uff0c\\(U\\) \u548c \\(V\\) \u662f\u6b63\u4ea4\u77e9\u9635\uff0c\u5206\u522b\u8868\u793a\u5de6\u53f3\u5947\u5f02\u5411\u91cf\uff0c\\(\\Sigma\\) \u662f\u5bf9\u89d2\u77e9\u9635\uff0c\u5bf9\u89d2\u7ebf\u4e0a\u7684\u5143\u7d20\u662f\u5947\u5f02\u503c\u3002</p> </li> </ul> \\[ A = U\\Sigma V^T \\tag{1} \\] <ul> <li>\u5e94\u7528<ul> <li>\u5728\u6570\u636e\u79d1\u5b66\u548c\u673a\u5668\u5b66\u4e60\u4e2d\uff0cSVD \u5e38\u7528\u4e8e\u964d\u7ef4\u3001\u6570\u636e\u538b\u7f29\u3001\u566a\u58f0\u8fc7\u6ee4\u7b49\u3002</li> <li>\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\uff0cSVD \u5e38\u7528\u4e8e\u63d0\u53d6\u6587\u672c\u6570\u636e\u7684\u6f5c\u5728\u8bed\u4e49\u7ed3\u6784\u3002</li> </ul> </li> </ul>"},{"location":"chapter3/adalora_tour/adalora_tour/#_4","title":"\u516c\u5f0f\u8bb2\u89e3","text":"\\[ W = W_{0} + \\Delta W = W_{0} + P\\Lambda Q \\tag{2} \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(W_{0}\\) \u662f\u539f\u59cb\u9884\u8bad\u7ec3\u6743\u91cd\u77e9\u9635\u3002</li> <li>\\(\\Lambda \\in \\mathbb{R}^{r\\times r}\\) \u662f\u5bf9\u89d2\u77e9\u9635\uff0c\u5305\u542b\u5947\u5f02\u503c\u3002</li> <li>\\(P \\in \\mathbb{R}^{d_1\\times r}\\) \u662f\u5de6\u5947\u5f02\u5411\u91cf\u77e9\u9635\u3002</li> <li>\\(Q \\in \\mathbb{R}^{r\\times d_2}\\) \u662f\u53f3\u5947\u5f02\u5411\u91cf\u77e9\u9635\u3002</li> </ul> <p>\u5173\u952e\u6539\u8fdb\u5728\u4e8e\u6b63\u4ea4\u6027\u7ea6\u675f\u3002\u4e3a\u4e86\u786e\u4fdd \\(P\\) \u548c \\(Q\\) \u7684\u6b63\u4ea4\u6027\uff0cAdaLoRA \u5f15\u5165\u4e86\u4e00\u4e2a\u6b63\u5219\u9879\uff1a</p> \\[ R(P,Q) = |P^T P - I|^2_F + |QQ^T - I|^2_F \\tag{3} \\] <p>\u8fd9\u4e2a\u6b63\u5219\u9879\u786e\u4fdd \\(P\\) \u548c \\(Q\\) \u4fdd\u6301\u6b63\u4ea4\uff0c\u8fd9\u5bf9\u4e8e\u7ef4\u6301 SVD \u7684\u6027\u8d28\u5f88\u91cd\u8981\u3002</p> <p>Note</p> <p>\u4e0a\u8ff0\u7684\u516c\u5f0f\u8bb2\u89e3\u53ef\u80fd\u6709\u70b9\u62bd\u8c61\u6666\u6da9\uff0c\u4f46\u662f\u6211\u4eec\u53ef\u4ee5\u628a\u5b83\u7406\u89e3\u4e3a\u4e00\u4e2a\u66f4\u7cbe\u7ec6\u7684\u8c03\u5473\u7cfb\u7edf\uff1a</p> <ul> <li>\\(W_{0}\\) \u662f\u57fa\u672c\u83dc\u54c1\u3002</li> <li>\\(P\\)\uff0c\\(\\Lambda\\)\uff0c\u548c \\(Q\\) \u7ec4\u5408\u8d77\u6765\u5f62\u6210\u4e86\u4e00\u4e2a\u66f4\u590d\u6742\u7684\u8c03\u5473\u65b9\u6848\u3002</li> </ul> <p>\u60f3\u8c61 \\(P\\) \u548c \\(Q\\) \u662f\u4e0d\u540c\u7c7b\u578b\u7684\u9999\u6599,\u800c \\(\\Lambda\\) \u63a7\u5236\u6bcf\u79cd\u9999\u6599\u7684\u7528\u91cf\u3002AdaLoRA\u7684\u5de7\u5999\u4e4b\u5904\u5728\u4e8e\uff0c\u5b83\u53ef\u4ee5\u81ea\u52a8\u8c03\u6574\u6bcf\u79cd\u9999\u6599\u7684\u91cd\u8981\u6027(\u901a\u8fc7\u8c03\u6574 \\(\\Lambda\\) \u4e2d\u7684\u503c)\uff0c\u5c31\u50cf\u4e00\u4e2a\u7ecf\u9a8c\u4e30\u5bcc\u7684\u53a8\u5e08\u77e5\u9053\u54ea\u79cd\u8c03\u6599\u66f4\u80fd\u63d0\u5347\u83dc\u54c1\u7684\u98ce\u5473\u3002</p> <p>AdaLoRA \u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u7279\u6b8a\u7684\u54c1\u63a7\u673a\u5236\uff1a</p> \\[ R(P,Q) = |P^T P - I|^2_F + |QQ^T - I|^2_F  \\tag{3} \\] <p>\u8fd9\u4e2a\u770b\u4f3c\u590d\u6742\u7684\u516c\u5f0f\u5176\u5b9e\u5c31\u662f\u786e\u4fdd\u6211\u4eec\u7684\"\u9999\u6599\"( \\(P\\) \u548c \\(Q\\) )\u4fdd\u6301\u7eaf\u51c0,\u4e0d\u4f1a\u76f8\u4e92\u5e72\u6270\u3002\u5c31\u50cf\u5728\u70f9\u996a\u4e2d\uff0c\u6211\u4eec\u8981\u786e\u4fdd\u6bcf\u79cd\u8c03\u6599\u90fd\u4fdd\u6301\u5176\u72ec\u7279\u7684\u98ce\u5473\uff0c\u4e0d\u4f1a\u76f8\u4e92\u63a9\u76d6\u3002</p> <p>\u901a\u8fc7\u8fd9\u4e9b\u6539\u8fdb\uff0cAdaLoRA\u80fd\u591f\u66f4\u7cbe\u786e\u3001\u66f4\u9ad8\u6548\u5730\"\u8c03\u5473\"\uff0c\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u65b0\u4efb\u52a1\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u6709\u7684\"\u57fa\u7840\u98ce\u5473\"\u3002</p>"},{"location":"chapter3/adalora_tour/adalora_tour/#_5","title":"\u91cd\u8981\u6027\u5efa\u6a21","text":"<p>AdaLoRA \u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u91cd\u8981\u6027\u5ea6\u91cf\u6807\u51c6\uff0c\u7528\u4e8e\u91cf\u5316\u6bcf\u4e2a\u4e09\u5143\u7ec4 \\(\\mathcal{G}_{k,i} = \\{P_{k,*i}, \\lambda_{k,i}, Q_{k,i*}\\}\\)  \u5bf9\u6a21\u578b\u6027\u80fd\u7684\u8d21\u732e\uff1a</p> \\[ S_{k,i} = s(\\lambda_{k,i}) + \\frac{1}{d_1}\\sum_{j=1}^{d_1}s(P_{k,ji}) + \\frac{1}{d_2}\\sum_{j=1}^{d_2}s(Q_{k,ij}) \\tag{4} \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(S_{k,i}\\) \u8868\u793a\u91cd\u8981\u6027\u5f97\u5206</li> <li>\\(s(\\lambda_{k,i})\\) \u662f\u5947\u5f02\u503c\uff08\u5bf9\u89d2\u77e9\u9635\uff09</li> <li>\\(\\frac{1}{d_1}\\sum_{j=1}^{d_1}s(P_{k,ji})\\) \u662f\u5de6\u5947\u5f02\u5411\u91cf</li> <li>\\(\\frac{1}{d_2}\\sum_{j=1}^{d_2}s(Q_{k,ij})\\) \u662f\u53f3\u5947\u5f02\u5411\u91cf</li> </ul> <p>\\(\\overline{I}^{(t)}\\) \u662f\u5e73\u6ed1\u540e\u7684\u654f\u611f\u5ea6\uff0c\\(U^{(t)}\\) \u662f\u4e0d\u786e\u5b9a\u6027\u9879\u3002\u8fd9\u4e24\u4e2a\u503c\u901a\u8fc7\u6307\u6570\u79fb\u52a8\u5e73\u5747(EMA)\u6765\u66f4\u65b0:</p> \\[ \\overline{I}^{(t)}(w_{ij}) = \\beta_1\\overline{I}^{(t-1)}(w_{ij}) + (1-\\beta_1)I^{(t)}(w_{ij}) \\tag{5} \\] \\[ \\overline{U}^{(t)}(w_{ij}) = \\beta_2U^{(t-1)}(w_{ij}) + (1-\\beta_2)|I^{(t)}(w_{ij}) - \\overline{I}^{(t)}(w_{ij})| \\tag{6} \\] <p>\u5176\u4e2d \\(I^{(t)}(w_{ij}) = |w_{ij}\\nabla_{w_{ij}}L|\\) \u662f\u53c2\u6570\u5bf9\u635f\u5931\u51fd\u6570\u7684\u654f\u611f\u5ea6\u3002</p> <p>Note</p> <p>\u4e3a\u4e86\u7b80\u5355\u7406\u89e3\uff0c\u6211\u4eec\u53ef\u4ee5\u8003\u8651\u5728\u70f9\u996a\u6bd4\u55bb\u4e2d\uff0cAdaLoRA \u5f15\u5165\u4e86\u4e00\u4e2a\u66f4\u7cbe\u7ec6\u7684\u8c03\u5473\u8bc4\u5206\u7cfb\u7edf\u3002\u8fd9\u4e2a\u7cfb\u7edf\u5e2e\u52a9\u6211\u4eec\u5224\u65ad\u6bcf\u79cd\u8c03\u6599\u7ec4\u5408\u7684\u91cd\u8981\u6027\u3002</p> <p>\u8c03\u5473\u7ec4\u5408\u7684\u8bc4\u5206\uff1a</p> <p>\u5bf9\u4e8e\u6bcf\u4e2a\u8c03\u5473\u7ec4\u5408 \\(G_{k,i}\\)\uff08\u60f3\u8c61\u8fd9\u662f\u4e00\u79cd\u7279\u5b9a\u7684\u9999\u6599\u6df7\u5408\uff09\uff0cAdaLoRA \u4f1a\u7ed9\u51fa\u4e00\u4e2a\u91cd\u8981\u6027\u5206\u6570\u3002</p> \\[ S_{k,i} = s(\\lambda_{k,i}) + \\frac{1}{d_1}\\sum_{j=1}^{d_1}s(P_{k,ji}) + \\frac{1}{d_2}\\sum_{j=1}^{d_2}s(Q_{k,ij}) \\tag{7} \\] <p>\u8fd9\u4e2a\u516c\u5f0f\u53ef\u4ee5\u7406\u89e3\u4e3a:  \\(s(\\lambda_{k,i})\\) \u662f\u8fd9\u79cd\u8c03\u6599\u6df7\u5408\u7684\u57fa\u7840\u91cd\u8981\u6027\uff0c\u540e\u9762\u4e24\u9879\u5219\u8003\u8651\u4e86\u8fd9\u79cd\u8c03\u6599\u5982\u4f55\u4e0e\u5176\u4ed6\u98df\u6750\u4e92\u52a8\u3002\u7b80\u5355\u6765\u8bf4,\u8fd9\u4e2a\u5206\u6570\u4e0d\u4ec5\u8003\u8651\u8c03\u6599\u672c\u8eab\u7684\u91cd\u8981\u6027\uff0c\u8fd8\u8003\u8651\u4e86\u5b83\u5982\u4f55\u5f71\u54cd\u6574\u9053\u83dc\u7684\u53e3\u5473\u3002</p> <p>\u8c03\u6599\u91cd\u8981\u6027\u7684\u52a8\u6001\u8bc4\u4f30\uff1a</p> <p>AdaLoRA\u4f7f\u7528\u4e00\u4e2a\u7279\u6b8a\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u6bcf\u79cd\u8c03\u6599\u7684\u91cd\u8981\u6027\u3002</p> \\[ s^{(t)}(w_{ij}) = \\overline{I}^{(t)}(w_{ij}) \\cdot U^{(t)}(w_{ij}) \\tag{8} \\] <p>\u8fd9\u91cc\u7684\\(\\overline{I}^{(t)}(w_{ij})\\) \u53ef\u4ee5\u7406\u89e3\u4e3a\u8c03\u6599\u7684\"\u53d7\u6b22\u8fce\u5ea6\"\uff0c\\(U^{(t)}(w_{ij})\\) \u5219\u4ee3\u8868\u8fd9\u79cd\u8c03\u6599\u4f7f\u7528\u7684\"\u521b\u65b0\u6027\"\u3002</p> <p>\u5c31\u50cf\u4e00\u4e2a\u53a8\u5e08\u4f1a\u6839\u636e\u987e\u5ba2\u53cd\u9988\u548c\u65b0\u7684\u70f9\u996a\u8d8b\u52bf\u6765\u8c03\u6574\u83dc\u5355,AdaLoRA\u4e5f\u4f1a\u4e0d\u65ad\u66f4\u65b0\u8fd9\u4e9b\u8bc4\u4f30:</p> \\[ \\overline{I}^{(t)}(w_{ij}) = \\beta_1\\overline{I}^{(t-1)}(w_{ij}) + (1-\\beta_1)I^{(t)}(w_{ij}) \\tag{9} \\] \\[ U^{(t)}(w_{ij}) = \\beta_2U^{(t-1)}(w_{ij}) + (1-\\beta_2)|I^{(t)}(w_{ij}) - \\overline{I}^{(t)}(w_{ij})| \\tag{10} \\] <p>\u8fd9\u4e9b\u516c\u5f0f\u8868\u793a,\u8c03\u6599\u7684\u53d7\u6b22\u8fce\u5ea6\u4f1a\u968f\u65f6\u95f4\u6162\u6162\u53d8\u5316\uff0c\u4f46\u4e5f\u4f1a\u6839\u636e\u6700\u65b0\u53cd\u9988\u5feb\u901f\u8c03\u6574\u3002\u5982\u679c\u4e00\u79cd\u8c03\u6599\u7684\u4f7f\u7528\u65b9\u5f0f\u7a81\u7136\u6539\u53d8(\u6bd4\u5982\u4e00\u79cd\u4f20\u7edf\u4e0a\u7528\u4e8e\u4e3b\u83dc\u7684\u9999\u6599\u5f00\u59cb\u7528\u4e8e\u751c\u70b9),\u7cfb\u7edf\u4f1a\u8fc5\u901f\u6ce8\u610f\u5230\u8fd9\u79cd\u521b\u65b0\u3002</p> <p>\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0cAdaLoRA \u5c31\u50cf\u4e00\u4e2a\u4e0d\u65ad\u5b66\u4e60\u548c\u521b\u65b0\u7684\u9876\u7ea7\u53a8\u5e08\uff0c\u80fd\u591f\u7cbe\u786e\u5730\u63a7\u5236\u6bcf\u79cd\u8c03\u6599\u7684\u7528\u91cf\uff0c\u521b\u9020\u51fa\u6700\u9002\u5408\u5f53\u524d\"\u53e3\u5473\"(\u4efb\u52a1\u9700\u6c42)\u7684\u83dc\u54c1\uff0c\u540c\u65f6\u4fdd\u6301\u83dc\u54c1\u7684\u57fa\u672c\u98ce\u683c\u4e0d\u53d8\u3002</p>"},{"location":"chapter3/adalora_tour/adalora_tour/#_6","title":"\u526a\u679d\u548c\u81ea\u9002\u5e94\u8c03\u6574\u672c\u5f81\u79e9","text":"<p>\u5728\u8fd9\u90e8\u5206\u6d89\u53ca\u539f\u7406\u90e8\u5206\u6709\u4e9b\u590d\u6742\uff0c\u76f4\u63a5\u5f15\u7528\u4e4b\u524d\u7684\u70f9\u996a\u6bd4\u55bb\uff0cAdaLoRA \u4e0d\u4ec5\u80fd\u8bc4\u4f30\u8c03\u6599\u7684\u91cd\u8981\u6027\uff0c\u8fd8\u80fd\u6839\u636e\u8fd9\u4e2a\u8bc4\u4f30\u52a8\u6001\u8c03\u6574\u8c03\u5473\u65b9\u6848\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u53ef\u4ee5\u5206\u4e3a\u51e0\u4e2a\u5173\u952e\u6b65\u9aa4\uff1a</p> <ul> <li>\u8c03\u5473\u7ec4\u5408\u7684\u91cd\u8981\u6027\u8bc4\u5206\u3002\u6bcf\u79cd\u8c03\u5473\u7ec4\u5408 \\(G_{k,i} = {P_{k,i}, \\lambda_{k,i}, Q_{k,i}}\\) \u90fd\u6709\u81ea\u5df1\u7684\u91cd\u8981\u6027\u8bc4\u5206\u3002\u8fd9\u5c31\u50cf\u53a8\u5e08\u5bf9\u6bcf\u79cd\u9999\u6599\u6df7\u5408\u7684\u8bc4\u4ef7\u3002\u540c\u65f6\uff0cAdaLoRA \u8fd8\u786e\u4fdd\u8c03\u6599\u4e4b\u95f4\u4e0d\u4f1a\u76f8\u4e92\u5e72\u6270\uff0c\u4fdd\u6301\u5404\u81ea\u7684\u72ec\u7279\u98ce\u5473\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a</li> </ul> \\[ R(P,Q) = |P^T P - I|^2_F + |QQ^T - I|^2_F \\tag{11} \\] <ul> <li>\u8c03\u6574\u8c03\u5473\u65b9\u6848\u3002AdaLoRA \u7684\u76ee\u6807\u662f\u627e\u5230\u6700\u4f73\u7684\u8c03\u5473\u65b9\u6848\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a</li> </ul> \\[ L(P, E, Q) = C(P, E, Q) + \\gamma \\sum_{k=1}^n R(P_k, Q_k) \\tag{12} \\] <p>\u8fd9\u91cc\uff0c\\(C(P, E, Q)\\) \u662f\u83dc\u54c1\u7684\u6574\u4f53\u53e3\u611f\uff0c \\(R(P_k, Q_k)\\)  \u786e\u4fdd\u6bcf\u79cd\u8c03\u6599\u4fdd\u6301\u5176\u72ec\u7279\u6027\uff0c\u800c \\(\\gamma\\) \u63a7\u5236\u8fd9\u79cd\u72ec\u7279\u6027\u7684\u91cd\u8981\u7a0b\u5ea6\u3002</p> <ul> <li>\u52a8\u6001\u8c03\u6574\u8c03\u6599\u7528\u91cf\u3002\u5728\u70f9\u996a\u8fc7\u7a0b\u4e2d\uff0cAdaLoRA \u4f1a\u4e0d\u65ad\u8c03\u6574\u6bcf\u79cd\u8c03\u6599\u7684\u7528\u91cf\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a</li> </ul> \\[ \\tilde{\\Lambda}k^{(t)} = \\Lambda_k^{(t)} - \\eta \\nabla{\\Lambda_k} L(P^{(t)}, E^{(t)}, Q^{(t)}) \\tag{13} \\] <p>\u8fd9\u5c31\u50cf\u53a8\u5e08\u6839\u636e\u54c1\u5c1d\u7ed3\u679c\u5fae\u8c03\u6bcf\u79cd\u8c03\u6599\u7684\u7528\u91cf\u3002</p> <ul> <li>\u4fdd\u7559\u6700\u91cd\u8981\u7684\u8c03\u6599\u3002\u63a5\u4e0b\u6765\uff0cAdaLoRA \u4f1a\u51b3\u5b9a\u4fdd\u7559\u54ea\u4e9b\u8c03\u6599\uff0c\u53bb\u6389\u4e0d\u592a\u91cd\u8981\u7684\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a</li> </ul> \\[ \\Lambda_k^{(t+1)} = T(\\tilde{\\Lambda}_k^{(t)}, S_k^{(t)}) \\tag{14} \\] <p>\u5176\u4e2d\uff0c\\(T\\) \u51fd\u6570\u53ea\u4fdd\u7559\u91cd\u8981\u6027\u6392\u540d\u524d \\(b^{(t)}\\) \u7684\u8c03\u6599\uff0c\u5176\u4ed6\u7684\u8c03\u6599\u91cf\u4f1a\u88ab\u8bbe\u4e3a \\(0\\) \u3002\u8fd9\u5c31\u50cf\u53a8\u5e08\u51b3\u5b9a\u54ea\u4e9b\u8c03\u6599\u662f\u83dc\u54c1\u5fc5\u4e0d\u53ef\u5c11\u7684\uff0c\u54ea\u4e9b\u53ef\u4ee5\u7565\u53bb\u3002</p> <ul> <li>\u6700\u540e\uff0cAdaLoRA \u4f1a\u6839\u636e\u70f9\u996a\u8fdb\u7a0b\u52a8\u6001\u8c03\u6574\u53ef\u7528\u7684\u8c03\u6599\u603b\u91cf\uff08\u9884\u7b97\uff09\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a</li> </ul> \\[ b^{(t)} = \\begin{cases} b^{(0)} &amp; 0 \\leq t &lt; t_i \\\\ b^{(T)} + (b^{(0)} - b^{(T)}) \\left( 1 - \\frac{t - t_i - t_f}{T - t_i - t_f} \\right)^3 &amp; t_i \\leq t &lt; T - t_f \\\\ b^{(T)} &amp; \\text{otherwise} \\end{cases} \\tag{15} \\] <p>\u8fd9\u5c31\u50cf\u53a8\u5e08\u5728\u70f9\u996a\u8fc7\u7a0b\u4e2d\u9010\u6e10\u51cf\u5c11\u6dfb\u52a0\u65b0\u8c03\u6599\u7684\u91cf\uff1a\u4e00\u5f00\u59cb\uff08 \\(0 \\leq t &lt; t_i\\) \uff09\uff0c\u53a8\u5e08\u4f1a\u4f7f\u7528\u8f83\u591a\u8c03\u6599\u6765\u8c03\u5473\u3002\u5728\u4e2d\u95f4\u9636\u6bb5\uff08 \\(t_i \\leq t &lt; T - t_f\\) \uff09\uff0c\u53a8\u5e08\u4f1a\u9010\u6e10\u51cf\u5c11\u65b0\u6dfb\u52a0\u7684\u8c03\u6599\u91cf\u3002\u6700\u540e\u9636\u6bb5\uff0c\u53a8\u5e08\u53ea\u4f7f\u7528\u6700\u5c11\u91cf\u7684\u8c03\u6599\u6765\u5fae\u8c03\u53e3\u5473\u3002</p> <p>\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0cAdaLoRA \u5c31\u50cf\u4e00\u4e2a\u7cbe\u901a\u70f9\u996a\u827a\u672f\u7684\u5927\u53a8\uff0c\u80fd\u591f\u5728\u70f9\u996a\u8fc7\u7a0b\u4e2d\u4e0d\u65ad\u8c03\u6574\u8c03\u6599\u7684\u79cd\u7c7b\u548c\u7528\u91cf\uff0c\u6700\u7ec8\u521b\u9020\u51fa\u65e2\u4fdd\u7559\u539f\u6709\u98ce\u5473\u53c8\u9002\u5e94\u65b0\u53e3\u5473\u7684\u5b8c\u7f8e\u83dc\u54c1\u3002</p>"},{"location":"chapter3/adalora_tour/adalora_tour/#_7","title":"\u4f18\u52bf","text":"<p>\u4e0e LoRA \u76f8\u6bd4\uff0cAdaLoRA \u5177\u6709\u4ee5\u4e0b\u4f18\u52bf:</p> <ol> <li>\u81ea\u9002\u5e94\u6027\uff1a\u80fd\u591f\u6839\u636e\u4e0d\u540c\u6743\u91cd\u77e9\u9635\u548c\u5c42\u7684\u91cd\u8981\u6027\u52a8\u6001\u8c03\u6574\u79e9\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u53c2\u6570\u5206\u914d\u3002</li> <li>\u7075\u6d3b\u6027\uff1aSVD-based\u7684\u53c2\u6570\u5316\u5141\u8bb8\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7075\u6d3b\u8c03\u6574\u77e9\u9635\u79e9\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u521d\u59cb\u5316\u3002</li> <li>\u7a33\u5b9a\u6027\uff1a\u901a\u8fc7\u4fdd\u7559\u5947\u5f02\u5411\u91cf\u800c\u53ea\u526a\u679d\u5947\u5f02\u503c\uff0cAdaLoRA \u80fd\u591f\u5728\u9700\u8981\u65f6\u6062\u590d\u88ab\u9519\u8bef\u526a\u679d\u7684\u53c2\u6570\uff0c\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u3002</li> <li>\u6027\u80fd\u63d0\u5347\uff1a\u5728\u591a\u9879\u4efb\u52a1\u4e0a\uff0cAdaLoRA \u5c55\u73b0\u51fa\u6bd4 LoRA \u66f4\u4f18\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u4f4e\u53c2\u6570\u9884\u7b97\u7684\u60c5\u51b5\u4e0b\u3002</li> </ol>"},{"location":"chapter3/adalora_tour/adalora_tour/#_8","title":"\u7ed3\u8bba","text":"<p>AdaLoRA\u4f5c\u4e3aLoRA\u7684\u6539\u8fdb\u7248\u672c\uff0c\u901a\u8fc7\u5f15\u5165\u52a8\u6001\u79e9\u8c03\u6574\u3001\u5168\u9762\u7684\u6a21\u5757\u9002\u914d\u548c\u57fa\u4e8eSVD\u7684\u53c2\u6570\u5316\uff0c\u6210\u529f\u5730\u63d0\u9ad8\u4e86\u53c2\u6570\u6548\u7387\u5fae\u8c03(PEFT)\u7684\u6027\u80fd\u3002\u5b83\u4e0d\u4ec5\u5728\u591a\u4e2aNLP\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u7ed3\u679c\uff0c\u800c\u4e14\u5728\u4f4e\u53c2\u6570\u9884\u7b97\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u5c24\u4e3a\u51fa\u8272\u3002AdaLoRA\u7684\u6210\u529f\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u5fae\u8c03\u5f00\u8f9f\u4e86\u65b0\u7684\u65b9\u5411\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u601d\u8def\u3002</p> <p>\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0cAdaLoRA \u53ef\u4ee5\u5e2e\u52a9\u7814\u7a76\u8005\u548c\u5de5\u7a0b\u5e08\u5728\u6709\u9650\u7684\u8ba1\u7b97\u8d44\u6e90\u4e0b\u66f4\u597d\u5730\u9002\u914d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5230\u7279\u5b9a\u4efb\u52a1\uff0c\u8fd9\u5bf9\u4e8e\u63a8\u52a8AI\u6280\u672f\u7684\u666e\u53ca\u548c\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002</p>"},{"location":"chapter3/adalora_tour/adalora_tour/#_9","title":"\u53c2\u8003\u8d44\u6599","text":"<ol> <li>Zhang, Q., Chen, M., Bukharin, A., Karampatziakis, N., He, P., Cheng, Y., Chen, W., &amp; Zhao, T. (2023). AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning. In International Conference on Learning Representations (ICLR 2023).\u00a0\u29c9</li> <li>Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., &amp; Chen, W. (2022). LoRA: Low-Rank Adaptation of Large Language Models. In International Conference on Learning Representations (ICLR 2022).\u00a0\u29c9</li> <li>He, J., Zhou, C., Ma, X., Berg-Kirkpatrick, T., &amp; Neubig, G. (2022). Towards a Unified View of Parameter-Efficient Transfer Learning. In International Conference on Learning Representations (ICLR 2022).\u00a0\u29c9</li> <li>Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.\u00a0\u29c9</li> </ol>"},{"location":"chapter3/ia3_tour/ia3_tour/","title":"IA3\uff1a\u63a2\u7d22\u65b0\u7684\u589e\u91cf\u8bad\u7ec3\u65b9\u6cd5","text":""},{"location":"chapter3/ia3_tour/ia3_tour/#_1","title":"\u524d\u8a00","text":"<p>\u4e3a\u4e86\u4f7f\u5fae\u8c03\u66f4\u52a0\u9ad8\u6548\uff0c\u5317\u5361\u7f57\u6765\u7eb3\u6559\u5802\u5c71\u5206\u6821\u7684\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u65b0\u7684\u589e\u91cf\u8bad\u7ec3\u65b9\u6cd5\\(IA^3\\)\u00a0\u29c9\uff0c\u8fd9\u79cd\u65b9\u6cd5\u901a\u8fc7\u5b66\u4e60\u5411\u91cf\u6765\u5bf9\u6fc0\u6d3b\u5c42\u52a0\u6743\u8fdb\u884c\u7f29\u653e\u3002\u4f5c\u8005\u56e2\u961f\u57fa\u4e8e\u4e4b\u524d\u7684 <code>T0</code> \u57fa\u7840\u6a21\u578b\uff0c\u4fee\u6539\u4e86\u635f\u5931\u51fd\u6570\u4ee5\u9002\u5e94\u5c0f\u6837\u672c\u5b66\u4e60\uff0c\u65e0\u9700\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u8fdb\u884c\u8c03\u6574\u5373\u53ef\u5e94\u7528\u4e8e\u65b0\u4efb\u52a1\uff0c\u547d\u540d\u4e3a<code>T-Few</code>\uff0c\u5e76\u5728<code>RAFT</code>\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u53d6\u5f97\u4e86\u5168\u65b0\u7684SOTA\u7ed3\u679c\uff0c\u8d85\u8fc7\u4e86\u4eba\u7c7b\u57fa\u51c6\u6c34\u5e73\u3002</p>"},{"location":"chapter3/ia3_tour/ia3_tour/#_2","title":"\u6838\u5fc3\u601d\u60f3","text":"<p>\\(IA^3\\) \u7684\u6838\u5fc3\u601d\u60f3\u662f\u5728\u539f\u59cb\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5173\u952e\u4f4d\u7f6e\u6ce8\u5165\u5c11\u91cf\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u6765\u5b9e\u73b0\u53c2\u6570\u7684\u9ad8\u6548\u5fae\u8c03\u3002</p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\\(IA^3\\) \u5f15\u5165\u4e86\u4e09\u4e2a\u5b66\u4e60\u5411\u91cf \\(l_k\\) \uff0c\\(l_v\\) \u548c \\(l_{ff}\\) \uff0c\u5206\u522b\u7528\u4e8e\u7f29\u653e\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u952e\uff08key\uff09\u548c\u503c\uff08value\uff09\uff0c\u4ee5\u53ca\u524d\u9988\u7f51\u7edc\uff08FFN\uff09\u4e2d\u7684\u4e2d\u95f4\u6fc0\u6d3b\u3002</p>"},{"location":"chapter3/ia3_tour/ia3_tour/#_3","title":"\u6280\u672f\u7ec6\u8282","text":""},{"location":"chapter3/ia3_tour/ia3_tour/#ia3","title":"\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\\(IA^3\\)","text":"<p>\u5728\u81ea\u6ce8\u610f\u529b\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u4e2d\uff0c\\(IA^3\\) \u5f15\u5165\u4e86\u4e24\u4e2a\u53ef\u5b66\u4e60\u7684\u5411\u91cf \\(l_k\\) \u548c \\(l_v\\)\uff0c\u5206\u522b\u7528\u4e8e\u7f29\u653e\u952e\uff08key\uff09\u548c\u503c\uff08value\uff09\u3002</p> <p>\u539f\u59cb\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\uff1a</p> \\[ Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V \\tag{1} \\] <p>\\(IA^3\\) \u4fee\u6539\u540e\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\uff1a</p> \\[ Attention_{IA^3}(Q, K, V) = softmax(\\frac{Q(l_k \\circ K)^T}{\\sqrt{d_k}})(l_v \\circ V) \\tag{2} \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(Q\\)\uff0c\\(K\\),\uff0c\\(V\\) \u5206\u522b\u5bf9\u5e94\u67e5\u8be2\u3001\u952e\u548c\u503c\u77e9\u9635\u3002</li> <li>\\(l_k, l_v \\in \\mathbb{R}^{d_k}\\) \u662f\u53ef\u5b66\u4e60\u7684\u7f29\u653e\u5411\u91cf\u3002</li> <li>\\(\\circ\\) \u8868\u793a\u54c8\u8fbe\u739b\u79ef\uff08\u5373\u6309\u4f4d\u4e58\uff09\u3002</li> <li>\\(d_{k}\\) \u8868\u793a\u6ce8\u610f\u529b\u5934\u7684\u7ef4\u5ea6\u3002</li> </ul>"},{"location":"chapter3/ia3_tour/ia3_tour/#ia3_1","title":"\u524d\u9988\u7f51\u7edc\u4e2d\u7684IA3","text":"<p>\u5728\u524d\u9988\u7f51\u7edc\uff08FFN\uff09\u4e2d\uff0c\\(IA^3\\) \u5f15\u5165\u4e86\u53ef\u5b66\u4e60\u7684\u5411\u91cf \\(l_{ff}\\) \u6765\u7f29\u653e\u7b2c\u4e00\u4e2a\u7ebf\u6027\u53d8\u6362\u7684\u8f93\u51fa\u3002</p> <p>\u539f\u59cb\u7684FFN\u8ba1\u7b97\uff1a</p> \\[ FFN(x) = W_2(\\gamma(W_{1}x + b_{1})) + b_{2} \\tag{3} \\] <p>\\(IA^3\\) \u4fee\u6539\u540e\u7684FFN\u8ba1\u7b97\uff1a</p> \\[ FFN_{IA3}(x) = W_2(l_{ff} \\odot \\gamma(W_{1}x + b_{1})) + b_{2} \\tag{4} \\] <p>\u5176\u4e2d:</p> <ul> <li>\\(W_1\\)\uff0c\\(W_2\\) \u662f\u6743\u91cd\u77e9\u9635\u3002</li> <li>\\(b_1\\)\uff0c\\(b_2\\) \u662f\u504f\u7f6e\u9879\u3002</li> <li>\\(l_{ff} \\in \\mathbb{R}^{d_{ff}}\\) \u662f\u53ef\u5b66\u4e60\u7684\u7f29\u653e\u5411\u91cf\u3002</li> <li>\\(d_{ff}\\) \u662fFFN\u7684\u9690\u85cf\u7ef4\u5ea6\u3002</li> <li>\\(\\odot\\) \u8868\u793a\u9010\u5143\u7d20\u4e58\u6cd5\u3002</li> <li>\\(\\gamma(x)\\) \u8868\u793a\u6fc0\u6d3b\u51fd\u6570\u3002</li> </ul>"},{"location":"chapter3/ia3_tour/ia3_tour/#_4","title":"\u53c2\u6570\u521d\u59cb\u5316","text":"<p>\u6240\u6709\u7684 \\(IA^3\\) \u53c2\u6570\uff08\\(l_k\\)\uff0cl_v$ \uff0c\\(l_{ff}\\)\uff09\u90fd\u521d\u59cb\u5316\u4e3a\u5168 \\(1\\) \u5411\u91cf\u4ee5\u786e\u4fdd\u4e86\u5728\u8bad\u7ec3\u5f00\u59cb\u65f6\uff0c\u6a21\u578b\u7684\u884c\u4e3a\u4e0e\u539f\u59cb\u9884\u8bad\u7ec3\u6a21\u578b\u76f8\u540c\u3002\u5373</p> \\[ l_k = l_v = l_{ff} = [1, 1, \\cdots, 1] \\tag{5} \\]"},{"location":"chapter3/ia3_tour/ia3_tour/#ia3_2","title":"\\(IA^3\\) \u53c2\u6570\u66f4\u65b0","text":"<p>\u5728\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\uff0c\u53ea\u6709 \\(IA^3\\) \u53c2\u6570\uff08\\(l_k\\)\uff0cl_v$ \uff0c\\(l_{ff}\\)\uff09\u4f1a\u88ab\u66f4\u65b0\uff0c\u800c\u539f\u59cb\u6a21\u578b\u7684\u53c2\u6570\u4fdd\u6301\u51bb\u7ed3\uff1a</p> \\[ l_k^{(t+1)} = l_k^{(t)} - \\eta \\nabla_{l_k} L \\tag{6} \\] \\[ l_v^{(t+1)} = l_v^{(t)} - \\eta \\nabla_{l_v} L \\tag{7} \\] \\[ l_{ff}^{(t+1)} = l_{ff}^{(t)} - \\eta \\nabla_{l_{ff}} L \\tag{8} \\] <p>\u5176\u4e2d:</p> <ul> <li>\\(\\eta\\) \u662f\u5b66\u4e60\u7387\u3002</li> <li>\\(L\\) \u662f\u635f\u5931\u51fd\u6570\u3002</li> <li>\\(\\nabla_{l} L\\) \u8868\u793a\u635f\u5931\u51fd\u6570\u5bf9\u53c2\u6570 \\(l\\) \u7684\u68af\u5ea6\u3002</li> </ul>"},{"location":"chapter3/ia3_tour/ia3_tour/#_5","title":"\u63a8\u7406\u65f6\u7684\u4f18\u5316","text":"<p>\u5728\u63a8\u7406\u9636\u6bb5\uff0c\u5c06 \\(IA^3\\) \u7684\u7f29\u653e\u5411\u91cf\u76f4\u63a5\u4e0e\u539f\u59cb\u6743\u91cd\u76f8\u4e58\uff0c\u4ece\u800c\u907f\u514d\u989d\u5916\u7684\u8ba1\u7b97\u5f00\u9500\u3002</p> <ul> <li>\u5bf9\u4e8e\u6ce8\u610f\u529b\u673a\u5236: \\(K_{eff} = l_k \\circ K\\),  \\(V_{eff} = l_v \\circ V\\)</li> <li>\u5bf9\u4e8eFFN:  \\(W_{1,eff} = diag(l_{ff}) W_1\\)</li> </ul> <p>\u5176\u4e2d \\(diag(l_{ff})\\) \u662f\u4ee5 \\(l_{ff}\\) \u4e3a\u5bf9\u89d2\u5143\u7d20\u7684\u5bf9\u89d2\u77e9\u9635\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\\(IA^3\\) \u5728\u4fdd\u6301\u9ad8\u6548\u63a8\u7406\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u3002</p>"},{"location":"chapter3/ia3_tour/ia3_tour/#_6","title":"\u5173\u952e\u7279\u6027","text":"\u7279\u6027 \u63cf\u8ff0 \u53c2\u6570\u6548\u7387\u9ad8 \u53ea\u5728\u6a21\u5757\u4e0a\u5f15\u5165\u5c11\u91cf\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u5927\u5927\u51cf\u5c11\u4e86\u9700\u8981\u5fae\u8c03\u7684\u53c2\u6570\u6570\u91cf\u3002 \u8ba1\u7b97\u6548\u7387\u9ad8 \u7531\u4e8e \\(IA^3\\) \u53ea\u662f\u5bf9\u73b0\u6709\u7684\u6fc0\u6d3b\u8fdb\u884c\u7f29\u653e\uff0c\u800c\u4e0d\u662f\u5f15\u5165\u65b0\u7684\u5c42\u6216\u590d\u6742\u7684\u7ed3\u6784\uff0c\u56e0\u6b64\u8ba1\u7b97\u5f00\u9500\u5f88\u5c0f\u3002 \u6613\u4e8e\u5b9e\u73b0 \\(IA^3\\) \u7684\u5b9e\u73b0\u76f8\u5bf9\u7b80\u5355\u3002 \u4e0e\u5176\u4ed6\u65b9\u6cd5\u517c\u5bb9 \\(IA^3\\)\u4e0e\u5176\u4ed6PEFT\u65b9\u6cd5\u517c\u5bb9\u6027\u9ad8\u3002"},{"location":"chapter3/ia3_tour/ia3_tour/#ia3-lora","title":"\\(IA^3\\) \u4e0e \\(LoRA\\) \u7684\u6bd4\u8f83","text":"<p>\u867d\u7136 \\(IA^3\\) \u4e0e \\(LoRA\\) \u90fd\u662f\u65e8\u5728\u5b9e\u73b0\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684\u65b9\u6cd5\uff0c\u4f46\u5b83\u4eec\u6709\u4e00\u4e9b\u5173\u952e\u533a\u522b\uff1a</p> \u7279\u6027 \\(IA^3\\) \\(LoRA\\) \u53c2\u6570\u6ce8\u5165\u4f4d\u7f6e \u76f4\u63a5\u5bf9\u6fc0\u6d3b\u8fdb\u884c\u7f29\u653e \u5728\u6743\u91cd\u77e9\u9635\u4e2d\u6ce8\u5165\u4f4e\u79e9\u66f4\u65b0 \u53c2\u6570\u6570\u91cf \u66f4\u5c11 (\u7ea6 0.01% \u7684\u6a21\u578b\u53c2\u6570) \u901a\u5e38\u9700\u8981\u66f4\u591a (&gt; 0.1% \u7684\u6a21\u578b\u53c2\u6570) \u5b9e\u73b0\u590d\u6742\u5ea6 \u66f4\u7b80\u5355\uff0c\u53ea\u9700\u5143\u7d20\u7ea7\u4e58\u6cd5 \u9700\u8981\u5bf9\u6743\u91cd\u77e9\u9635\u8fdb\u884c\u4fee\u6539 \u9002\u7528\u8303\u56f4 \u66f4\u5e7f\u6cdb\uff0c\u53ef\u7528\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u548c\u524d\u9988\u7f51\u7edc \u4e3b\u8981\u7528\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u6743\u91cd\u77e9\u9635"},{"location":"chapter3/ia3_tour/ia3_tour/#_7","title":"\u7ed3\u8bba","text":"<p>\\(IA^3\\) \u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b80\u5355\u800c\u6709\u6548\u7684\u6fc0\u6d3b\u7f29\u653e\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u9002\u914d\u3002\u5b83\u4e0d\u4ec5\u5927\u5927\u51cf\u5c11\u4e86\u5fae\u8c03\u6240\u9700\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u8fd8\u4fdd\u6301\u4e86\u4e0e\u5168\u53c2\u6570\u5fae\u8c03\u76f8\u5f53\u7684\u6027\u80fd\u3002</p>"},{"location":"chapter3/ia3_tour/ia3_tour/#_8","title":"\u53c2\u8003\u6587\u732e","text":"<ol> <li>Liu, H., Tam, D., Muqeeth, M., Mohta, J., Huang, T., Bansal, M., &amp; Raffel, C. (2022). Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning. arXiv preprint arXiv:2205.05638.\u00a0\u29c9</li> <li>Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., &amp; Chen, W. (2021). LoRA: Low-Rank Adaptation of Large Language Models. arXiv preprint arXiv:2106.09685.\u00a0\u29c9</li> <li>Pfeiffer, J., R\u00fcckle, A., Poth, C., Kamath, A., Vuli\u0107, I., Ruder, S., Cho, K., &amp; Gurevych, I. (2020). AdapterHub: A Framework for Adapting Transformers. arXiv preprint arXiv:2007.07779.\u00a0\u29c9</li> <li>Lester, B., Al-Rfou, R., &amp; Constant, N. (2021). The Power of Scale for Parameter-Efficient Prompt Tuning. arXiv preprint arXiv:2104.08691.\u00a0\u29c9</li> </ol>"},{"location":"chapter3/lora_tour/lora_tour/","title":"LoRA: \u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f4e\u79e9\u9002\u914d","text":""},{"location":"chapter3/lora_tour/lora_tour/#_1","title":"\u524d\u8a00","text":"<p>\u968f\u7740\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u7684\u4e0d\u65ad\u589e\u5927\uff0c\u5168\u91cf\u5fae\u8c03\uff08\u5373\u91cd\u65b0\u8bad\u7ec3\u6240\u6709\u6a21\u578b\u53c2\u6570\uff09\u9700\u8981\u82b1\u8d39\u5de8\u5927\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u800c\u4e14\u96be\u4ee5\u4fdd\u8bc1\u6027\u80fd\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5fae\u8f6f\u7814\u7a76\u9662\u63d0\u51fa\u4e86\u4f4e\u79e9\u9002\u914d(Low-Rank Adaptation, LoRA)\u00a0\u29c9\u65b9\u6cd5\uff0c\u5373\u901a\u8fc7\u4f4e\u79e9\u5206\u89e3\u7684\u65b9\u5f0f\u9ad8\u6548\u5730\u5fae\u8c03\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u3002</p>"},{"location":"chapter3/lora_tour/lora_tour/#_2","title":"\u6838\u5fc3\u601d\u60f3","text":"<p>LoRA \u7684\u6838\u5fc3\u601d\u60f3\u662f\u901a\u8fc7\u53ea\u66f4\u65b0\u4e00\u5c0f\u90e8\u5206\u53c2\u6570\uff0c\u4ece\u800c\u9ad8\u6548\u5730\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9002\u914d\u5230\u4e0b\u6e38\u4efb\u52a1\u7684\u95ee\u9898\u3002</p> <p>\u8fd9\u79cd\u65b9\u6cd5\u51bb\u7ed3\u6574\u4e2a\u9884\u8bad\u7ec3\u6743\u91cd\u77e9\u9635 \\(W_0\\)\uff0c\u7136\u540e\u5c06\u6743\u91cd\u66f4\u65b0 \\(\\Delta W\\) \u5206\u89e3\u4e3a\u4f4e\u79e9\u8868\u793a\u3002\u5373</p> \\[ W = W_0 + \\Delta W = W_0 + BA \\tag{1} \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(W_0\\) \u8868\u793a\u539f\u59cb\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u3002</li> <li>\\(B \\in \\mathbb{R}^{d \\times r}\\) \u548c \\(A \\in \\mathbb{R}^{r \\times k}\\) \u8868\u793a\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u4f4e\u79e9\u77e9\u9635\uff0c\u5176\u4e2d \\(r &lt;&lt; min(d, k)\\)\u3002</li> </ul> <p></p> <p>\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u8f93\u5165 \\(x\\) \u4e58\u4ee5\u539f\u59cb\u6743\u91cd\u77e9\u9635 (\\(W_0x\\)) \u5e76\u52a0\u4e0a\u4f4e\u79e9\u9002\u914d (\\(BAx\\)) \u7684\u7ed3\u679c\u3002\u7531\u4e8e \\(r\\) \u8fdc\u5c0f\u4e8e \\(d\\) \u548c \\(k\\)\uff0c\u56e0\u6b64\u4e0e\u66f4\u65b0\u6574\u4e2a \\(W_0\\) \u76f8\u6bd4\uff0c\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u6570\u91cf\u5927\u5927\u51cf\u5c11\u3002</p> <p>Note</p> <p>\u4e3a\u4e86\u786e\u4fdd\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u548c\u6548\u7387\uff0cLoRA \u5bf9\u4f4e\u79e9\u77e9\u9635\u7684\u521d\u59cb\u5316\u548c\u8f93\u51fa\u8fdb\u884c\u4e86\u7279\u6b8a\u5904\u7406\uff1a</p> <ul> <li>\\(A\\) \u77e9\u9635\u4f7f\u7528\u9ad8\u65af\u5206\u5e03\u8fdb\u884c\u968f\u673a\u521d\u59cb\u5316\uff0c\u4e3a\u6a21\u578b\u5f15\u5165\u4e86\u968f\u673a\u6027\uff0c\u6709\u52a9\u4e8e\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u53c2\u6570\u7a7a\u95f4\u3002</li> <li>\\(B\\) \u77e9\u9635\u521d\u59cb\u5316\u4e3a\u96f6\u77e9\u9635\uff0c\u8fd9\u6837\u5728\u8bad\u7ec3\u5f00\u59cb\u65f6\uff0cLoRA \u7684\u8f93\u51fa\u4e3b\u8981\u7531\u539f\u59cb\u6a21\u578b\u51b3\u5b9a\uff0c\u7136\u540e\u9010\u6e10\u52a0\u5165\u4f4e\u79e9\u9002\u914d\u7684\u5f71\u54cd\u3002</li> <li>\u4e3a\u4e86\u63a7\u5236\u4f4e\u79e9\u9002\u914d\u5bf9\u6700\u7ec8\u8f93\u51fa\u7684\u5f71\u54cd\uff0c\u5c06  \\(BAx\\)  \u7684\u7ed3\u679c\u4e58\u4ee5\u4e00\u4e2a\u7f29\u653e\u56e0\u5b50 \\(\\frac{\\alpha}{r}\\)\uff0c\u901a\u8fc7\u8fd9\u79cd\u7f29\u653e\u64cd\u4f5c\uff0c\u53ef\u4ee5\u5e73\u8861\u539f\u59cb\u6a21\u578b\u548c\u4f4e\u79e9\u9002\u914d\u7684\u8d21\u732e\uff0c\u9632\u6b62\u4f4e\u79e9\u9002\u914d\u8fc7\u5ea6\u5f71\u54cd\u6700\u7ec8\u8f93\u51fa\u3002<ul> <li>\\(\\alpha\\) \u662f\u4e00\u4e2a\u5e38\u6570\uff0c\u901a\u5e38\u8bbe\u7f6e\u4e3a \\(1\\) \u6216\u6839\u636e\u7ecf\u9a8c\u8fdb\u884c\u8c03\u6574\u3002</li> <li>\\(r\\) \u662f\u4f4e\u79e9\u77e9\u9635\u7684\u79e9\u3002</li> </ul> </li> </ul> <p>\u5728\u63a8\u7406\u65f6\uff0c\u5c06\u9884\u8bad\u7ec3\u7684\u4f4e\u79e9\u9002\u914d\u77e9\u9635 \\(A\\) \u548c \\(B\\) \u52a0\u56de\u5230\u539f\u59cb\u9884\u8bad\u7ec3\u6743\u91cd\u77e9\u9635 \\(W\\) \u4e0a\uff0c\u5f97\u5230\u4e00\u4e2a\u65b0\u7684\u6743\u91cd\u77e9\u9635\uff0c\u5373\u4e0a\u6587\u63d0\u5230\u7684 \\(W\\) \u3002\u5b83\u5305\u542b\u4e86\u539f\u59cb\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u4fe1\u606f\u548c LoRA \u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b66\u4e60\u5230\u7684\u7279\u5b9a\u4efb\u52a1\u77e5\u8bc6\u3002</p> <p>Note</p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u6743\u91cd\u5408\u5e76\u7684\u8fc7\u7a0b\u5982\u4e0b\uff1a</p> <ol> <li>\u5c06\u8bad\u7ec3\u597d\u7684 \\(B\\) \u548c \\(A\\) \u77e9\u9635\u76f8\u4e58\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u4e58\u4ee5\u7f29\u653e\u56e0\u5b50 \\(\\frac{\\alpha}{r}\\) \u3002</li> <li>\u5c06\u4e0a\u8ff0\u7684\u6700\u540e\u7ed3\u679c\u52a0\u5230\u539f\u59cb\u6743\u91cd\u77e9\u9635 \\(W_{0}\\) \u4e0a\uff0c\u5f97\u5230\u65b0\u7684\u6743\u91cd\u77e9\u9635 \u3002</li> <li>\u4f7f\u7528\u65b0\u6743\u91cd\u77e9\u9635\u8fdb\u884c\u63a8\u7406\uff1a \u4f7f\u7528\u65b0\u7684\u6743\u91cd\u77e9\u9635 \\(W\\) \u5bf9\u8f93\u5165 \\(x\\) \u8fdb\u884c\u63a8\u7406\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u8f93\u51fa\u3002</li> </ol>"},{"location":"chapter3/lora_tour/lora_tour/#_3","title":"\u4f18\u52bf","text":"<p>LoRA \u4e3a\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u51e0\u9879\u663e\u8457\u4f18\u52bf\uff1a</p> <ul> <li>\u53c2\u6570\u6548\u7387\uff1aLoRA \u901a\u8fc7\u4ec5\u8bad\u7ec3\u4f4e\u79e9\u77e9\u9635\u663e\u8457\u51cf\u5c11\u4e86\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u6570\u91cf\uff0c\u4ece\u800c\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u4e86\u5b58\u50a8\u9700\u6c42\u5e76\u5141\u8bb8\u5728\u8d44\u6e90\u6709\u9650\u7684\u8bbe\u5907\u4e0a\u8fdb\u884c\u5fae\u8c03\u3002</li> <li>\u8ba1\u7b97\u6548\u7387\uff1a\u7531\u4e8e\u51cf\u5c11\u4e86\u53c2\u6570\u66f4\u65b0\uff0cLoRA \u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4f7f\u5f97\u5fae\u8c03\u8fc7\u7a0b\u66f4\u5feb\u3001\u66f4\u9ad8\u6548\u3002</li> <li>\u4e0e\u5168\u91cf\u5fae\u8c03\u76f8\u5f53\u7684\u6027\u80fd\uff1a\u5c3d\u7ba1 LoRA \u5177\u6709\u6548\u7387\u4f18\u52bf\uff0c\u4f46\u5b83\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4ecd\u80fd\u4fdd\u6301\u4e0e\u5168\u91cf\u5fae\u8c03\u76f8\u5f53\u7684\u6027\u80fd\u3002</li> </ul>"},{"location":"chapter3/lora_tour/lora_tour/#_4","title":"\u5b9e\u8df5\u5efa\u8bae","text":"<p>\u4e3a\u4e86\u5728\u5b9e\u8df5\u4e2d\u6709\u6548\u5730\u5229\u7528 LoRA \uff0c\u53ef\u4ee5\u8003\u8651\u4ee5\u4e0b\u5efa\u8bae\uff1a</p> <ul> <li>\u9009\u62e9\u5408\u9002\u7684\u79e9\uff08r\uff09\uff1a\u4ece\u8f83\u5c0f\u7684 \\(r\\) \u503c\u5f00\u59cb\uff0c\u5e76\u6839\u636e\u4efb\u52a1\u9700\u6c42\u9010\u6e10\u589e\u52a0\uff0c\u4ee5\u5e73\u8861\u6548\u7387\u548c\u6027\u80fd\u3002</li> <li>\u6743\u91cd\u9009\u62e9\uff1a\u4f18\u5148\u8003\u8651\u540c\u65f6\u8c03\u6574\u67e5\u8be2\uff08Q\uff09\u548c\u503c\uff08V\uff09\u77e9\u9635\u4ee5\u83b7\u5f97\u6700\u4f73\u7ed3\u679c\u3002</li> <li>\u4e0e\u5176\u4ed6\u6280\u672f\u76f8\u7ed3\u5408\uff1a\u63a2\u7d22\u5c06 LoRA \u4e0e\u5176\u4ed6\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u76f8\u7ed3\u5408\u4ee5\u83b7\u5f97\u6f5c\u5728\u7684\u989d\u5916\u6536\u76ca\u3002</li> <li>\u7f29\u653e\u56e0\u5b50\u8c03\u4f18\uff1a\u5c1d\u8bd5\u4e0d\u540c\u7684 \\(\\alpha\\) \u503c\u4ee5\u4f18\u5316\u7279\u5b9a\u4efb\u52a1\u7684\u6027\u80fd\u3002</li> </ul>"},{"location":"chapter3/lora_tour/lora_tour/#_5","title":"\u7ed3\u8bba","text":"<ol> <li>LoRA \u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u3002</li> <li>\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u4f4e\u79e9\u5206\u89e3\uff0c\u51cf\u5c11\u4e86\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u5168\u91cf\u5fae\u8c03\u76f8\u5f53\u7684\u6027\u80fd\u3002</li> <li>\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0d\u65ad\u53d1\u5c55\uff0cLoRA \u7b49\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002</li> </ol>"},{"location":"chapter3/lora_tour/lora_tour/#_6","title":"\u53c2\u8003\u8d44\u6599","text":"<ol> <li>Edward J. Hu, et al. \"LoRA: Low-Rank Adaptation of Large Language Models.\" arXiv preprint arXiv:2106.09685 (2021).\u00a0\u29c9</li> <li>Neil Houlsby, et al. \"Parameter-Efficient Transfer Learning for NLP.\" ICML 2019.\u00a0\u29c9</li> <li>Elad Ben-Zaken, et al. \"BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models.\" ACL 2022.\u00a0\u29c9</li> </ol>"},{"location":"chapter3/p_tuning_tour/p_tuning_tour/","title":"P-Tuning\uff1a\u89e3\u51b3\u4eba\u5de5\u8bbe\u8ba1Prompt\u7684\u95ee\u9898","text":""},{"location":"chapter3/p_tuning_tour/p_tuning_tour/#_1","title":"\u524d\u8a00","text":"<p>\u4e0d\u8bba\u662f<code>Prefix Tuning</code>\u8fd8\u662f<code>Prompt Tuning</code>\u90fd\u9700\u8981\u624b\u52a8\u8bbe\u8ba1\u79bb\u6563\u7684\u63d0\u793a\u8bcd\uff0c\u4e8e\u662f\u6e05\u534e\u5927\u5b66\u4e0e\u9ebb\u7701\u7406\u5de5\u5b66\u9662\u7684\u5b66\u8005\u4eec\u5408\u4f5c\u63d0\u51fa\u4e86P-Tuning\u00a0\u29c9\u65b9\u6cd5\uff0c\u5373\u901a\u8fc7\u8fde\u7eed\u53ef\u5b66\u4e60\u7684prompt embedding\u6765\u9ad8\u6548\u5730\u5fae\u8c03\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u3002</p>"},{"location":"chapter3/p_tuning_tour/p_tuning_tour/#_2","title":"\u6838\u5fc3\u601d\u60f3","text":"<p>\u5177\u4f53\u6765\u8bf4\uff0c<code>P-Tuning</code>\u5728\u8f93\u5165\u5e8f\u5217\u7684\u4e0d\u540c\u4f4d\u7f6e\u63d2\u5165\u4e00\u7cfb\u5217\u7279\u6b8atoken [P]\uff0c\u6bcf\u4e2a[P]\u5bf9\u5e94\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684embedding\u5411\u91cf\u3002\u8fd9\u4e9b\u8fde\u7eed\u7684 prompt embedding\u4e0e\u79bb\u6563\u6587\u672c\u7684embedding\u5171\u540c\u6784\u6210\u6a21\u578b\u7684\u8f93\u5165\u3002</p> <p><code>P-Tuning</code>\u7684\u521b\u65b0\u4e4b\u5904\u5728\u4e8e\u6784\u5efa\u4e00\u4e2a\uff08Prompt\uff09\u8f6f\u5316\u7684\u53ef\u5b66\u4e60\u7684\u5d4c\u5165\u5c42\uff08Embedding Layer\uff09\u3002</p>"},{"location":"chapter3/p_tuning_tour/p_tuning_tour/#_3","title":"\u6280\u672f\u7ec6\u8282","text":"<ul> <li>\u5728\uff08a\uff09\u4e2d\uff0c\u63d0\u793a\u751f\u6210\u5668\u53ea\u63a5\u6536\u79bb\u6563\u5956\u52b1\uff1b</li> <li>\u5728\uff08b\uff09\u4e2d\uff0c\u8fde\u7eed\u7684\u63d0\u793a\u5d4c\u5165\uff08Prompt Embedding\uff09\u548c\u63d0\u793a\u7f16\u7801\u5668\uff08Prompt Encoder\uff09\u4ee5\u53ef\u5fae\u7684\u65b9\u5f0f\u8fdb\u884c\u4f18\u5316\u3002</li> </ul>"},{"location":"chapter3/p_tuning_tour/p_tuning_tour/#_4","title":"\u6574\u4f53\u6846\u67b6","text":"<p><code>P-Tuning</code>\u7684\u6574\u4f53\u6846\u67b6\u5982\u4e0b\uff1a</p> <ol> <li>\u4e3a\u6bcf\u4e2a\u4e0b\u6e38\u4efb\u52a1\u8bbe\u8ba1\u4e00\u4e2a prompt \u6a21\u677f\uff0c\u5305\u542b\u79bb\u6563\u6587\u672c\u548c\u7279\u6b8atoken [P]\uff1b</li> <li>\u5c06prompt\u6a21\u677f\u5e94\u7528\u4e8e\u8f93\u5165\u6837\u672c\uff0c\u5f97\u5230\u6df7\u5408\u5e8f\u5217\uff1b</li> <li>\u4f7f\u7528prompt encoder\u5c06[P] token\u6620\u5c04\u4e3a\u8fde\u7eed\u5411\u91cf\uff1b</li> <li>\u5c06\u8fde\u7eedprompt\u5411\u91cf\u4e0e\u79bb\u6563token embedding\u62fc\u63a5\uff0c\u8f93\u5165\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff1b</li> <li>\u4f18\u5316prompt\u53c2\u6570\u548c\u4efb\u52a1\u7279\u5b9a\u53c2\u6570\uff08\u5982\u5206\u7c7b\u5934\uff09\uff0c\u56fa\u5b9a\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u3002</li> </ol>"},{"location":"chapter3/p_tuning_tour/p_tuning_tour/#prompt","title":"Prompt \u7f16\u7801\u5668","text":"<p><code>P-Tuning</code>\u5f15\u5165\u4e86prompt\u7f16\u7801\u5668\u6765\u5efa\u6a21[P] token\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u3002</p> <p>\u5e38\u7528\u7684\u7f16\u7801\u5668\u5305\u62ec\uff1a</p> <ul> <li>LSTM\uff1a\u6355\u6349\u957f\u7a0b\u4f9d\u8d56</li> <li>MLP\uff1a\u7b80\u5355\u6709\u6548</li> <li>\u7ebf\u6027\u5c42\uff1a\u76f4\u63a5\u5b66\u4e60\u72ec\u7acb\u7684embedding</li> </ul> <p>\u5b9e\u9a8c\u8868\u660eLSTM\u548cMLP\u901a\u5e38\u6548\u679c\u8f83\u597d\uff0c\u800c\u7b80\u5355\u7684\u7ebf\u6027\u5c42\u5728\u67d0\u4e9b\u4efb\u52a1\u4e0a\u53ef\u80fd\u4e0d\u7a33\u5b9a\u3002</p>"},{"location":"chapter3/p_tuning_tour/p_tuning_tour/#_5","title":"\u8bad\u7ec3\u76ee\u6807","text":"<p><code>P-Tuning</code>\u7684\u8bad\u7ec3\u76ee\u6807\u662f\u6700\u5c0f\u5316\u4e0b\u6e38\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570\u3002\u4ee5\u5206\u7c7b\u4efb\u52a1\u4e3a\u4f8b\uff1a</p> \\[ L = CrossEntropy(f(x_prompt), y) \\tag{1} \\] <p>\u5176\u4e2d \\(x_prompt\\) \u662f\u52a0\u5165\u8fde\u7eedprompt\u540e\u7684\u8f93\u5165\uff0c\\(f\\) \u662f\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\\(y\\) \u662f\u771f\u5b9e\u6807\u7b7e\u3002</p>"},{"location":"chapter3/p_tuning_tour/p_tuning_tour/#_6","title":"\u63a8\u7406","text":"<p>\u5728\u63a8\u7406\u65f6\uff0c<code>P-Tuning</code>\u5c06\u8bad\u7ec3\u597d\u7684prompt embedding\u4e0e\u8f93\u5165\u6587\u672c\u62fc\u63a5\uff0c\u76f4\u63a5\u9001\u5165\u9884\u8bad\u7ec3\u6a21\u578b\u5373\u53ef\u3002\u8fd9\u65e2\u907f\u514d\u4e86\u79bb\u6563prompt\u641c\u7d22\u7684\u590d\u6742\u6027\uff0c\u53c8\u4fdd\u6301\u4e86\u8f83\u4f4e\u7684\u53c2\u6570\u91cf\u548c\u8ba1\u7b97\u5f00\u9500\u3002</p>"},{"location":"chapter3/p_tuning_tour/p_tuning_tour/#_7","title":"\u4f18\u52bf","text":"<p>\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c<code>P-Tuning</code>\u5177\u6709\u4ee5\u4e0b\u4f18\u52bf\uff1a</p> <ol> <li>\u53c2\u6570\u6548\u7387\u9ad8\uff1a\u53ea\u9700\u8bad\u7ec3\u5c11\u91cfprompt\u53c2\u6570\uff0c\u5927\u5927\u51cf\u5c11\u4e86\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42</li> <li>\u6027\u80fd\u4f18\u5f02\uff1a\u5728\u591a\u4e2aNLU\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u4eba\u5de5\u8bbe\u8ba1\u7684\u79bb\u6563prompt</li> <li>\u8bad\u7ec3\u7a33\u5b9a\uff1a\u8fde\u7eed\u6027\u4f7f\u5f97\u4f18\u5316\u8fc7\u7a0b\u66f4\u52a0\u5e73\u6ed1\uff0c\u4e0d\u6613\u53d7\u5c40\u90e8\u6700\u4f18\u5f71\u54cd</li> <li>\u901a\u7528\u6027\u5f3a\uff1a\u9002\u7528\u4e8e\u5404\u79cd\u9884\u8bad\u7ec3\u6a21\u578b\uff08\u5982 BERT\u3001GPT \u7b49\uff09\u548c\u4e0b\u6e38\u4efb\u52a1</li> <li>\u6613\u4e8e\u4f7f\u7528\uff1a\u65e0\u9700\u5927\u91cfprompt\u5de5\u7a0b\uff0c\u81ea\u52a8\u5b66\u4e60\u4efb\u52a1\u76f8\u5173\u77e5\u8bc6</li> </ol>"},{"location":"chapter3/p_tuning_tour/p_tuning_tour/#p-tuning-prefix-tuning","title":"P-Tuning \u548c Prefix-Tuning \u4e3b\u8981\u533a\u522b\u5728\u4e8e","text":"<p>\u5f53\u6211\u4eec\u4e86\u89e3\u5b8cPrefix-Tuning\u540e\uff0c\u518d\u6765\u7406\u89e3P-Tuning\uff0c\u4f1a\u53d1\u73b0\u5e38\u5e38\u5c06\u4e8c\u8005\u6df7\u6dc6\uff0c\u56e0\u4e3a\u5b83\u4eec\u90fd\u662f\u4e3a\u4e86\u89e3\u51b3\u4eba\u5de5\u8bbe\u8ba1\u63d0\u793a\u7684\u95ee\u9898\u3002</p> \u7279\u70b9 <code>Prefix Tuning</code> <code>P-Tuning</code> \u5d4c\u5165\u4f4d\u7f6e \u503e\u5411\u4e8e\u5728\u6a21\u578b\u521d\u59cb\u8f93\u5165\u7684\u5d4c\u5165\u5c42 (embedding) \u66f4\u4e3a\u7075\u6d3b\u7684\u5d4c\u5165\u4f4d\u7f6e \u5b9e\u73b0\u65b9\u6cd5 \u5728\u6bcf\u4e2a\u6ce8\u610f\u529b\u5c42\u589e\u52a0\u72ec\u7acb\u5c0f\u578b\u8f93\u5165\u5d4c\u5165\u88c5\u7f6e\uff0c\u5e76\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u673a (MLP) \u8fdb\u884c\u521d\u59cb\u5316 \u4ec5\u5728\u8f93\u5165\u90e8\u5206\u589e\u52a0\uff0c\u5e76\u901a\u8fc7\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc (LSTM) \u52a0MLP\u8fdb\u884c\u521d\u59cb\u5316"},{"location":"chapter3/p_tuning_tour/p_tuning_tour/#_8","title":"\u7ed3\u8bba","text":"<p><code>P-Tuning</code>\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u9002\u914d\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u8303\u5f0f\u3002\u5b83\u5de7\u5999\u5730\u7ed3\u5408\u4e86\u79bb\u6563prompt\u7684\u5148\u9a8c\u77e5\u8bc6\u548c\u8fde\u7eedembedding\u7684\u53ef\u5b66\u4e60\u6027\uff0c\u5728\u591a\u79cd\u8bbe\u7f6e\u4e0b\u90fd\u5c55\u73b0\u51fa\u4e86\u4f18\u5f02\u7684\u6027\u80fd\u3002</p>"},{"location":"chapter3/p_tuning_tour/p_tuning_tour/#_9","title":"\u53c2\u8003\u6587\u732e","text":"<ol> <li>Liu, X., et al. (2021). GPT Understands, Too. arXiv preprint arXiv:2103.10385.\u00a0\u29c9</li> <li>Schick, T., &amp; Sch\u00fctze, H. (2020). It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners. arXiv preprint arXiv:2009.07118.\u00a0\u29c9</li> <li>Brown, T. B., et al. (2020). Language Models are Few-Shot Learners. arXiv preprint arXiv:2005.14165.\u00a0\u29c9</li> </ol>"},{"location":"chapter3/peft_tour/peft_tour/","title":"PEFT\uff08Parameter-Efficient Fine-Tuning\uff09","text":""},{"location":"chapter3/peft_tour/peft_tour/#_1","title":"\u524d\u8a00","text":"<p>\ud83e\udd17 <code>PEFT</code>\uff08\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff09\u662f\u4e00\u4e2a\u7528\u4e8e\u9ad8\u6548\u5730\u5c06\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u9002\u914d\u5230\u5404\u79cd\u4e0b\u6e38\u5e94\u7528\u7684\u5e93\u3002</p> <p>\u7531\u4e8e\u5fae\u8c03\u6a21\u578b\u7684\u6240\u6709\u53c2\u6570\u6210\u672c\u9ad8\u6602\u4e14\u96be\u4ee5\u5b9e\u73b0\uff0c\u800c <code>PEFT</code> \u65b9\u6cd5\u53ea\u9700\u8981\u5fae\u8c03\u5c11\u91cf\u989d\u5916\u6a21\u578b\u53c2\u6570\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u5b58\u50a8\u6210\u672c\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u4e0e\u6a21\u578b\u5168\u91cf\u5fae\u8c03\u8fd1\u4e4e\u76f8\u5f53\u7684\u6027\u80fd\u3002\u8fd9\u4f7f\u5f97\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8bad\u7ec3\u548c\u4fdd\u5b58\u5927\u8bed\u8a00\u6a21\u578b (LLM) \u53d8\u5f97\u66f4\u52a0\u5bb9\u6613\u3002</p> <p>\u5b89\u88c5 <code>peft</code></p> \u5b89\u88c5peft<pre><code>pip install peft\n</code></pre> <p>PEFT \u6db5\u76d6\u4f17\u591a\u4e3b\u6d41\u4f4e\u53c2\u9ad8\u6821\u5fae\u8c03\u6280\u672f\uff0c\u5e76\u53ef\u4ee5\u548c <code>Transformers</code>\u3001<code>Accelerate</code> \u4e00\u8d77\u4f7f\u7528\uff0c\u6bd4\u5982</p> <ol> <li><code>LoRa</code></li> <li><code>Prefix Tuning</code></li> <li><code>AdaLoRA</code></li> <li><code>Prompt Tuning</code></li> <li><code>MultiTask Prompt Tuning</code></li> <li><code>LoHa</code></li> <li>\\(\\cdots\\)</li> </ol> <p><code>PEFT</code> \u5e93\u652f\u6301\u7684\u65b9\u6cd5\u5747\u53ef\u5728 Adapters HuggingFace\u00a0\u29c9 \u5de6\u4fa7\u5bfc\u822a\u680f\u67e5\u627e</p> <p>\u63a5\u4e0b\u6765\u7684\u5185\u5bb9\u5c06\u4ecb\u7ecd <code>PEFT</code> \u7684\u4e3b\u8981\u7ec4\u6210\uff0c\u4ee5\u53ca\u5982\u4f55\u8bad\u7ec3\u6216\u8fd0\u884c\u90a3\u4e9b\u901a\u5e38\u5728\u6d88\u8d39\u7ea7\u8bbe\u5907\u4e0a\u96be\u4ee5\u8bad\u7ec3\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u3002</p>"},{"location":"chapter3/peft_tour/peft_tour/#peftconfig","title":"<code>PeftConfig</code>","text":"<p>\u6bcf\u79cd <code>PEFT</code> \u65b9\u6cd5\u90fd\u5bf9\u5e94\u4e00\u4e2a\u72ec\u7279\u7684 <code>PeftConfig</code> \u7c7b\uff0c\u7528\u4e8e\u5b58\u50a8\u6784\u5efa\u76f8\u5e94 <code>PeftModel</code> \u7684\u6240\u6709\u5fc5\u8981\u53c2\u6570\u3002</p> <p>\u5f53\u4f60\u60f3\u8981\u8c03\u7528\u67d0\u4e2a <code>PEFT</code> \u65b9\u6cd5\u65f6\uff0c\u9700\u8981\u5148\u52a0\u8f7d\u5e76\u521b\u5efa\u4e00\u4e2a\u8be5\u65b9\u6cd5\u5bf9\u5e94\u7684 <code>PeftConfig</code> \u7c7b\u5b9e\u4f8b\uff0c\u5e76\u5728\u5b9e\u4f8b\u5316\u8fc7\u7a0b\u4e2d\u6307\u5b9a\u8be5\u65b9\u6cd5\u9700\u8981\u7684\u53c2\u6570\u3002\u8fd9\u4e9b\u53c2\u6570\u4f1a\u56e0 <code>PEFT</code> \u65b9\u6cd5\u7684\u4e0d\u540c\u800c\u6709\u6240\u5dee\u5f02\uff0c\u4f8b\u5982\uff1a</p> <ul> <li><code>LoRa</code> (<code>LoraConfig</code>)\uff1a\u9700\u8981\u6307\u5b9a\u00a0<code>lora_rank</code>\uff08\u4f4e\u79e9\u77e9\u9635\u7684\u79e9\uff09\u3001<code>lora_alpha</code>\uff08\u7f29\u653e\u56e0\u5b50\uff09\u548c\u00a0<code>lora_dropout</code>\uff08dropout \u6982\u7387\uff09\u7b49\u53c2\u6570\u3002</li> <li><code>Prompt Tuning</code> (<code>PromptTuningConfig</code>)\uff1a\u9700\u8981\u6307\u5b9a\u00a0<code>prompt_tuning_num_tokens</code>\uff08prompt \u4e2d\u7684 token \u6570\u91cf\uff09\u3001<code>prompt_tuning_init_text</code>\uff08prompt \u7684\u521d\u59cb\u5316\u6587\u672c\uff09\u548c\u00a0<code>prompt_tuning_placeholder_id</code>\uff08\u5360\u4f4d\u7b26 ID\uff09\u7b49\u53c2\u6570\u3002</li> </ul> <p>\u5047\u5982\u4ee5 <code>LoRa</code> \u4e3a\u4f8b\u5b50\uff0c\u600e\u4e48\u8ba9 <code>LoRa</code> \u4f5c\u7528\u4e8e\u6a21\u578b\u5462\uff1f</p> <ol> <li>\u5f15\u5165\u00a0<code>LoraConfig</code>\u00a0\u7c7b\u3002</li> <li>\u5b9a\u4e49 <code>LoRa</code> \u7684\u53c2\u6570\uff0c\u5305\u62ec\u00a0<code>task_type</code>\uff0c<code>inference_mode</code>\uff0c<code>r</code>\uff0c<code>lora_alpha</code>\u00a0\u548c\u00a0<code>lora_dropout</code> \u7b49\u3002</li> </ol> LoraConfig<pre><code>from peft import LoraConfig, TaskType\n\npeft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1)\n</code></pre>"},{"location":"chapter3/peft_tour/peft_tour/#peft","title":"PEFT \u53c2\u6570\u8be6\u89e3","text":"\u53c2\u6570 \u8bf4\u660e <code>Task_type</code> \u4e0b\u6e38\u4efb\u52a1\u7c7b\u578b\uff0c\u5f71\u54cd PEFT \u65b9\u6cd5\u8c03\u6574\u6a21\u578b\u7684\u65b9\u5f0f\u3002\u4e0d\u540c\u7684\u4efb\u52a1\u7c7b\u578b\u53ef\u80fd\u9700\u8981\u4e0d\u540c\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u56e0\u6b64\u9700\u8981\u6839\u636e\u5b9e\u9645\u60c5\u51b5\u9009\u62e9\u5408\u9002\u7684\u00a0<code>Task_type</code>\u3002\u4f8b\u5982\uff0c<code>SEQ_CLS</code>\u00a0\u7528\u4e8e\u6587\u672c\u5206\u7c7b\uff0c<code>SEQ_2_SEQ_LM</code>\u00a0\u7528\u4e8e\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u8bed\u8a00\u6a21\u578b\uff0c<code>CAUSAL_LM</code>\u00a0\u7528\u4e8e\u56e0\u679c\u5173\u7cfb\u6a21\u578b\u7b49\u3002\u66f4\u591a\u4efb\u52a1\u7c7b\u578b\u8bf7\u53c2\u8003\u5b98\u65b9\u6587\u6863\uff1aTask_type Huggingface\u00a0\u29c9 <code>Inference_mode</code> \u4f18\u5316\u6a21\u578b\u63a8\u7406\u9636\u6bb5\u6027\u80fd\u7684\u673a\u5236\u3002<code>False</code>\u00a0\u4ee3\u8868\u8bad\u7ec3\u6a21\u5f0f\uff0c\u542f\u7528\u68af\u5ea6\u66f4\u65b0\u548c\u8bad\u7ec3\u9636\u6bb5\u7279\u6709\u7684\u64cd\u4f5c\u3002<code>True</code>\u00a0\u4ee3\u8868\u63a8\u7406\u6a21\u5f0f\uff0c\u7981\u7528\u68af\u5ea6\u66f4\u65b0\uff0c\u91ca\u653e\u5185\u5b58\u7a7a\u95f4\uff0c\u63d0\u9ad8\u63a8\u7406\u901f\u5ea6\u3002 <code>r</code> \u4f4e\u79e9\u77e9\u9635\u7684\u7ef4\u5ea6\uff0c\u5f71\u54cd LoRa \u6dfb\u52a0\u7684\u53c2\u6570\u91cf\u548c\u8bad\u7ec3\u901f\u5ea6\u3002<code>r</code>\u00a0\u503c\u8d8a\u5c0f\uff0c\u53c2\u6570\u8d8a\u5c11\uff0c\u8bad\u7ec3\u8d8a\u5feb\uff0c\u4f46\u53ef\u80fd\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u3002\u9700\u8981\u6839\u636e\u5b9e\u9645\u60c5\u51b5\u6743\u8861\u8bad\u7ec3\u901f\u5ea6\u548c\u6a21\u578b\u6027\u80fd\u6765\u9009\u62e9\u5408\u9002\u7684\u00a0<code>r</code>\u00a0\u503c\u3002 <code>lora_alpha</code> \u4f4e\u79e9\u77e9\u9635\u7684\u7f29\u653e\u56e0\u5b50\uff0c\u5f71\u54cd LoRa \u5bf9\u6a21\u578b\u7684\u5f71\u54cd\u7a0b\u5ea6\u3002<code>lora_alpha</code>\u00a0\u503c\u8d8a\u5927\uff0c\u5f71\u54cd\u8d8a\u5927\u3002 <code>lora_dropout</code> \u5e94\u7528\u4e8e LoRa \u5c42\u7684 dropout \u6982\u7387\uff0c\u9632\u6b62\u6a21\u578b\u8fc7\u62df\u5408\u3002<code>lora_dropout</code>\u00a0\u53ef\u4ee5\u8bbe\u7f6e\u4e3a 0 \u5230 1 \u4e4b\u95f4\u7684\u6570\u503c\uff0c\u9002\u5f53\u7684\u6570\u503c\u8303\u56f4\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u9632\u6b62\u6a21\u578b\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u8fc7\u62df\u5408\u3002 <code>target_modules</code> \u9009\u62e9\u8981\u5e94\u7528\u9002\u914d\u5668\u7684\u6a21\u5757\u3002\u53ef\u4ee5\u901a\u8fc7\u6b63\u5219\u8868\u8fbe\u5f0f\u3001\u7cbe\u786e\u5339\u914d\u3001\u6a21\u5757\u540d\u79f0\u7ed3\u5c3e\u5339\u914d\u6216\u9009\u62e9\u6240\u6709\u7ebf\u6027\u5c42\u6765\u5b9e\u73b0\u5bf9\u76ee\u6807\u6a21\u5757\u7684\u9009\u62e9\u3002\u672a\u6307\u5b9a\u65f6\uff0cPEFT \u4f1a\u6839\u636e\u6a21\u578b\u67b6\u6784\u81ea\u52a8\u9009\u62e9\u76ee\u6807\u6a21\u5757\u3002 \u65e0\u6cd5\u8bc6\u522b\u6a21\u578b\u67b6\u6784\u65f6\uff0c\u9700\u8981\u624b\u52a8\u6307\u5b9a\u76ee\u6807\u6a21\u5757\u3002 \u6240\u6709\u9ed8\u8ba4\u7684\u5fae\u8c03\u6a21\u5757\u90fd\u53ef\u4ee5\u5728\u00a0peft.utils.constants\u00a0\u29c9\u00a0\u67e5\u770b\u3002 <p>\u4e0a\u9762\u7684\u4f8b\u5b50\u662f\u9488\u5bf9\u4e8e <code>LoRa</code> \u7684\uff0c\u4f46\u662f\u73b0\u5b9e\u4e2d\u53ef\u80fd\u9700\u8981\u66f4\u591a\u4e0d\u540c\u7684 <code>PEFT</code> \u65b9\u6cd5, \u4e0d\u540c\u7684 <code>PEFT</code> \u65b9\u6cd5\u53c8\u9700\u8981\u6307\u5b9a\u4e0d\u540c\u7684\u53c2\u6570\uff0c\u5728\u4e0d\u4e86\u89e3\u9700\u8981\u4ec0\u4e48\u53c2\u6570\u7684\u65f6\u5019\u600e\u4e48\u64cd\u4f5c\u5462\uff1f</p> <p>\u6240\u6709\u7684\u5fae\u8c03\u65b9\u6cd5\u7684\u914d\u7f6e\u53ca\u5176\u53c2\u6570\u4ecb\u7ecd\u90fd\u80fd\u5728 Adapters HuggingFace\u00a0\u29c9 \u5de6\u4fa7\u5bfc\u822a\u680f\u88ab\u627e\u5230\u3002</p> <p>\u8fdb\u5165\u8be6\u7ec6\u4ecb\u7ecd\u754c\u9762\uff0c\u6574\u4f53\u80fd\u770b\u5230\u76f8\u5e94 <code>PEFT</code> \u65b9\u6cd5\u7684\u4ecb\u7ecd</p> <p></p> <p>\u5176\u6b21\u662f\u76f8\u5e94 <code>PEFT</code> \u65b9\u6cd5\u7684\u5185\u7f6e\u7684\u53c2\u6570\uff0c\u5728 <code>Parameters</code> \u680f\u5217\u51fa\u4e86\u6700\u4e3a\u91cd\u8981\u7684\u53c2\u6570\uff0c\u4f7f\u7528\u8005\u53ef\u4ee5\u6839\u636e\u8bf4\u660e\u53ca\u9700\u6c42\u81ea\u5b9a\u4e49\u76f8\u5173\u53c2\u6570\u3002</p> <p></p>"},{"location":"chapter3/peft_tour/peft_tour/#peftmodel","title":"<code>PeftModel</code>","text":"<p>\u8bbe\u7f6e\u5b8c <code>PeftConfig</code> \u540e\uff0c\u7136\u540e\u4f7f\u7528 <code>get_peft_model()</code> \u51fd\u6570\u521b\u5efa <code>PeftModel</code>\u3002 <code>get_peft_model()</code> \u9700\u8981\u4e00\u4e2a\u4ece <code>transformers</code> \u52a0\u8f7d\u7684\u57fa\u7840\u6a21\u578b\u548c\u5df2\u7ecf\u5b9a\u4e49\u597d\u7684 <code>PeftModel</code> \u5b9e\u4f8b\u3002</p> base model<pre><code>from transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/mt0-large\")\n</code></pre> <p>\u4f7f\u7528\u00a0<code>get_peft_model()</code>\u00a0\u548c\u00a0<code>peft_config</code>\u00a0\u521b\u5efa\u00a0<code>PeftModel</code>\u00a0\u662f\u4f7f\u7528 <code>PEFT</code> \u7684\u6807\u51c6\u65b9\u6cd5\u3002</p> LoraModel<pre><code>from peft import get_peft_model\n\nmodel = get_peft_model(model, peft_config)\n</code></pre> <p><code>PeftModel</code> \u62e5\u6709\u8bb8\u591a\u5185\u7f6e\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\uff0c\u8fd9\u91cc\u4e3b\u8981\u4ecb\u7ecd\u4ee5\u4e0b\u4e09\u79cd\u3002</p> <ol> <li><code>peft_model.base_model</code>: \u8bbf\u95ee\u57fa\u7840\u6a21\u578b</li> <li><code>peft_model.print_trainable_parameters()</code>: \u6253\u5370\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u6570\u91cf\u548c\u540d\u79f0</li> <li><code>peft_model.save_pretrained()</code>: \u4fdd\u5b58\u00a0<code>PeftModel</code>\uff0c\u5305\u62ec\u57fa\u7840\u6a21\u578b\u548c <code>PEFT</code> \u9002\u914d\u5668</li> </ol> <p>\u73b0\u5728\u8ba9\u6211\u4eec\u770b\u770b\u5168\u91cf\u5fae\u8c03\u4e0e\u4f7f\u7528\u4f4e\u53c2\u9ad8\u6548\u5fae\u8c03\u65f6\uff0c\u53c2\u4e0e\u68af\u5ea6\u66f4\u65b0\u7684\u53c2\u6570\u5bf9\u6bd4\u5427\u3002</p> model.print_trainable_parameters()<pre><code>\"output: trainable params: 2359296 || all params: 1231940608 || trainable%: 0.19151053100118282\"\n</code></pre> <p><code>bigscience/mt0-large</code> \u6a21\u578b\u62e5\u6709 \\(12\\) \u4ebf\u53c2\u6570\uff0c\u800c\u6211\u4eec\u53ea\u9700\u8981\u5fae\u8c03\u5176\u4e2d \\(0.19\\%\\) \u5c31\u80fd\u5b9e\u73b0\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u6548\u679c\uff01\u603b\u7684\u6765\u8bf4\u9762\u5bf9\u5e9e\u5927\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c<code>PEFT</code> \u5de7\u5999\u5730\u51bb\u7ed3\u5927\u90e8\u5206\u53c2\u6570\uff0c\u53ea\u5fae\u8c03\u5c11\u91cf\u7684\u989d\u5916\u53c2\u6570\uff0c\u5c31\u80fd\u53d6\u5f97\u4e0e\u5168\u91cf\u5fae\u8c03\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u6548\u679c\u3002\u8fd9\u662f\u4e00\u9879\u591a\u4e48\u4ee4\u4eba\u5fc3\u60c5\u6109\u60a6\u7684\u4e8b\u60c5\uff01</p>"},{"location":"chapter3/peft_tour/peft_tour/#_2","title":"\u8bad\u7ec3","text":"<p>\ud83c\udf89 \u5230\u73b0\u5728\u5df2\u7ecf\u6210\u529f\u5730\u8bbe\u7f6e\u597d\u4e86\u88ab <code>PEFT</code> \u65b9\u6cd5\u5305\u88f9\u540e\u7684\u6a21\u578b\u4e86\uff0c\u5e76\u4e14\u51c6\u5907\u597d\u5f00\u59cb\u8bad\u7ec3\u4e86\uff01</p> <p>\u63a5\u4e0b\u6765\u5c31\u53ef\u4ee5\u4f7f\u7528 <code>Trainer</code>, <code>Accelerate</code>, \u6216\u8005\u81ea\u5b9a\u4e49\u7684 <code>PyTorch</code> \u7684\u8bad\u7ec3\u6d41\u7a0b\u3002</p> <p>\u8bad\u7ec3\u90e8\u5206\u4e0d\u662f\u672c\u8282\u7684\u91cd\u70b9\uff0c\u6545\u76f4\u63a5\u5f15\u7528\u5b98\u65b9\u7684\u4ee3\u7801\u3002</p> training_args<pre><code>training_args = TrainingArguments(\n    output_dir=\"your-name/bigscience/mt0-large-lora\",\n    learning_rate=1e-3,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)\n</code></pre> <p>\u73b0\u5728\u5c31\u53ef\u4ee5\u628a\u6a21\u578b\u3001\u8bad\u7ec3\u53c2\u6570\u3001\u6570\u636e\u96c6\u3001\u5206\u8bcd\u5668\u548c\u5176\u4ed6\u5fc5\u8981\u7ec4\u4ef6\u7edf\u7edf\u6254\u7ed9 <code>Trainer</code> \uff0c\u7136\u540e\u8c03\u7528 <code>train()</code> \u65b9\u6cd5\u5f00\u59cb\u8bad\u7ec3\uff01</p> Trainer<pre><code>trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n</code></pre>"},{"location":"chapter3/peft_tour/peft_tour/#_3","title":"\u4fdd\u5b58\u6a21\u578b\u3001\u63a8\u7406","text":""},{"location":"chapter3/peft_tour/peft_tour/#_4","title":"\u4fdd\u5b58","text":"<p>\u5f53\u6a21\u578b\u5b8c\u6210\u8bad\u7ec3\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u00a0<code>model.save_pretrained()</code>\u00a0\u51fd\u6570\u5c06\u5176\u4fdd\u5b58\u5230\u6307\u5b9a\u7684\u76ee\u5f55\u4e2d\u3002</p>"},{"location":"chapter3/peft_tour/peft_tour/#_5","title":"\u63a8\u7406","text":"<p>\u65e0\u8bba\u662f\u81ea\u5df1\u8fd8\u662f\u522b\u4eba\u4f7f\u7528 <code>PEFT</code> \u8bad\u7ec3\u51fa\u6765\u7684\u6a21\u578b\uff0c\u53ea\u8981\u62ff\u5230\u6a21\u578b\u6587\u4ef6\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u00a0<code>AutoPeftModel</code>\u00a0\u7c7b\u53ca\u5176\u00a0<code>from_pretrained</code>\u00a0\u65b9\u6cd5\u8f7b\u677e\u52a0\u8f7d <code>PEFT</code> \u8bad\u7ec3\u7684\u6a21\u578b\u4ee5\u8fdb\u884c\u63a8\u7406\u3002\u8fd9\u79cd\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u7f1d\u7684\u65b9\u5f0f\u6765\u52a0\u8f7d\u548c\u4f7f\u7528\u4f60\u7684\u5fae\u8c03\u6a21\u578b\uff0c\u800c\u65e0\u9700\u624b\u52a8\u6307\u5b9a\u6a21\u578b\u67b6\u6784\u6216 <code>PEFT</code> \u914d\u7f6e\u3002</p> PeftModel infer<pre><code>from peft import AutoPeftModelForCausalLM\nfrom transformers import AutoTokenizer\nimport torch\n\nmodel = AutoPeftModelForCausalLM.from_pretrained(\"ybelkada/opt-350m-lora\")\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n\nmodel = model.to(\"cuda\")\nmodel.eval()\ninputs = tokenizer(\"Preheat the oven to 350 degrees and place the cookie dough\", return_tensors=\"pt\")\n\noutputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=50)\nprint(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0])\n</code></pre> output<pre><code>\"Preheat the oven to 350 degrees and place the cookie dough in the center of the oven. In a large bowl, combine the flour, baking powder, baking soda, salt, and cinnamon. In a separate bowl, combine the egg yolks, sugar, and vanilla.\"\n</code></pre> <p>\u52a0\u8f7d\u6a21\u578b\u7684\u65b9\u5f0f</p> <p>\u6211\u4eec\u65e2\u53ef\u4ee5\u5728\u8bad\u7ec3\u5b8c\u6210\u540e\u7acb\u5373\u4f7f\u7528\u8bad\u7ec3\u597d\u7684 <code>PEFT</code> \u6a21\u578b\u8fdb\u884c\u63a8\u7406\uff0c\u4e5f\u53ef\u4ee5\u5c06\u6a21\u578b\u4fdd\u5b58\u5230\u78c1\u76d8\uff0c\u7a0d\u540e\u518d\u52a0\u8f7d\u5b83\u8fdb\u884c\u63a8\u7406\u3002\u9009\u62e9\u54ea\u79cd\u65b9\u6cd5\u53d6\u51b3\u4e8e\u4f60\u7684\u5177\u4f53\u9700\u6c42\u3002\u5982\u679c\u53ea\u662f\u60f3\u5feb\u901f\u6d4b\u8bd5\u6a21\u578b\uff0c\u90a3\u4e48\u7b2c\u4e00\u79cd\u65b9\u6cd5\u66f4\u65b9\u4fbf\u3002\u5982\u679c\u9700\u8981\u957f\u671f\u4fdd\u5b58\u548c\u7ba1\u7406\u6a21\u578b\uff0c\u90a3\u4e48\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u66f4\u5408\u9002\u3002</p>"},{"location":"chapter3/peft_tour/peft_tour/#_6","title":"\u53c2\u8003\u8d44\u6599","text":"<ul> <li> <p><code>PEFT</code>\u652f\u6301\u7684\u5fae\u8c03\u65b9\u6cd5</p> <p>Adapters HuggingFace\u00a0\u29c9</p> </li> <li> <p><code>PEFT</code> \u652f\u6301\u7684\u4efb\u52a1\u7c7b\u578b</p> <p>Task_type Huggingface\u00a0\u29c9</p> </li> <li> <p>Hugging Face \u5b98\u65b9\u7684\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u5feb\u901f\u5165\u95e8\u548c\u793a\u4f8b\u3002</p> <p>PEFT HuggingFace\u00a0\u29c9</p> </li> <li> <p><code>PEFT</code>\u65b9\u6cd5\u9ed8\u8ba4\u7684\u76ee\u6807\u6a21\u5757</p> <p>peft.utils.constants\u00a0\u29c9</p> </li> </ul>"},{"location":"chapter3/prefix_tuning_tour/prefix_tuning_tour/","title":"Prefix-Tuning\uff1a\u81ea\u52a8\u5316\u6784\u9020Prompts","text":""},{"location":"chapter3/prefix_tuning_tour/prefix_tuning_tour/#_1","title":"\u524d\u8a00","text":"<p>\u5fae\u8c03\uff08fine-tuning\uff09\u4f5c\u4e3a\u5229\u7528\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u6267\u884c\u4e0b\u6e38\u4efb\u52a1\u7684\u6807\u51c6\u65b9\u6cd5\uff0c\u867d\u7136\u6548\u679c\u663e\u8457\uff0c\u5374\u9700\u8981\u4fee\u6539\u6a21\u578b\u7684\u6240\u6709\u53c2\u6570\uff0c\u5bfc\u81f4\u6bcf\u4e2a\u4efb\u52a1\u90fd\u9700\u8981\u5b58\u50a8\u4e00\u4e2a\u5b8c\u6574\u7684\u6a21\u578b\u526f\u672c\uff0c\u9020\u6210\u5b58\u50a8\u6210\u672c\u7684\u4e0a\u5347\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u65af\u5766\u798f\u5927\u5b66\u7684\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6cd5Prefix-Tuning\u00a0\u29c9\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ec5\u4f18\u5316\u4e00\u5c0f\u6bb5\u8fde\u7eed\u7684\u4efb\u52a1\u7279\u5b9a\u5411\u91cf\uff08\u524d\u7f00\uff09\uff0c\u5373\u53ef\u9ad8\u6548\u5730\u5fae\u8c03\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff0c\u800c\u65e0\u9700\u4fee\u6539\u548c\u5b58\u50a8\u6574\u4e2a\u6a21\u578b\u7684\u53c2\u6570\u3002</p>"},{"location":"chapter3/prefix_tuning_tour/prefix_tuning_tour/#_2","title":"\u6280\u672f\u7ec6\u8282","text":""},{"location":"chapter3/prefix_tuning_tour/prefix_tuning_tour/#fine-tuning-vs-prefix-tuning","title":"<code>Fine-Tuning</code> vs <code>Prefix-Tuning</code>","text":"<p>\u4e0a\u56fe\u76f4\u89c2\u5730\u5c55\u793a\u4e86<code>Prefix-Tuning</code>\u548c\u4f20\u7edf<code>Fine-tuning</code>\u7684\u5dee\u5f02\uff1a</p> <ul> <li><code>Fine-Tuning</code>\uff1a\u66f4\u65b0\u6a21\u578b\u7684\u6240\u6709\u53c2\u6570\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u5b58\u50a8\u4e00\u4e2a\u5b8c\u6574\u7684\u6a21\u578b\u526f\u672c\uff08\u56fe\u793a\u9876\u90e8\uff09\u3002</li> <li><code>Prefix-Tuning</code>\uff1a\u4ec5\u4f18\u5316\u524d\u7f00\u90e8\u5206\u7684\u53c2\u6570\uff0c\u5e76\u4e14\u51bb\u7ed3\u6a21\u578b\u7684\u6240\u6709\u53c2\u6570\uff08\u56fe\u793a\u5e95\u90e8\uff09\u3002</li> </ul> <p>\u5907\u6ce8</p> <p><code>Prefix-Tuning</code>\u8fd9\u79cd\u65b9\u6cd5\u5141\u8bb8\u6a21\u578b\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u8bbe\u7f6e\u7279\u5b9a\u6307\u4ee4\u96c6\uff0c\u4ece\u800c\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u7279\u5b9a\u4efb\u52a1\u76f8\u5173\u7684\u8f93\u51fa\u3002</p>"},{"location":"chapter3/prefix_tuning_tour/prefix_tuning_tour/#_3","title":"\u524d\u7f00\u5d4c\u5165","text":"<p><code>Prefix-Tuning</code>\u5728\u9884\u8bad\u7ec3\u7684<code>Transformer</code>\u6a21\u578b\u7684\u6bcf\u4e00\u5c42\u524d\u90fd\u6dfb\u52a0\u4e86\u4e00\u6bb5\u53ef\u8bad\u7ec3\u7684\u524d\u7f00\u5411\u91cf\u3002</p> <ul> <li>\u524d\u7f00\u662f\u6dfb\u52a0\u5728\u8f93\u5165\u5e8f\u5217\u4e4b\u524d\uff0c\u4f5c\u4e3a\u865a\u62df\u7684<code>token</code>\uff0c\u6a21\u578b\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u53ef\u4ee5\u5bf9\u5176\u8fdb\u884c\u5173\u6ce8\u3002</li> <li>\u8fd9\u4e9b\u524d\u7f00\u662f\u81ea\u7531\u53c2\u6570\uff0c\u4e0d\u5bf9\u5e94\u4e8e\u8bcd\u6c47\u8868\u4e2d\u7684\u4efb\u4f55\u7279\u5b9a\u8bcd\u8bed\u3002</li> </ul> <p>\u53e6\u5916\uff1a</p> <ul> <li>\u5bf9\u4e8e\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\uff08\u5982 GPT\uff09\uff0c\u524d\u7f00\u88ab\u6dfb\u52a0\u5230\u6bcf\u4e00\u5c42\u7684\u952e\u548c\u503c\u5411\u91cf\u4e2d\u3002</li> <li>\u5bf9\u4e8e\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\uff08\u5982 BART\uff09\uff0c\u524d\u7f00\u88ab\u5206\u522b\u6dfb\u52a0\u5230\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7684\u6bcf\u4e00\u5c42\u4e2d\u3002</li> </ul> <p>\u5373\u5bf9\u4e8e\u4e00\u4e2a \\(n\\) \u5c42\u7684<code>Transformer</code>\u6a21\u578b\uff0c<code>Prefix-Tuning</code>\u4f1a\u4e3a\u6bcf\u4e00\u5c42\u6dfb\u52a0\u4e00\u5bf9\u524d\u7f00\u5411\u91cf \\(P_i^K, P_i^V \\in \\mathbb{R}^{|P|\\times d}\\)\uff0c\u5176\u4e2d \\(|P|\\) \u662f\u524d\u7f00\u957f\u5ea6\uff0c\\(d\\) \u662f\u9690\u85cf\u72b6\u6001\u7ef4\u5ea6\u3002</p>"},{"location":"chapter3/prefix_tuning_tour/prefix_tuning_tour/#_4","title":"\u53c2\u6570\u66f4\u65b0","text":"<p>\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c<code>Prefix-Tuning</code>\u53ea\u66f4\u65b0\u524d\u7f00\u5411\u91cf\u7684\u53c2\u6570\uff0c\u800c\u4fdd\u6301\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\u4e0d\u53d8\u3002\u8fd9\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a</p> \\[ \\theta = [\\theta_P; \\theta_{LM}] \\tag{1} \\] <p>\u5176\u4e2d \\(\\theta_P\\) \u662f\u53ef\u8bad\u7ec3\u7684\u524d\u7f00\u53c2\u6570\uff0c\\(\\theta_{LM}\\) \u662f\u51bb\u7ed3\u7684\u8bed\u8a00\u6a21\u578b\u53c2\u6570\u3002</p> <p>\u4f18\u5316\u76ee\u6807\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a</p> \\[ \\mathcal{L}(\\phi(x; \\theta_P, \\theta_{LM}), y) \\tag{2} \\] <p>\u5176\u4e2d \\(\\phi\\) \u662f\u6a21\u578b\u8f93\u51fa\uff0c\\(x\\) \u662f\u8f93\u5165\uff0c\\(y\\) \u662f\u76ee\u6807\u8f93\u51fa\uff0c\\(\\mathcal{L}\\) \u662f\u635f\u5931\u51fd\u6570\u3002</p>"},{"location":"chapter3/prefix_tuning_tour/prefix_tuning_tour/#_5","title":"\u91cd\u53c2\u6570\u5316\u6280\u5de7","text":"<p>\u4e3a\u4e86\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\uff0c<code>Prefix-Tuning</code>\u91c7\u7528\u4e86\u4e00\u4e2a\u91cd\u53c2\u6570\u5316\u6280\u5de7\uff1a\u524d\u7f00\u5411\u91cf \\(P_i\\) \u4e0d\u662f\u76f4\u63a5\u4f18\u5316\u7684\uff0c\u800c\u662f\u901a\u8fc7\u4e00\u4e2a\u5c0f\u578b MLP \u7f51\u7edc\u751f\u6210\u7684\uff1a</p> \\[ P_i = \\text{MLP}_\\theta(P'_i) \\tag{3} \\] <p>\u5176\u4e2d \\(P'_i\\) \u662f\u4e00\u4e2a\u8f83\u5c0f\u7684\u77e9\u9635\uff0cMLP \u7f51\u7edc\u5c06\u5176\u6620\u5c04\u5230\u6240\u9700\u7684\u7ef4\u5ea6\u3002\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u51cf\u5c11\u53c2\u6570\u6570\u91cf\uff0c\u5e76\u63d0\u9ad8\u4f18\u5316\u7a33\u5b9a\u6027\u3002</p>"},{"location":"chapter3/prefix_tuning_tour/prefix_tuning_tour/#_6","title":"\u4f18\u52bf","text":"<p><code>Prefix-Tuning</code> \u76f8\u6bd4\u4e8e\u4f20\u7edf\u7684\u5168\u91cf\u5fae\u8c03\u65b9\u6cd5\u6709\u4ee5\u4e0b\u51e0\u4e2a\u663e\u8457\u4f18\u52bf\uff1a</p> <ol> <li>\u53c2\u6570\u6548\u7387\u9ad8\uff1a\u53ea\u9700\u8981\u8bad\u7ec3\u4e00\u5c0f\u90e8\u5206\u524d\u7f00\u53c2\u6570\uff0c\u5927\u5927\u51cf\u5c11\u4e86\u6240\u9700\u7684\u8ba1\u7b97\u8d44\u6e90\u548c\u5b58\u50a8\u7a7a\u95f4\u3002</li> <li>\u6a21\u5757\u5316\uff1a\u6bcf\u4e2a\u4efb\u52a1\u53ea\u9700\u8981\u5b58\u50a8\u4e00\u4e2a\u5c0f\u7684\u524d\u7f00\uff0c\u800c\u4e0d\u662f\u6574\u4e2a\u6a21\u578b\u7684\u526f\u672c\uff0c\u4fbf\u4e8e\u7ba1\u7406\u548c\u90e8\u7f72\u591a\u4e2a\u4efb\u52a1\u3002</li> <li>\u7075\u6d3b\u6027\uff1a\u53ef\u4ee5\u8f7b\u677e\u5730\u4e3a\u65b0\u4efb\u52a1\u6dfb\u52a0\u524d\u7f00\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6574\u4e2a\u6a21\u578b\u3002</li> <li>\u6027\u80fd\u4fdd\u8bc1\uff1a\u5728\u8bb8\u591a\u4efb\u52a1\u4e0a\uff0c<code>Prefix-Tuning</code> \u80fd\u591f\u8fbe\u5230\u4e0e\u5168\u91cf\u5fae\u8c03\u76f8\u5f53\u7684\u6027\u80fd\u3002</li> <li>\u9002\u7528\u4e8e\u5927\u6a21\u578b\uff1a\u7279\u522b\u9002\u5408\u90a3\u4e9b\u53c2\u6570\u6570\u91cf\u5e9e\u5927\u7684\u6a21\u578b\uff0c\u5982 GPT-3\uff0c\u4f7f\u5fae\u8c03\u8fd9\u4e9b\u6a21\u578b\u6210\u4e3a\u53ef\u80fd\u3002</li> </ol>"},{"location":"chapter3/prefix_tuning_tour/prefix_tuning_tour/#_7","title":"\u7ed3\u8bba","text":"<p><code>Prefix-Tuning</code> \u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b80\u5355\u800c\u6709\u6548\u7684\u524d\u7f00\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u9002\u914d\u3002\u5b83\u4e0d\u4ec5\u5927\u5927\u51cf\u5c11\u4e86\u5fae\u8c03\u6240\u9700\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u8fd8\u4fdd\u6301\u4e86\u4e0e\u5168\u53c2\u6570\u5fae\u8c03\u76f8\u5f53\u7684\u6027\u80fd\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u548c\u4e2a\u6027\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002</p>"},{"location":"chapter3/prefix_tuning_tour/prefix_tuning_tour/#_8","title":"\u53c2\u8003\u8d44\u6599","text":"<ol> <li>Li, X. L., &amp; Liang, P. (2021). Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190.\u00a0\u29c9</li> <li>Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., ... &amp; Liu, P. J. (2020). Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140), 1-67.\u00a0\u29c9</li> </ol>"},{"location":"chapter3/prompt_tuning_tour/prompt_tuning_tour/","title":"Prompt-Tuning: Soft Prompts\u5f00\u521b\u8005","text":""},{"location":"chapter3/prompt_tuning_tour/prompt_tuning_tour/#_1","title":"\u524d\u8a00","text":"<p>OpenAI\u63d0\u51faGPT3\u65f6\uff0c\u9a8c\u8bc1\u4e86\u4e3a\u4efb\u52a1\u8bbe\u8ba1\u7279\u5b9a<code>prompt</code>\u53ef\u4ee5\u63d0\u5347\u6a21\u578b\u7684\u8868\u73b0\uff0c\u4f46\u6bcf\u6b21\u9047\u5230\u65b0\u4efb\u52a1\u90fd\u8981\u82b1\u8d39\u5927\u91cf\u7cbe\u529b\u53bb\u8bbe\u8ba1\u5408\u9002\u7684<code>prompt</code>\u5e76\u4e0d\u73b0\u5b9e\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0cGoogle Research\u7684\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86Prompt Tuning\u00a0\u29c9\u65b9\u6cd5\u3002\u8fd9\u79cd\u65b9\u6cd5\u4ec5\u5fae\u8c03\u4e00\u5c0f\u90e8\u5206\u8fde\u7eed\u7684\u201c\u8f6f\u63d0\u793a\u201d\uff08soft prompt\uff09\u53c2\u6570\uff0c\u9ad8\u6548\u5730\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u9002\u914d\u5230\u4e0d\u540c\u7684\u4e0b\u6e38\u4efb\u52a1\uff0c\u8fdb\u800c\u5927\u5927\u7b80\u5316\u4efb\u52a1\u9002\u914d\u7684\u8fc7\u7a0b\u3002</p>"},{"location":"chapter3/prompt_tuning_tour/prompt_tuning_tour/#_2","title":"\u6280\u672f\u7ec6\u8282","text":""},{"location":"chapter3/prompt_tuning_tour/prompt_tuning_tour/#prompt-tuning","title":"<code>Prompt Tuning</code>\u8bad\u7ec3\u65b9\u6cd5","text":"<ol> <li>\u8bbe\u8ba1\u63d0\u793a: \u6839\u636e\u4efb\u52a1\u9009\u62e9\u786c\u63d0\u793a\uff08\u56fa\u5b9a\u6587\u672c\uff09\u6216\u8f6f\u63d0\u793a\uff08\u53ef\u8bad\u7ec3\u5411\u91cf\uff09\u4f5c\u4e3a\u8f93\u5165\u3002</li> <li>\u878d\u5165\u8f93\u5165: \u786c\u63d0\u793a\u76f4\u63a5\u52a0\u5165\u6587\u672c\uff0c\u8f6f\u63d0\u793a\u4f5c\u4e3a\u5411\u91cf\u52a0\u5165\u5e8f\u5217\uff0c\u6307\u5bfc\u6a21\u578b\u751f\u6210\u4efb\u52a1\u7279\u5b9a\u7684\u8f93\u51fa\u3002</li> <li>\u8bad\u7ec3\u8fc7\u7a0b: \u786c\u63d0\u793a\u4e0b\u8fdb\u884c\u5168\u9762\u5fae\u8c03\u6a21\u578b\uff1b\u8f6f\u63d0\u793a\u4e0b\u53ea\u8c03\u6574\u63d0\u793a\u5411\u91cf\uff0c\u5176\u4ed6\u53c2\u6570\u4e0d\u53d8\u3002</li> <li>\u6267\u884c\u4efb\u52a1: \u8bad\u7ec3\u540e\u6a21\u578b\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u95ee\u7b54\u3001\u6458\u8981\uff09\uff0c\u8f93\u51fa\u7531\u63d0\u793a\u5f15\u5bfc\u3002</li> </ol> <p>\u8fd9\u79cd\u65b9\u6cd5\u7684\u72ec\u7279\u4e4b\u5904\u5728\u4e8e\uff0c\u5b83\u5c06\u4efb\u52a1\u9002\u914d\u4fe1\u606f\u6d53\u7f29\u5728\u4e00\u5c0f\u7ec4\u8fde\u7eed\u5411\u91cf\u4e2d\uff0c\u800c\u4e0d\u662f\u5206\u6563\u5728\u6574\u4e2a\u6a21\u578b\u7684\u53c2\u6570\u4e2d\u3002\u8fd9\u5927\u5927\u964d\u4f4e\u4e86\u6bcf\u4e2a\u4efb\u52a1\u7684\u53c2\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u5168\u91cf\u5fae\u8c03\u76f8\u5f53\u7684\u6027\u80fd\u3002</p>"},{"location":"chapter3/prompt_tuning_tour/prompt_tuning_tour/#_3","title":"\u6a21\u578b\u7ed3\u6784","text":"<p><code>Prompt Tuning</code>\u57fa\u4e8e<code>T5</code>\u7b49\u7f16\u7801\u5668\u89e3\u7801\u5668\u67b6\u6784\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3002</p> <p>\u5177\u4f53\u6765\u8bf4:</p> <ol> <li>\u5728\u8f93\u5165\u7aef\u6dfb\u52a0\u4e00\u6bb5\u53ef\u8bad\u7ec3\u7684\u8fde\u7eed\u5411\u91cf\u5e8f\u5217\uff08\u8f6f\u63d0\u793a\uff09\uff1b</li> <li>\u5c06\u8f6f\u63d0\u793a\u4e0e\u5206\u8bcd\u540e\u7684\u6587\u672c\u62fc\u63a5\uff1b</li> <li>\u9001\u5165\u7f16\u7801\u5668\u8fdb\u884c\u7f16\u7801\uff1b</li> <li>\u89e3\u7801\u5668\u6839\u636e\u7f16\u7801\u5668\u8f93\u51fa\u751f\u6210\u76ee\u6807\u5e8f\u5217\u3002</li> </ol> <p>\u6a21\u578b\u7ed3\u6784\u793a\u610f\u56fe\u5982\u4e0b:</p> Text Only<pre><code>Input: [Soft Prompt] [Input Tokens]\n        \u2193\nEncoder: Frozen Pre-trained Parameters\n        \u2193\nDecoder: Frozen Pre-trained Parameters\n        \u2193\nOutput: [Generated Tokens]\n</code></pre>"},{"location":"chapter3/prompt_tuning_tour/prompt_tuning_tour/#_4","title":"\u53c2\u6570\u521d\u59cb\u5316","text":"<p>\u8f6f\u63d0\u793a\u53c2\u6570\u7684\u521d\u59cb\u5316\u5bf9\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\u3002</p> <p>\u5e38\u7528\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u5305\u62ec:</p> <ol> <li>\u968f\u673a\u521d\u59cb\u5316\uff1a\u4ece\u5747\u5300\u5206\u5e03\u6216\u6b63\u6001\u5206\u5e03\u4e2d\u91c7\u6837\u3002</li> <li>\u8bcd\u8868\u91c7\u6837\uff1a\u4ece\u6a21\u578b\u8bcd\u8868\u4e2d\u968f\u673a\u91c7\u6837token\u7684embedding\u3002</li> <li>\u7c7b\u522b\u8bcd\u521d\u59cb\u5316\uff1a\u4f7f\u7528\u4efb\u52a1\u8f93\u51fa\u7c7b\u522b\u5bf9\u5e94token\u7684embedding\u3002</li> </ol> <p>\u5b9e\u9a8c\u8868\u660e\uff0c\u7c7b\u522b\u8bcd\u521d\u59cb\u5316\u901a\u5e38\u80fd\u83b7\u5f97\u6700\u597d\u7684\u6548\u679c\u3002</p>"},{"location":"chapter3/prompt_tuning_tour/prompt_tuning_tour/#_5","title":"\u8bad\u7ec3\u8fc7\u7a0b","text":"<p>\u8bad\u7ec3\u8fc7\u7a0b\u4e0e\u4f20\u7edf\u7684\u5fae\u8c03\u7c7b\u4f3c\uff0c\u4f46\u53ea\u66f4\u65b0\u8f6f\u63d0\u793a\u53c2\u6570:</p> <ol> <li>\u51c6\u5907\u4efb\u52a1\u6570\u636e\uff0c\u6dfb\u52a0\u8f6f\u63d0\u793a</li> <li>\u524d\u5411\u4f20\u64ad\uff0c\u8ba1\u7b97\u635f\u5931</li> <li>\u53cd\u5411\u4f20\u64ad\uff0c\u4ec5\u66f4\u65b0\u8f6f\u63d0\u793a\u53c2\u6570</li> <li>\u91cd\u590d\u6b65\u9aa42-3\u76f4\u5230\u6536\u655b</li> </ol> <p>\u8bad\u7ec3\u76ee\u6807\u662f\u6700\u5927\u5316\u6761\u4ef6\u6982\u7387:</p> \\[ \\max_{\\theta_P} \\log P(Y|[P;X], \\theta) \\tag{1} \\] <p>\u5176\u4e2d \\(\\theta_P\\) \u662f\u8f6f\u63d0\u793a\u53c2\u6570\uff0c\\(P\\) \u662f\u8f6f\u63d0\u793a\uff0c\\(X\\) \u662f\u8f93\u5165\uff0c\\(Y\\) \u662f\u76ee\u6807\u8f93\u51fa\uff0c\\(\\theta\\) \u662f\u51bb\u7ed3\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u3002</p>"},{"location":"chapter3/prompt_tuning_tour/prompt_tuning_tour/#_6","title":"\u63a8\u7406\u8fc7\u7a0b","text":"<p>\u63a8\u7406\u65f6\uff0c\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u8f6f\u63d0\u793a:</p> <ol> <li>\u5c06\u8bad\u7ec3\u597d\u7684\u8f6f\u63d0\u793a\u4e0e\u65b0\u7684\u8f93\u5165\u62fc\u63a5</li> <li>\u9001\u5165\u6a21\u578b\u8fdb\u884c\u6b63\u5e38\u7684\u63a8\u7406</li> <li>\u751f\u6210\u4efb\u52a1\u76f8\u5173\u7684\u8f93\u51fa</li> </ol> <p>\u8fd9\u4e2a\u8fc7\u7a0b\u4e0d\u9700\u8981\u989d\u5916\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u4fdd\u6301\u4e86\u539f\u59cb\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u3002</p>"},{"location":"chapter3/prompt_tuning_tour/prompt_tuning_tour/#_7","title":"\u4f18\u52bf","text":"<p><code>Prompt Tuning</code>\u76f8\u6bd4\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u6709\u4ee5\u4e0b\u4f18\u52bf:</p> <ol> <li>\u76f4\u89c2\u6027\uff1a<code>Prompt tuning</code>\u4f7f\u7528\u76f4\u89c2\u7684\u8bed\u8a00\u63d0\u793a\u6765\u5f15\u5bfc\u6a21\u578b\uff0c\u4f7f\u5176\u66f4\u6613\u4e8e\u7406\u89e3\u548c\u64cd\u4f5c\u3002</li> <li>\u9002\u7528\u6027\uff1a\u8fd9\u79cd\u65b9\u6cd5\u7279\u522b\u9002\u7528\u4e8e\u90a3\u4e9b\u9884\u8bad\u7ec3\u6a21\u578b\u5df2\u7ecf\u638c\u63e1\u4e86\u5927\u91cf\u901a\u7528\u77e5\u8bc6\u7684\u60c5\u51b5\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u63d0\u793a\u5c31\u80fd\u6fc0\u53d1\u7279\u5b9a\u7684\u54cd\u5e94\u3002</li> <li>\u5fae\u8c03\u6210\u672c\u4f4e\uff1a<code>Prompt tuning</code>\u53ef\u4ee5\u5728\u5fae\u8c03\u65f6\u51cf\u5c11\u6240\u9700\u8ba1\u7b97\u8d44\u6e90\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u6027\u80fd\u3002</li> </ol>"},{"location":"chapter3/prompt_tuning_tour/prompt_tuning_tour/#_8","title":"\u7ed3\u8bba","text":"<ol> <li> <p><code>Prompt Tuning</code>\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u9002\u914d\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u8303\u5f0f\u3002\u5b83\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5927\u5927\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u5b58\u50a8\u6210\u672c\u3002\u8fd9\u79cd\u65b9\u6cd5\u7279\u522b\u9002\u5408\u4e8e\u53c2\u6570\u91cf\u8d85\u8fc7\u6570\u5341\u4ebf\u7684\u8d85\u5927\u6a21\u578b\uff0c\u4e3a\u8fd9\u4e9b\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\u94fa\u5e73\u4e86\u9053\u8def\u3002</p> </li> <li> <p>\u5c3d\u7ba1\u5982\u6b64\uff0c<code>Prompt Tuning</code>\u4ecd\u7136\u5b58\u5728\u4e00\u4e9b\u5c40\u9650\u6027\uff0c\u4f8b\u5982\u5728\u5c0f\u6a21\u578b\u4e0a\u6548\u679c\u4e0d\u4f73\u3001\u5bf9\u63d0\u793a\u957f\u5ea6\u548c\u521d\u59cb\u5316\u654f\u611f\u7b49\u3002\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u5305\u62ec\u6539\u8fdb\u63d0\u793a\u7684\u8868\u793a\u65b9\u5f0f\u3001\u63a2\u7d22\u66f4\u597d\u7684\u521d\u59cb\u5316\u7b56\u7565\u3001\u5c06<code>Prompt Tuning</code>\u4e0e\u5176\u4ed6\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u7ed3\u5408\u7b49\u3002</p> </li> </ol>"},{"location":"chapter3/prompt_tuning_tour/prompt_tuning_tour/#_9","title":"\u53c2\u8003\u8d44\u6599","text":"<ol> <li>Lester, B., Al-Rfou, R., &amp; Constant, N. (2021). The Power of Scale for Parameter-Efficient Prompt Tuning.\u00a0\u29c9</li> <li>Liu, X., et al. (2021). GPT Understands, Too. arXiv preprint arXiv:2103.10385.\u00a0\u29c9</li> <li>Brown, T., et al. (2020). Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems.\u00a0\u29c9</li> </ol>"},{"location":"chapter5/diffusers_index/","title":"\u7d22\u5f15","text":"<p>\u4e3b\u9875</p> <ul> <li>\u6269\u6563\u6a21\u578b\u6570\u5b66\u539f\u7406</li> </ul>"},{"location":"chapter5/ddpm/ddpm_math/","title":"\u6269\u6563\u6a21\u578b\u6570\u5b66\u539f\u7406","text":""},{"location":"chapter5/ddpm/ddpm_math/#_1","title":"\u524d\u5411\u6269\u6563","text":"<p>\u73b0\u5728\u5047\u5b9a\u6709\u4e00\u5f20\u50cf\u7d20\u503c\u8303\u56f4\u4e3a <code>[0, 255]</code> \u7684\u5f69\u8272 <code>RGB</code> \u56fe\u50cf \\(x_0\\) \u3002</p> <p>\u521b\u5efa\u548c\u8f93\u5165\u56fe\u50cf\u5f62\u72b6\u5b8c\u5168\u4e00\u6837\uff0c\u670d\u4ece\u6b63\u6001\u5206\u5e03\u7684\u968f\u673a\u566a\u58f0 \\(\\epsilon\\) \u3002</p> <p>\u7136\u540e\u5229\u7528\u516c\u5f0f 1 \u5c06\u56fe\u7247 \\(x\\) \u548c\u9ad8\u65af\u566a\u58f0 \\(\\epsilon\\) \u8fdb\u884c\u52a0\u6743\u6df7\u5408\u3002\u5176\u4e2d \\(\\beta\\) \u662f\u4ecb\u4e8e \\(0\\) \u548c \\(1\\) \u4e4b\u95f4\u7684\u6570\u5b57\u3002\u53ef\u4ee5\u770b\u51fa\u968f\u7740 \\(\\beta\\) \u7684\u53d8\u5316\uff0c\u56fe\u50cf\u548c\u566a\u58f0\u8fdb\u884c\u6df7\u5408\u7684\u65f6\u5019\u5404\u81ea\u7684\u6743\u91cd\u6b64\u6d88\u5f7c\u957f\u3002</p> \\[ \\sqrt{\\beta}\\times\\epsilon+\\sqrt{1-\\beta}\\times x \\tag{1} \\] <p></p> <p>\u9996\u5148\u6709\u539f\u59cb\u56fe\u50cf \\(x_0\\) \uff0c\u540e\u7eed\u7684 \\(x_t\\) \u662f\u7531\u56fe\u50cf \\(x_{t-1}\\) \u548c\u968f\u673a\u9ad8\u65af\u566a\u58f0 \\(\\epsilon_t\\) \u52a0\u6743\u6df7\u5408\u800c\u6210\u3002\u4e5f\u5c31\u662f\u8bf4\u540e\u4e00\u65f6\u523b\u7684\u566a\u58f0\u56fe\u50cf\u662f\u7531\u524d\u4e00\u65f6\u523b\u7684\u56fe\u50cf\u52a0\u4e0a\u5f53\u524d\u65f6\u523b\u7684\u9ad8\u65af\u566a\u58f0\u4ea7\u751f\u7684\u3002</p> <p>\u5c06\u4e0a\u9762\u7684\u8fc7\u7a0b\u5f62\u5f0f\u5316\uff0c\u4e5f\u5c31\u662f\u7528\u6570\u5b66\u516c\u5f0f\u5bf9\u8fd9\u4e2a\u8fc7\u7a0b\u8fdb\u884c\u8868\u793a\u3002</p> <p>\u5bf9\u4e8e \\(x_1\\) \u7684\u4ea7\u751f\uff1a</p> \\[ x_1 = \\sqrt{\\beta_1} \\times \\epsilon_1 + \\sqrt{1 - \\beta_1} \\times x_{0} \\tag{2} \\] <p>\u5bf9\u4e8e \\(x_2\\) \u7684\u4ea7\u751f\uff1a</p> \\[ x_2 = \\sqrt{\\beta_{2}} \\times \\epsilon_2 + \\sqrt{1 - \\beta_{2}} \\times x_{1} \\tag{3} \\] <p>\u5bf9\u4e8e \\(x_3\\) \u7684\u4ea7\u751f\uff1a</p> \\[ x_3 = \\sqrt{\\beta_{3}} \\times \\epsilon_3 + \\sqrt{1 - \\beta_{3}} \\times x_{2} \\tag{4} \\] <p>\u4ee5\u6b64\u7c7b\u63a8 \\(\\ldots\\)</p> \\[ \\vdots \\] <p>\u5bf9\u4e8e \\(x_t\\) \u7684\u4ea7\u751f\uff1a</p> \\[ x_t = \\sqrt{\\beta_{t}} \\times \\epsilon_t + \\sqrt{1 - \\beta_{t}} \\times x_{t-1} \\tag{5} \\] <p>\u6211\u4eec\u53d1\u73b0\u89c4\u5f8b\uff1a</p> \\[ x_T = \\sqrt{\\beta_T} \\times \\epsilon_{T} + \\sqrt{1 - \\beta_{T}}  \\times x_{T-1} \\tag{6} \\] <ul> <li>\u5176\u4e2d \\(\\epsilon_t\\) \u548c\u5176\u4ed6\u4efb\u610f\u65f6\u523b\u7684 \\(\\epsilon_i\\) \\((i\u2260t)\\) \u90fd\u662f\u72ec\u7acb\u540c\u5206\u5e03\u7684\uff0c\\(\\epsilon_t \\sim N(0, 1)\\)\u3002\u4e5f\u5c31\u662f\u4efb\u610f\u4fe9\u65f6\u523b\u7684\u566a\u58f0\u662f\u4e92\u4e0d\u5f71\u54cd\u7684\u3002</li> <li>\u7279\u522b\u6ce8\u610f\u4e00\u4e0b\uff0c\\(0&lt;\\beta_1&lt;\\beta_2&lt;\\beta_3&lt;\\ldots&lt;\\beta_{t-1}&lt;\\beta_{t}&lt;1\\)\uff0c\u5728\u4e00\u5f00\u59cb\u7684 \\(\\beta\\) \u53d6\u503c\u8f83\u5c0f\uff0c\u4e5f\u5c31\u662f\u566a\u58f0\u7684\u6743\u91cd\u8f83\u5c0f\uff0c\u8d8a\u5f80\u540e\u7684 \\(\\beta\\) \u7684\u53d6\u503c\u9010\u6e10\u53d8\u5927\uff0c\u4e5f\u5c31\u662f\u566a\u58f0\u7684\u6743\u91cd\u8f83\u5927\u3002</li> <li>\u89c4\u5f8b\u5c31\u662f\u5728\u524d\u671f\u56fe\u50cf\u7684\u6269\u6563\u901f\u7387\u8f83\u4f4e\uff0c\u5230\u540e\u671f\u56fe\u50cf\u7684\u6269\u6563\u901f\u7387\u9010\u6b65\u52a0\u5feb\u3002</li> </ul> <p>\u4e3a\u4e86\u7b80\u5316\u540e\u7eed\u7684\u63a8\u5bfc\uff0c\u5728\u8fd9\u91cc\u7528 \\(\\alpha_t\\) \u53d6\u4ee3 \\(1-\\beta_t\\)\u3002</p> <p>\u6240\u4ee5\u516c\u5f0f\u53c8\u80fd\u5199\u6210\uff1a</p> \\[ x_T = \\sqrt{1 - \\alpha_T} \\times \\epsilon_T + \\sqrt{\\alpha_{T}}  \\times x_{T-1} \\tag{7} \\] <p>\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u4f7f\u7528\u516c\u5f0f 7 \u641e\u4ebf\u70b9\u4e8b\u60c5\u3002</p> <p></p> <p>\u4f7f\u7528\u516c\u5f0f 7 \u6211\u4eec\u53ef\u4ee5\u4ece\u56fe\u50cf \\(x_0\\) \u4e00\u6b65\u6b65\u8fed\u4ee3\u5230 \\(x_t\\) \uff0c\u4f46\u662f\u5f88\u591a\u65f6\u5019\u6211\u4eec\u5c31\u662f\u60f3\u4e00\u6b65\u5230\u4f4d\uff0c\u6211\u73b0\u5728\u5c31\u662f\u60f3\u907f\u5f00\u8fd9\u6837\u7684\u4e00\u4e2a\u5faa\u73af\u8fc7\u7a0b\uff0c\u4ece \\(x_0\\) \u5230 \\(x_t\\) \u4e00\u6b65\u5230\u4f4d, \u6216\u8005\u5230\u4efb\u610f\u65f6\u523b\u3002</p> <p>\u80fd\u505a\u5230\u5417\uff1f</p> <p>\u9996\u5148\u6211\u4eec\u6709\uff1a</p> \\[ x_t = \\sqrt{1 - \\alpha_t} \\times\\epsilon_t + \\sqrt{\\alpha_t} \\times x_{t-1}\\tag{8} \\] <p>\u7136\u540e\u8fd8\u6709\uff1a</p> \\[ x_{t-1} = \\sqrt{1 - \\alpha_{t-1}} \\times\\epsilon_{t-1} + \\sqrt{\\alpha_{t-1}} \\times x_{t-2}\\tag{9} \\] <p>\u7136\u540e\u8fd8\u6709\uff1a</p> \\[ x_{t-2} = \\sqrt{1 - \\alpha_{t-2}} \\times\\epsilon_{t-2} + \\sqrt{\\alpha_{t-2}} \\times x_{t-3}\\tag{10} \\] <p>\u8fd8\u6709\u5f88\u591a\u5f88\u591a\uff0c\u4e00\u76f4\u5230\uff1a</p> \\[ \\vdots \\] \\[ x_1 = \\sqrt{1 - \\alpha_{1}} \\times\\epsilon_{1} + \\sqrt{\\alpha_{1}} \\times x_0\\tag{11} \\] <p>\u53ef\u4ee5\u770b\u5230\u597d\u50cf\uff0c\u4ec5\u4ec5\u662f\u597d\u50cf\u53ea\u8981\u77e5\u9053\u8fd9\u4e00\u65f6\u523b\u7684\u56fe\u50cf\u5c31\u80fd\u8868\u793a\u51fa\u540e\u4e00\u65f6\u523b\u7684\u56fe\u50cf\uff0c\u90a3\u4e48\u6211\u4eec\u5c06\u8fd9\u4e9b\u516c\u5f0f\u5408\u5e76\u8d77\u6765\uff0c\u770b\u770b\u80fd\u7528 \\(x_0\\) \u6765\u8868\u793a \\(x_t\\) \u5417\uff1f</p> <p>\u9996\u5148\u5408\u5e76\u516c\u5f0f 8 \u548c\u516c\u5f0f 9 \u6211\u4eec\u5f97\u5230\uff1a</p> \\[ x_t = \\sqrt{1 - \\alpha_{t}} \\times\\epsilon_{t} + \\sqrt{\\alpha_{t}(1 - \\alpha_{t-1})} \\times{\\epsilon_{t-1}} + \\sqrt{\\alpha_t\\alpha_{t-1}}\\times x_{t-2}\\tag{12} \\] <p>\u518d\u628a\u516c\u5f0f 10 \u548c\u4e0a\u5f0f\u516c\u5f0f 12 \u5408\u5e76\u80fd\u591f\u5f97\u51fa\uff1a</p> \\[ x_t = \\sqrt{1 - \\alpha_{t}} \\times\\epsilon_{t} + \\sqrt{\\alpha_{t}(1 - \\alpha_{t-1})} \\times{\\epsilon_{t-1}} + \\sqrt{\\alpha_{t}\\alpha_{t-1}(1-\\alpha_{t-2})}\\times{\\epsilon_{t-2}}+\\sqrt{\\alpha_t\\alpha_{t-1}\\alpha_{t-2}}\\times x_{t-3}\\tag{13} \\] <p>\u8fd9\u6837\u4e00\u76f4\u5408\u5e76\u4e0b\u53bb\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\uff1a</p> \\[ x_t = \\boxed{\\sqrt{1 - \\alpha_{t}} \\times\\epsilon_{t} + \\sqrt{\\alpha_{t}(1 - \\alpha_{t-1})} \\times{\\epsilon_{t-1}} + \\sqrt{\\alpha_{t}\\alpha_{t-1}(1-\\alpha_{t-2})}\\times{\\epsilon_{t-2}}+\\cdots + \\sqrt{\\alpha_{t}\\alpha_{t-1}\\alpha_{t-2}\\cdots(1-\\alpha_{1})}\\times{\\epsilon_{1}}} +\\\\\\sqrt{\\alpha_t\\alpha_{t-1}\\alpha_{t-2}\\alpha_{t-3}\\cdots\\alpha_{2}\\alpha_{1}}\\times x_0\\tag{14} \\] <p>\u8fd9\u4e2a\u516c\u5f0f\u53ef\u80fd\u590d\u6742\u4e86\u4e00\u70b9\uff0c\u4f46\u662f\u4f60\u8981\u662f\u6709\u8010\u5fc3\u4e00\u70b9\u70b9\u8fdb\u884c\u5408\u5e76\u662f\u53ef\u4ee5\u987a\u7406\u6210\u7ae0\u63a8\u5bfc\u51fa\u6765\u7684\u3002</p> <p>\u6211\u4eec\u770b\u77e9\u5f62\u6846\u5185\u7684\u6bcf\u4e2a \\(\\epsilon\\) \uff0c\u6bcf\u4e2a \\(\\epsilon\\) \u90fd\u670d\u4ece\u5747\u503c\u4e3a \\(0\\) \uff0c\u65b9\u5dee\u4e3a \\(1\\) \u7684\u6b63\u6001\u5206\u5e03\u3002\u90a3\u4e48\u6bcf\u4e2a\u6b63\u6001\u5206\u5e03\u6240\u6709\u7684\u53ef\u80fd\u53bb\u4e58\u4ee5\u540c\u4e00\u4e2a\u6570\u4f1a\u5bfc\u81f4\u5176\u65b9\u5dee\u53d8\u5316\u3002</p> \u5206\u5e03 \u5747\u503c \u65b9\u5dee \\(\\sqrt{1 - \\alpha_{t}} \\times\\epsilon_{t}\\) \\(0\\) \\(1 - \\alpha_{t}\\) \\(\\sqrt{\\alpha_{t}(1 - \\alpha_{t-1})} \\times{\\epsilon_{t-1}}\\) \\(0\\) \\(\\alpha_{t}(1 - \\alpha_{t-1})\\) \\(\\sqrt{\\alpha_{t}\\alpha_{t-1}(1-\\alpha_{t-2})}\\times{\\epsilon_{t-2}}\\) \\(0\\) \\(\\alpha_{t}\\alpha_{t-1}(1-\\alpha_{t-2})\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\sqrt{\\alpha_{t}\\alpha_{t-1}\\alpha_{t-2}\\cdots(1-\\alpha_{1})}\\times{\\epsilon_{1}}\\) \\(0\\) \\(\\alpha_{t}\\alpha_{t-1}\\alpha_{t-2}\\cdots(1-\\alpha_{1})\\) <p>\u5230\u8fd9\u91cc\uff0c\u6211\u4eec\u8fd8\u77e5\u9053\u5c31\u662f\u591a\u4e2a\u7b26\u5408\u6b63\u6001\u5206\u5e03\u7684\u5206\u5e03\u548c\u8fdb\u884c\u53e0\u52a0\u540e\u7684\u5206\u5e03\u8fd8\u662f\u7b26\u5408\u6b63\u6001\u5206\u5e03\u7684\uff0c\u5176\u524d\u540e\u5747\u503c\u548c\u65b9\u5dee\u8fd8\u6ee1\u8db3\u4e00\u5b9a\u7684\u89c4\u5f8b\uff0c\u8fd9\u91cc\u4e0d\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u3002</p> <p>\u90a3\u4e48\u5c31\u53ef\u4ee5\u5229\u7528\u91cd\u53c2\u6570\u5316\u6280\u5de7\u5f97\u51fa\uff1a\u516c\u5f0f 14 \u7684\u77e9\u5f62\u6846\u533a\u57df\u7684\u5206\u5e03\u662f\u670d\u4ece\u5747\u503c\u4e3a \\(0\\) \uff0c\u65b9\u5dee\u4e3a \\(\\boxed{1 - \\alpha_{t}\\alpha_{t-1}\\alpha_{t-2}\\cdots\\alpha_{3}\\alpha_{2}\\alpha_{1}}\\) \u7684\u6b63\u6001\u5206\u5e03\u3002</p> \\[ x_t = \\boxed{\\sqrt{ (1 - \\alpha_{t}\\alpha_{t-1}\\alpha_{t-2}\\cdots\\alpha_{3}\\alpha_{2}\\alpha_{1}}) \\times \\epsilon } + \\sqrt{\\alpha_t\\alpha_{t-1}\\alpha_{t-2}\\alpha_{t-3}\\cdots\\alpha_{2}\\alpha_{1}}\\times x_0\\tag{15} \\] <p>\u8fd9\u6837\u7684\u5173\u7cfb\u5f0f\u8fd8\u662f\u5f88\u5197\u957f\uff0c\u7528 \\(\\bar{\\alpha}_t\\) \u6765\u7b49\u4ef7\u4e8e \\(\\boxed{\\alpha_{t}\\alpha_{t-1}\\alpha_{t-2}\\cdots\\alpha_{3}\\alpha_{2}\\alpha_{1}}\\)\u3002\u90a3\u4e48\u516c\u5f0f\u5c31\u80fd\u5199\u6210\uff1a</p> \\[ x_t = \\boxed{\\sqrt{ (1 - \\bar{\\alpha}_t)}\\times \\epsilon } + \\sqrt{\\bar{\\alpha}_t}\\times x_0\\tag{16} \\] <p>\u73b0\u5728\u4ece\u4e0a\u5f0f\u6765\u770b\uff0c\u53ea\u8981\u7ed9\u5b9a\u4e00\u4e2a\u968f\u673a\u566a\u58f0\u5206\u5e03 \\(\\epsilon\\) \uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u80fd\u4ece \\(x_0\\) \u4e00\u6b65\u5230\u4f4d\u52a0\u5165\u566a\u58f0 \\(\\epsilon\\) \u53d8\u6210 \\(x_t\\) \u3002</p>"},{"location":"chapter5/ddpm/ddpm_math/#_2","title":"\u53cd\u5411\u8fc7\u7a0b","text":"<p>\u521a\u624d\u4ecb\u7ecd\u7684\u662f\u4ece\u4e00\u5f20\u6ca1\u6709\u566a\u58f0\u7684\u56fe\u5982\u4f55\u6709\u89c4\u5f8b\u7684\u52a0\u5165\u566a\u58f0\uff0c\u73b0\u5728\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u5f20\u51e0\u4e4e\u90fd\u662f\u566a\u58f0\u7684\u56fe\u7247\uff0c\u6211\u4eec\u5e0c\u671b\u6709\u4e00\u79cd\u80fd\u591f\u548c\u524d\u5411\u6269\u6563\u5b8c\u5168\u76f8\u53cd\u7684\u8fc7\u7a0b\uff0c\u4e3a\u4ec0\u4e48\u9700\u8981\u5462\uff1f</p> <p>\u521a\u624d\u662f\u4ece \\(x_0\\) \u5230 \\(x_t\\) \uff0c\u6211\u4eec\u60f3\u77e5\u9053\u6709\u6ca1\u6709\u4e00\u79cd\u65b9\u6cd5\u80fd\u4ece \\(x_t\\) \u5927\u81f4\u7684\u77e5\u9053 \\(x_0\\) \uff0c\u8fd9\u6837\u53ea\u8981\u7ed9\u6211\u4e00\u5f20\u566a\u58f0\u56fe\uff0c\u90a3\u4e48\u6211\u4e00\u5b9a\u80fd\u751f\u6210\u4e00\u5f20\u548c\u539f\u59cb\u56fe\u50cf\u5206\u5e03\u76f8\u4f3c\u7684\u56fe\u50cf\u3002</p> <p>\u5148\u628a\u9700\u8981\u7528\u5230\u7684\u516c\u5f0f\u5199\u4e0b\u6765\u3002</p> \\[ x_t = \\sqrt{1 - \\alpha_t} \\times\\epsilon_t + \\sqrt{\\alpha_t} \\times x_{t-1}\\tag{17} \\] \\[ x_t = \\sqrt{ 1 - \\bar{\\alpha}_t}\\times \\epsilon + \\sqrt{\\bar{\\alpha}_t}\\times x_0\\tag{18} \\] \\[ P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\\tag{19} \\] <p>\u5173\u4e8e\u8d1d\u53f6\u65af\u516c\u5f0f\uff08\u516c\u5f0f 19\uff09\uff0c\u8865\u5145\u4e00\u70b9\uff0c\u5047\u5982 \\(A\\)\uff0c\\(B\\) \u4e8b\u4ef6\u7684\u53d1\u751f\u6709\u5148\u540e\u987a\u5e8f\uff0c\u5c31\u5047\u5b9a \\(A\\) \u65f6\u95f4\u5148\u4e8e \\(B\\) \u4e8b\u4ef6\u53d1\u751f\u3002\u90a3\u4e48\u6211\u80fd\u901a\u8fc7\u516c\u5f0f 19 \u83b7\u5f97\u5728\u5df2\u77e5 \\(B\\) \u5df2\u7ecf\u53d1\u751f\u7684\u60c5\u51b5\u4e0b\uff0c\u53d1\u751f\u4e86 \\(A\\)  \u7684\u6982\u7387\u662f\u591a\u5c11\u3002</p> <p>\u90a3\u4e48\u7ed3\u5408\u4f8b\u5b50\u6765\u8bb2\uff0c\u77e5\u9053\u4e86\u524d\u5411\u6269\u6563\u7684\u8fd9\u4e00\u4e8b\u4ef6\u7684\u5177\u4f53\u8fc7\u7a0b\uff0c\u73b0\u5728\u6211\u4eec\u5c31\u53ef\u4ee5\u5229\u7528\u8fd9\u4e2a\u8fc7\u7a0b\u6839\u636e\u5df2\u7ecf\u53d1\u751f\u7684\u524d\u5411\u6269\u6563\u5f97\u5230\u524d\u4e00\u65f6\u523b\u566a\u58f0\u56fe\u3002</p> <p>\u6211\u4eec\u7528 \\(P (x_{t-1}|x_t)\\) \u6765\u8868\u793a\u7ed9\u5b9a \\(x_t\\) \u7684\u60c5\u51b5\u4e0b\u662f\u56fe\u50cf \\(x_{t-1}\\) \u7684\u6982\u7387\u3002\u7ed3\u5408\u8d1d\u53f6\u65af\u516c\u5f0f\u90a3\u4e48\u53ef\u4ee5\u5f97\u5230\uff1a</p> \\[ P(x_{t-1}|x_t) = \\frac{P(x_t|x_{t-1})P(x_{t-1})}{P(x_t)} = \\frac{P(x_t|x_{t-1})P(x_{t-1}|x_0)}{P(x_t|x_0)} \\tag{20} \\] <p>\u4e3a\u4e86\u4e25\u8c28\u66f4\u65b0\u4e00\u4e0b\u516c\u5f0f\uff0c\u8fd9\u6837\u5c31\u662f\u8bf4\u90fd\u662f\u4ece\u540c\u4e00\u5f20\u539f\u59cb\u56fe\u50cf\u51fa\u53d1\uff1a</p> \\[ P(x_{t-1}|x_t,x_0) = \\frac{P(x_t|x_{t-1},x_0)P(x_{t-1}|x_0)}{P(x_t|x_0)} \\tag{21} \\] <p>\u6211\u4eec\u770b\u770b\u7b49\u5f0f\u53f3\u8fb9\u5404\u4e2a\u6b63\u6001\u5206\u5e03\uff1a</p> \\[ \\boxed{x_t = \\sqrt{1 - \\alpha_t} \\times\\epsilon_t + \\sqrt{\\alpha_t} \\times x_{t-1}} \\sim N(\\sqrt{\\alpha_t} x_{t-1}, 1-\\alpha_t)\\tag{22} \\] \\[ \\boxed{x_t = \\sqrt{ (1 - \\bar{\\alpha}_t)}\\times \\epsilon +\\sqrt{\\bar{\\alpha}_t}\\times x_0} \\sim N(\\sqrt{\\bar{{\\alpha}_t}}x_0,1 - \\bar{\\alpha}_t)\\tag{23} \\] \\[ \\boxed{x_{t-1} = \\sqrt{ (1 - \\bar{\\alpha}_{t-1})}\\times \\epsilon + \\sqrt{\\bar{\\alpha}_{t-1}}\\times x_0} \\sim N(\\sqrt{\\bar{{\\alpha}}_{t-1}}x_0,1 - \\bar{\\alpha}_{t-1})\\tag{24} \\] <p>\u90a3\u4e48\u518d\u8f6c\u5316\u4e00\u4e0b\uff0c\u7528\u6b63\u6001\u5206\u5e03\u8868\u8fbe\u5f0f\u6765\u8868\u793a\u4e0a\u5f0f\uff1a</p> \\[ P(x_{t-1}|x_t,x_0) = \\frac{N(x_t|x_{t-1},x_0)N(x_{t-1}|x_0)}{N(x_t|x_0)} \\tag{25} \\] <p>\u4ed6\u4eec\u5199\u6210\u6b63\u6001\u5206\u5e03\u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u8868\u8fbe\u5f0f\uff1a</p> \\[ P(x_t|x_{t-1}, x_0) = \\frac{1}{{\\sqrt{2\\pi}{\\sqrt{1 - {\\alpha}_t}}}}e^{[-\\frac{1}{2}\\frac{(x_t-\\sqrt{\\bar{\\alpha}_t}x_{t-1})^2}{1-\\alpha_t}]}\\tag{26} \\] \\[ P(x_t|x_0) = \\frac{1}{{\\sqrt{2\\pi}{\\sqrt{1 - \\bar\\alpha_t}}}}e^{[-\\frac{1}{2}\\frac{(x_t-\\sqrt{\\bar{\\alpha}_t}x_{0})^2}{1-\\bar{\\alpha}_{t}}]}\\tag{27} \\] \\[ P(x_{t-1}|x_0) = \\frac{1}{{\\sqrt{2\\pi}{\\sqrt{1 - \\bar{\\alpha}_{t-1}}}}}e^{[-\\frac{1}{2}\\frac{(x_{t-1}-\\sqrt{\\bar{\\alpha}_{t-1}}x_{0})^2}{1-\\bar{\\alpha}_{t-1}}]}\\tag{28} \\] <p>\u6211\u4eec\u5c06\u4e0a\u9762\u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u4ee3\u5165\u516c\u5f0f 25 \u4e2d\uff0c\u7ecf\u8fc7\u5316\u7b80\u5c31\u80fd\u5f97\u5230\uff1a</p> \\[ P(x_{t-1}|x_t,x_0) = \\frac{1}{\\sqrt{2\\pi} \\left({\\color{red}{\\frac{\\sqrt{1-a_t}\\sqrt{1-\\bar{\\alpha}_{t-1}}}{\\sqrt{1-\\bar{\\alpha}_t}}}}\\right)} e^{\\left[-\\frac{\\left(x_{\\boldsymbol{t}-\\mathbf{1}}-\\left({{\\color{purple}\\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}t}x_t+\\frac{\\sqrt{\\bar{\\alpha}{t-1}}(1-\\alpha_t)}{1-\\bar{\\alpha}_t}x_0}}\\right) \\right)^2}{2 { \\left({\\color{red}{\\frac{\\sqrt{1-\\alpha_t}\\sqrt{1-\\bar{\\alpha}_{t-1}}}{\\sqrt{1-\\bar{\\alpha}_t}}}}\\right)}^2}\\right]}\\tag{29} \\] <p>\u4e5f\u5c31\u662f\u8bf4\uff1a</p> \\[ \\begin{aligned}P(x_{t-1}|x_t,x_0)&amp;\\sim N\\left(\\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t+\\frac{\\sqrt{\\bar{\\alpha}_{t-1}}(1-\\alpha_t)}{1-\\bar{\\alpha}_t}x_0,\\left(\\frac{\\sqrt{1-\\alpha_t}\\sqrt{1-\\bar{\\alpha}_{t-1}}}{\\sqrt{1-\\bar{\\alpha}_t}}\\right)^2\\right)\\end{aligned}\\tag{30} \\] <p>\u4f46\u662f\u6211\u4eec\u5fc5\u987b\u8bb0\u5f97\u6211\u4eec\u662f\u60f3\u7528 \\(x_t\\) \u65f6\u523b\u7684\u56fe\u50cf\u53bb\u9884\u6d4b \\(x_{t-1}\\) \u65f6\u523b\u7684\u56fe\u50cf\uff0c\u4e0a\u8ff0\u516c\u5f0f\u7adf\u7136\u51fa\u73b0\u4e86 \\(x_0\\) \uff0c\u8bdd\u8bf4\u56de\u6765\uff0c\u6211\u4eec\u7ec8\u6781\u76ee\u7684\u5c31\u662f\u77e5\u9053  \\(x_0\\) \uff0c\u73b0\u5728\u5374\u9700\u8981 \\(x_0\\) \uff0c\u663e\u7136\u6211\u4eec\u5f97\u60f3\u529e\u6cd5\u66ff\u6362 \\(x_0\\) \u3002</p> <p>\u6b63\u597d\u6709\u8fd9\u4e2a\u516c\u5f0f\uff1a</p> \\[ x_t = \\sqrt{ (1 - \\bar{\\alpha}_t)}\\times \\epsilon + \\sqrt{\\bar{\\alpha}_t}\\times x_0\\tag{31} \\] <p>\u6839\u636e\u8fd9\u4e2a\u516c\u5f0f\u53ef\u4ee5\u7528 \\(x_t\\) \u8868\u793a \\(x_0\\)\uff1a</p> \\[ x_0=\\frac{x_t-\\sqrt{1-\\bar{\\alpha}_t}\\epsilon}{\\sqrt{\\bar{\\alpha}_t}}\\tag{32} \\] <p>\u8fd8\u53ef\u4ee5\u8868\u793a  \\(\\epsilon_t\\) \uff1a</p> \\[ \\epsilon_t=\\frac{x_t-\\sqrt{\\bar{\\alpha}_t}x_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\tag{33} \\] <p>\u518d\u628a\u4e0a\u5f0f\u4ee3\u5165\u516c\u5f0f 30\uff0c\u90a3\u4e48\u5c31\u80fd\u5f97\u5230\uff1a</p> \\[ P(x_{t-1}|x_t,x_0)\\sim N\\left(\\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t+\\frac{\\sqrt{\\bar{\\alpha}_{t-1}}(1-\\alpha_t)}{1-\\bar{\\alpha}_t}\\times\\frac{x_t-\\sqrt{1-\\bar{\\alpha}_t}\\color{red}{\\epsilon}}{\\sqrt{\\bar{\\alpha}_t}},\\left(\\sqrt{\\frac{\\beta_t(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}}\\right)^2\\right)\\tag{34} \\] <p>\u7ecf\u8fc7\u8fd9\u6837\u7684\u8fc7\u7a0b\uff1a</p> \\[ \\begin{aligned} &amp;\\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t+\\frac{\\sqrt{\\bar{\\alpha}_{t-1}}(1-\\alpha_t)}{1-\\bar{\\alpha}_t}\\times\\frac{x_t-\\sqrt{1-\\bar{\\alpha}_t}\\color{red}{\\epsilon}}{\\sqrt{\\bar{\\alpha}_t}}\\\\\\\\=&amp;\\frac{\\sqrt{\\alpha_t}\\left(1-\\overline{\\alpha}_{t-1}\\right)x_t+\\frac{\\sqrt{\\bar{\\alpha}_{t-1}}}{\\sqrt{\\bar{\\alpha}_t}}(1-\\alpha_t)(x_t-\\sqrt{1-\\overline{\\alpha}_t}\\epsilon)}{1-\\overline{\\alpha}_t} \\\\\\\\=&amp;\\frac{\\sqrt{\\alpha_t}\\left(1-\\overline{\\alpha}_{t-1}\\right)x_t+\\frac{1}{\\sqrt{\\alpha_t}}(1-\\alpha_t)(x_t-\\sqrt{1-\\overline{\\alpha}_t}\\epsilon)}{1-\\overline{\\alpha}_t} \\\\\\\\ =&amp;\\frac1{\\sqrt{\\alpha_{t}}}\\frac{\\alpha_{t}\\left(1-\\overline{\\alpha}_{t-1}\\right)x_{t}+(1-\\alpha_{t})x_{t}-(1-\\alpha_{t})\\sqrt{1-\\overline{\\alpha}_{t}}\\epsilon)}{1-\\overline{\\alpha}_{t}} \\\\\\\\ =&amp;\\frac{1}{\\sqrt{\\alpha_{t}}}\\frac{(1-\\overline{\\alpha}_{t})x_{t}-(1-\\alpha_{t})\\sqrt{1-\\overline{\\alpha}_{t}}\\epsilon)}{1-\\overline{\\alpha}_{t}} \\\\\\\\ =&amp;\\frac1{\\sqrt{\\alpha_{t}}}\\left(x_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-\\overline{\\alpha}_{t}}}\\epsilon\\right) \\end{aligned} \\tag{35} \\] <p>\u6211\u4eec\u6574\u7406\u5f97\u5230\uff1a</p> \\[ P(x_{t-1}|x_t,x_0)\\sim N\\left(\\frac1{\\sqrt{\\alpha_{t}}}\\left(x_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-\\overline{\\alpha}_{t}}}\\epsilon_t\\right),\\frac{\\beta_t(1-\\bar{a}_{t-1})}{1-\\bar{a}_t}\\right)\\tag{36} \\] \u7ed3\u8bba <ul> <li>\u6839\u636e\u516c\u5f0f 31 \u53ef\u4ee5\u77e5\u9053\uff0c\u53ea\u8981\u6211\u4eec\u77e5\u9053\u539f\u59cb\u56fe\u50cf \\(x_0\\) \uff0c\u6211\u4eec\u5c31\u80fd\u901a\u8fc7\u76f4\u63a5\u52a0\u5165\u4e00\u4e2a\u566a\u58f0 \\(\\color{red}{\\epsilon}\\) \u53d8\u6210\u566a\u58f0\u56fe\u50cf \\(x_t\\)\u3002</li> <li>\u6839\u636e\u516c\u5f0f 35 \u53ef\u4ee5\u77e5\u9053\uff0c\u53ea\u8981\u6211\u4eec\u77e5\u9053\u4e86\u566a\u58f0 \\(\\color{red}{\\epsilon}\\) \uff0c\u5c31\u80fd\u77e5\u9053\u524d\u4e00\u65f6\u523b\u7684\u56fe\u50cf\u6982\u7387\u5206\u5e03\u3002</li> <li>\u4f46\u662f\u95ee\u9898\u5c31\u5728\u4e8e\u6211\u4eec\u4e0d\u77e5\u9053\u8fd9\u4e2a\u566a\u58f0 \\(\\color{red}{\\epsilon}\\) \uff0c\u90a3\u4e48\u5c31\u80fd\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u5f3a\u5927\u7684\u62df\u5408\u80fd\u529b\uff0c\u7ed9\u5b9a\u4e00\u5f20\u566a\u58f0\u56fe\u53bb\u9884\u6d4b\u566a\u58f0 \\(\\color{red}{\\epsilon_t}\\) \u6765\u83b7\u53d6\u524d\u4e00\u65f6\u523b\u7684\u566a\u58f0\u56fe\u50cf\uff0c\u518d\u5728\u524d\u4e00\u65f6\u523b\u7684\u566a\u58f0\u56fe\u50cf\u53bb\u9884\u6d4b\u53e6\u4e00\u4e2a\u566a\u58f0 \\(\\color{red}{\\epsilon}\\) \u6765\u83b7\u53d6\u524d\u524d\u4e00\u65f6\u523b\u7684\u566a\u58f0\u56fe\u50cf\uff0c\u5982\u6b64\u5faa\u73af\u4e00\u5b9a\u6b65\u6570\u3002\u6700\u7ec8\u5c31\u80fd\u5f97\u51fa\u63a5\u8fd1\u539f\u59cb\u56fe\u50cf\u7684\u56fe\u7247\u3002</li> </ul>"},{"location":"chapter5/ddpm/ddpm_math/#_3","title":"\u53c2\u8003\u8d44\u6599","text":"<ul> <li>\u5927\u767d\u8bddAI | \u56fe\u50cf\u751f\u6210\u6a21\u578bDDPM | \u6269\u6563\u6a21\u578b | \u751f\u6210\u6a21\u578b | \u6982\u7387\u6269\u6563\u53bb\u566a\u751f\u6210\u6a21\u578b\u00a0\u29c9</li> <li>\u5927\u767d\u8bddAI | \u795e\u7ecf\u7f51\u7edc | \u6982\u7387\u7a7a\u95f4 | \u8fb9\u7f18\u6982\u7387 | \u5404\u5411\u540c\u6027\u9ad8\u65af\u5206\u5e03 |\u00a0\u29c9</li> <li>\u4e09\u7ef4\u52a8\u753b\u5c55\u793a AIGC \u6269\u6563\u751f\u6210\u5168\u8fc7\u7a0b\uff01| \u5927\u767d\u8bdd AI | DDPM \u6a21\u578b\u89e3\u6790\u4e4b\u4e09 | \u6269\u6563\u751f\u6210\u6a21\u578b\u00a0\u29c9</li> </ul>"},{"location":"chapter6/code_index/","title":"\u7d22\u5f15","text":"<p>\u4e3b\u9875</p> <ul> <li>\u591a\u6807\u7b7e\u5206\u7c7b:\u9762\u5bf9\u6709\u5bb3\u8a00\u8bba, \u662f\u65f6\u5019\u8ba9AI\u91cd\u62f3\u51fa\u51fb\u4e86</li> <li>\u62bd\u53d6\u5f0f\u9605\u8bfb\u7406\u89e3:CMRC2018</li> <li>\u6587\u672c\u6458\u8981:LCSTS\u77ed\u6587\u672c\u65b0\u95fb\u6458\u8981</li> <li>\u96c6\u88c5\u7bb1\u7f16\u53f7\u4f4d\u7f6e\u68c0\u6d4b:DETR\u76ee\u6807\u68c0\u6d4b</li> <li>\u6587\u672c\u7ffb\u8bd1:\u4e2d\u82f1\u6587\u672c\u7ffb\u8bd1</li> <li>\u7b80\u5355\u53bb\u566a:ddpm-unet</li> </ul>"},{"location":"chapter6/container-detr/container-detr/","title":"\u96c6\u88c5\u7bb1\u7f16\u53f7\u4f4d\u7f6e\u5b9a\u4f4d","text":""},{"location":"chapter6/container-detr/container-detr/#_1","title":"\u524d\u8a00","text":"<p>\u968f\u7740\u5168\u7403\u8d38\u6613\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u96c6\u88c5\u7bb1\u8fd0\u8f93\u5df2\u6210\u4e3a\u56fd\u9645\u8d38\u6613\u4e2d\u4e0d\u53ef\u6216\u7f3a\u7684\u4e00\u90e8\u5206\u3002\u7136\u800c\uff0c\u96c6\u88c5\u7bb1\u4fe1\u606f\u7684\u51c6\u786e\u8bc6\u522b\u4e0e\u7ba1\u7406\u4f9d\u7136\u662f\u7269\u6d41\u884c\u4e1a\u4e2d\u7684\u4e00\u5927\u6311\u6218\u3002</p> <p>\u672c\u6587\u5c06\u4ee5\u8be5\u547d\u9898\u4e3a\u4f9d\u636e\uff0c\u4f7f\u7528HuggingFace\u751f\u6001\u5de5\u5177\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\uff0c\u5f00\u53d1\u8005\u5728\u505a\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u65f6\u5c06\u6570\u636e\u96c6\u8f6c\u5316\u4e3a\u672c\u547d\u9898\u4e00\u81f4\u7684\u6570\u636e\u683c\u5f0f\uff0c\u5feb\u901f\u542f\u52a8\u8bad\u7ec3\u3002</p>"},{"location":"chapter6/container-detr/container-detr/#_2","title":"\u4ee3\u7801","text":""},{"location":"chapter6/container-detr/container-detr/#_3","title":"\u5bfc\u5165\u51fd\u6570\u5e93","text":"Bash<pre><code>pip install -U datasets transformers[torch] evaluate timm albumentations accelerate\n</code></pre> Python<pre><code>import albumentations\nimport numpy as np\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoImageProcessor,\n    AutoModelForObjectDetection,\n    Trainer,\n    TrainingArguments,\n)\n</code></pre>"},{"location":"chapter6/container-detr/container-detr/#_4","title":"\u52a0\u8f7d\u6570\u636e\u96c6","text":"Python<pre><code>data = load_dataset(\"moyanxinxu/container\")\n</code></pre> data<pre><code>DatasetDict({\n    train: Dataset({\n        features: ['image', 'image_id', 'width', 'height', 'objects'],\n        num_rows: 1049\n    })\n    test: Dataset({\n        features: ['image', 'image_id', 'width', 'height', 'objects'],\n        num_rows: 263\n    })\n})\n</code></pre> data[\"train\"][0]<pre><code>{\n    'image': &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1120x1080&gt;,\n    'image_id': 475,\n    'width': 1120,\n    'height': 1080,\n    'objects':\n    {\n        'area': [23562.0],\n        'bbox': [[415.0, 592.0, 374.0, 63.0]],\n        'category': ['container'],\n        'id': [0]\n    }\n}\n</code></pre> <p>\u5b57\u6bb5\u8bf4\u660e\uff1a</p> \u5b57\u6bb5 \u8bf4\u660e <code>image</code> \u5e94\u4e3a<code>PIL</code>\u683c\u5f0f\u7684\u56fe\u7247 <code>image_id</code> \u56fe\u7247ID <code>width</code> \u56fe\u7247\u5bbd\u5ea6\uff0c\u5355\u4f4d\u50cf\u7d20 <code>height</code> \u56fe\u7247\u9ad8\u5ea6\uff0c\u5355\u4f4d\u50cf\u7d20 <code>objects</code> \u5305\u542b\u56fe\u50cf\u4e2d\u6240\u6709\u5bf9\u8c61\u7684\u5b57\u5178 <code>objects.area</code> \u76ee\u6807\u9762\u79ef\u5217\u8868\uff0c\u5b58\u50a8\u56fe\u7247\u4e0a\u6240\u6709\u76ee\u6807\u7684\u9762\u79ef <code>objects.bbox</code> \u76ee\u6807\u951a\u6846\u5217\u8868\uff0c\u5b58\u50a8\u56fe\u7247\u4e0a\u6240\u6709\u76ee\u6807\u7684\u951a\u6846\u4f4d\u7f6e\uff0c\u6bcf\u4e2a\u8fb9\u754c\u6846\u683c\u5f0f\u4e3a <code>[xmin, ymin, width, height]</code> <code>objects.category</code> \u76ee\u6807\u7c7b\u522b\u5217\u8868\uff0c\u5b58\u50a8\u56fe\u7247\u4e0a\u6240\u6709\u76ee\u6807\u7684\u5b57\u7b26\u6807\u7b7e <code>objects.id</code> \u76ee\u6807ID\u5217\u8868\uff0c\u5b58\u50a8\u56fe\u7247\u4e0a\u6240\u6709\u76ee\u6807\u7684\u6570\u5b57\u6807\u7b7e <p>\u4e0b\u9762\u4e3a\u90e8\u5206\u6570\u636e\u96c6\uff1a</p> <p> </p>"},{"location":"chapter6/container-detr/container-detr/#_5","title":"\u52a0\u8f7d\u5904\u7406\u5668","text":"Python<pre><code>preprocessor = AutoImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n</code></pre>"},{"location":"chapter6/container-detr/container-detr/#_6","title":"\u5b9a\u4e49\u56fe\u50cf\u589e\u5e7f","text":"Python<pre><code>aug = albumentations.Compose(\n    transforms=[\n        albumentations.Resize(480, 480),\n        albumentations.HorizontalFlip(p=1),\n        albumentations.RandomBrightnessContrast(p=1.0),\n    ],\n    bbox_params=albumentations.BboxParams(format=\"coco\", label_fields=[\"category\"]),\n)\n</code></pre> <p>\u56fe\u50cf\u589e\u5e7f</p> <p><code>albumentations</code>\u51fd\u6570\u5e93\u63d0\u4f9b\u4e86\u5404\u79cd\u5404\u6837\u7684\u56fe\u50cf\u589e\u5f3a\u6280\u672f\u3002\u5f00\u53d1\u8005\u53ef\u4ee5\u5728\u8fd9\u7247\u4ee3\u7801\u4e2d\u81ea\u5b9a\u4e49\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5\u3002</p> <p>\u53c2\u6570<code>transforms</code>\u6307\u5b9a\u56fe\u50cf\u7684\u53d8\u5316\u65b9\u5f0f\uff0c\u53c2\u6570<code>bbox_params</code>\u6307\u5b9a\u6807\u7b7e\u7684\u53d8\u5316\u65b9\u5f0f\u3002</p> \u4ee3\u7801 \u529f\u80fd <code>Resize(480, 480)</code> \u5c06\u56fe\u50cf\u5c3a\u5bf8\u8c03\u6574\u4e3a <code>480x480</code> <code>HorizontalFlip(p=1)</code> \u4ee5\u6982\u7387<code>p</code>\u6c34\u5e73\u7ffb\u8f6c\u56fe\u50cf <code>albumentations.RandomBrightnessContrast(p=1.0)</code> \u4ee5\u6982\u7387<code>p</code>\u968f\u673a\u8c03\u6574\u56fe\u50cf\u7684\u4eae\u5ea6\u548c\u5bf9\u6bd4\u5ea6 <code>BboxParams(format=\"coco\", label_fields=[\"category\"])</code> \u6307\u660e\u8fb9\u754c\u6846\u683c\u5f0f\u91c7\u7528<code>COCO</code>\u6570\u636e\u96c6\u683c\u5f0f\uff0c\u5e76\u4e14\u6807\u7b7e\u7c7b\u522b\u5b57\u6bb5\u4e3a<code>category</code>"},{"location":"chapter6/container-detr/container-detr/#_7","title":"\u5b9a\u4e49\u6570\u636e\u683c\u5f0f\u8f6c\u5316\u51fd\u6570","text":"Python<pre><code>def datapipe(data):\n    images, bboxes, areas, categories, targets = [], [], [], [], []\n\n    image_ids = data[\"image_id\"]\n\n    for image, objects in zip(data[\"image\"], data[\"objects\"]):\n        image = np.array(image.convert(\"RGB\"))[:, :, ::-1]\n        out = aug(image=image, bboxes=objects[\"bbox\"], category=objects[\"id\"])\n\n        areas.append(objects[\"area\"])\n\n        images.append(out[\"image\"])\n        bboxes.append(out[\"bboxes\"])\n        categories.append(out[\"category\"])\n\n    for image_id, category, area, box in zip(image_ids, categories, areas, bboxes):\n        annotations = []\n\n        for _category, _area, _box in zip(category, area, box):\n            new_ann = {\n                \"image_id\": image_id,\n                \"category_id\": _category,\n                \"isCrowd\": 0,\n                \"area\": _area,\n                \"bbox\": list(_box),\n            }\n            annotations.append(new_ann)\n        targets.append({\"image_id\": image_id, \"annotations\": annotations})\n    return preprocessor(images=images, annotations=targets, return_tensors=\"pt\")\n</code></pre> <p>\u4e0a\u8ff0\u4ee3\u7801\u5bf9\u539f\u59cb\u6570\u636e\u96c6\u683c\u5f0f\u8fdb\u884c\u8f6c\u5316\u3002\u8f6c\u5316\u540e\u7684\u6570\u636e\u96c6\u683c\u5f0f\u89c1<code>train_data[0]</code>\u3002</p> Python<pre><code>train_data = data[\"train\"].with_transform(datapipe)\n# val_data = data[\"validation\"].with_transform(datapipe)\ntest_data = data[\"test\"].with_transform(datapipe)\n</code></pre> train_data[0]<pre><code>{\n'pixel_values':\ntensor([[[-0.3198, -0.3712, -0.4568,  ...,  0.0569,  0.0398,  0.0398],\n         [-0.3883, -0.4397, -0.5424,  ...,  0.0569,  0.0398,  0.0398],\n         [-0.4739, -0.5424, -0.6623,  ...,  0.0398,  0.0227,  0.0227],\n         ...,\n         [ 0.3138,  0.2796,  0.2282,  ...,  0.2282,  0.2624,  0.2796],\n         [ 0.2453,  0.2453,  0.2624,  ...,  0.2624,  0.2796,  0.2624],\n         [ 0.1939,  0.2282,  0.2967,  ...,  0.2967,  0.2796,  0.2624]],\n\n        [[-0.1275, -0.2150, -0.3375,  ...,  0.1001,  0.0826,  0.0826],\n         [-0.1975, -0.3025, -0.4251,  ...,  0.1001,  0.0826,  0.0826],\n         [-0.3200, -0.4251, -0.5651,  ...,  0.0826,  0.0651,  0.0651],\n         ...,\n         [ 0.5028,  0.4678,  0.4328,  ...,  0.1527,  0.2052,  0.2402],\n         [ 0.4328,  0.4328,  0.4678,  ...,  0.1702,  0.1702,  0.1702],\n         [ 0.3803,  0.4153,  0.4853,  ...,  0.1702,  0.1527,  0.1352]],\n\n        [[ 0.0953,  0.0082, -0.1138,  ...,  0.2348,  0.2173,  0.1999],\n         [ 0.0082, -0.0964, -0.2184,  ...,  0.2348,  0.2173,  0.1999],\n         [-0.1312, -0.2358, -0.3753,  ...,  0.2173,  0.1999,  0.1825],\n         ...,\n         [ 0.7925,  0.7576,  0.7054,  ...,  0.3568,  0.4265,  0.4788],\n         [ 0.7054,  0.7228,  0.7402,  ...,  0.3393,  0.3916,  0.4091],\n         [ 0.6531,  0.7054,  0.7751,  ...,  0.3393,  0.3568,  0.3568]]]),\n\n'pixel_mask':\ntensor([[1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        ...,\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1]]),\n\n'labels':\n{\n    'size': tensor([800, 800]),\n    'image_id': tensor([475]),\n    'class_labels': tensor([0]),\n    'boxes': tensor([[0.4625, 0.5773, 0.3339, 0.0583]]),\n    'area': tensor([65449.9961]),\n    'iscrowd': tensor([0]),\n    'orig_size': tensor([480, 480])\n}\n\n}\n</code></pre>"},{"location":"chapter6/container-detr/container-detr/#_8","title":"\u5b9a\u4e49\u6574\u7406\u51fd\u6570","text":"Python<pre><code>def collate_fn(batch):\n    pixel_values = [item[\"pixel_values\"] for item in batch]\n    output = preprocessor.pad(pixel_values, return_tensors=\"pt\")\n    labels = [item[\"labels\"] for item in batch]\n\n    ret = {}\n\n    ret[\"pixel_values\"] = output[\"pixel_values\"]\n    ret[\"pixel_mask\"] = output[\"pixel_mask\"]\n    ret[\"labels\"] = labels\n\n    return ret\n</code></pre>"},{"location":"chapter6/container-detr/container-detr/#_9","title":"\u52a0\u8f7d\u6a21\u578b","text":"Python<pre><code>id2label = {0: \"container-id\"}\nlabel2id = {\"container-id\": 0}\n\n\nmodel = AutoModelForObjectDetection.from_pretrained(\n    \"facebook/detr-resnet-50\",\n    id2label=id2label,\n    label2id=label2id,\n    ignore_mismatched_sizes=True,\n)\n</code></pre>"},{"location":"chapter6/container-detr/container-detr/#_10","title":"\u5b9a\u4e49\u8d85\u53c2","text":"Python<pre><code>training_args = TrainingArguments(\n    output_dir=\"detr-resnet-50-container-finetuned\",\n    per_device_train_batch_size=10,\n    num_train_epochs=20,\n    eval_strategy=\"epoch\",\n    learning_rate=1e-5,\n    weight_decay=1e-4,\n    save_total_limit=2,\n    remove_unused_columns=False,\n)\n</code></pre>"},{"location":"chapter6/container-detr/container-detr/#_11","title":"\u5b9a\u4e49\u8bad\u7ec3\u5668","text":"Python<pre><code>trainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=collate_fn,\n    train_dataset=train_data,\n    eval_dataset=test_data,\n    tokenizer=preprocessor,\n)\n</code></pre>"},{"location":"chapter6/container-detr/container-detr/#_12","title":"\u8bad\u7ec3","text":"Python<pre><code>tainer.train()\n</code></pre>"},{"location":"chapter6/container-detr/container-detr/#_13","title":"\u63a8\u7406","text":"Python<pre><code>from transformers import pipeline\n\nobj_detector = pipeline(\"object-detection\", model=\"detr-resnet-50-container-finetuned\")\n\nresults = obj_detector(train_dataset[0][\"image\"])\n</code></pre>"},{"location":"chapter6/container-detr/container-detr/#_14","title":"\u53c2\u8003\u8d44\u6599","text":"<ul> <li> <p>HuggingFace\u793e\u533a\u6559\u7a0b</p> <p>\u8d70\u8fdb\u8ba1\u7b97\u673a\u89c6\u89c9\u00a0\u29c9</p> </li> <li> <p>HuggingFace\u76ee\u6807\u68c0\u6d4b\u4ee3\u7801\u6848\u4f8b</p> <p>\u4f7f\u7528DETR\u5b8c\u6210\u76ee\u6807\u68c0\u6d4b</p> </li> </ul>"},{"location":"chapter6/ddpm-unet-mnist/ddpm-unet-mnist/","title":"\u4e00\u79cd\u7b80\u5355\u7684\u53bb\u566a\u65b9\u6cd5","text":""},{"location":"chapter6/ddpm-unet-mnist/ddpm-unet-mnist/#_1","title":"\u524d\u8a00","text":"<p>\u968f\u7740<code>sora</code>\u7684\u6a2a\u7a7a\u51fa\u4e16\uff0c\u6587\u751f\u89c6\u9891\u55a7\u56a3\u4e00\u65f6\uff0c\u7a76\u5176\u6280\u672f\u6e90\u5934\u4ecd\u7136\u662f\u9690\u6269\u6563\u53bb\u566a\u6a21\u578b\u3002</p> <p>\u672c\u6587\u5e0c\u671b\u4ece\u624b\u5199\u6570\u5b57\u56fe\u50cf\u53bb\u566a\u4ee3\u7801\uff0c\u6765\u4e86\u89e3\u4ee5\u4e0b\u7684\u77e5\u8bc6\u3002</p> <ol> <li>\u5c0f\u6279\u91cf\u6570\u636e\u6dfb\u52a0\u566a\u58f0</li> <li>\u81ea\u5efa\u7b80\u5355\u7684UNet\u7f16\u89e3\u7801\u5668</li> <li>\u57fa\u672c\u7684\u8bad\u7ec3\u6d41\u7a0b</li> </ol>"},{"location":"chapter6/ddpm-unet-mnist/ddpm-unet-mnist/#_2","title":"\u4ee3\u7801","text":""},{"location":"chapter6/ddpm-unet-mnist/ddpm-unet-mnist/#_3","title":"\u57fa\u672c\u51fd\u6570\u5e93\u7684\u5bfc\u5165","text":"Python<pre><code>import torch\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n</code></pre>"},{"location":"chapter6/ddpm-unet-mnist/ddpm-unet-mnist/#_4","title":"\u6570\u636e\u96c6\u7684\u52a0\u8f7d","text":"Python<pre><code>class MnistDataset:\n    def __init__(self, data_path, test=False):\n        if not test: # \u6839\u636e\u6570\u636e\u96c6\u7684\u771f\u5b9e\u60c5\u51b5\u7f16\u5199\u4ee3\u7801\n            self.data = pd.read_csv(data_path).drop(\"label\", axis=1)\n        else:\n            self.data = pd.read_csv(data_path)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        item = self.data.iloc[index, :]\n        img = item.to_numpy().reshape(1, 28, 28) / 255\n        img = torch.tensor(img)\n        return img, img # \u7b2c\u4e00\u4e2aimg\u7528\u4e8e\u52a0\u566a\u58f0\uff0c\u7b2c\u4e8c\u4e2aimg\u7528\u4e8e\u5f53\u4f5c\u6807\u7b7e\u3002\n</code></pre>"},{"location":"chapter6/ddpm-unet-mnist/ddpm-unet-mnist/#_5","title":"\u524d\u5411\u6269\u6563","text":"Python<pre><code>def corrupt(image, amount):\n    # image: \u5c06\u8981\u8fdb\u884c\u52a0\u566a\u58f0\u7684\u56fe\u50cf\u6570\u636e\n    # amount: \u566a\u58f0\u5f3a\u5ea6\u7684\u5927\u5c0f\u7ec4\u6210\u7684\u5f20\u91cf\n    noise = torch.rand_like(image)\n    amount = torch.tensor(amount).reshape(-1, 1, 1, 1)\n    return image * (1 - amount) + noise * amount\n</code></pre> <p>\u52a0\u566a\u58f0\u5bf9\u5e94\u524d\u5411\u6269\u6563\uff0c\u5177\u4f53\u7684\u4ee3\u7801\u7684\u903b\u8f91\uff1a</p> <ol> <li>\u5229\u7528<code>torch.rand_like(image)</code>\u6839\u636e\u56fe\u50cf\u7684\u5f62\u72b6\u751f\u6210\u7b26\u5408\u9ad8\u65af\u5206\u5e03\u7684\u566a\u58f0\u3002</li> <li><code>amount</code>\u662f\u957f\u5ea6\u4e3a\u6279\u91cf\u5927\u5c0f\uff0c\u6570\u503c\u8303\u56f4\u4e3a\\(0\\sim1\\)\u7684\u5747\u5300\u5206\u5e03\u6570\u636e\u3002\u4e3a\u4ec0\u4e48\u8981\u8fd9\u6837\u5462\uff1f\u56e0\u4e3a\u6211\u4eec\u8981\u5bf9\u6570\u636e\u52a0\u4e0a\u4e0d\u540c\u5f3a\u5ea6\u7684\u566a\u58f0\u3002</li> <li>\u5c06amount\u7684\u5f62\u72b6\u8bbe\u7f6e\u4e3a<code>(batch size, 1, 1, 1)</code>,\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4e3a<code>batch size</code>\uff0c\u6bcf\u5f20\u56fe\u90fd\u5bf9\u5e94\u4e00\u4e2a\u566a\u58f0\u7a0b\u5ea6\uff0c\u5176\u4f59\u7684\u7ef4\u5ea6\u5747\u4e3a\\(1\\)\u4fbf\u4e8e\u4e0e\u6bcf\u5f20\u539f\u59cb\u56fe\u50cf\u5728\u76f8\u52a0\u7684\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u5e7f\u64ad\u3002</li> <li>\u5bf9\u56fe\u50cf\u52a0\u5165\u566a\u58f0\u7684\u65b9\u5f0f\u662f\uff0c\u4fdd\u7559\u4e00\u90e8\u5206\u539f\u59cb\u56fe\u50cf\uff0c\u518d\u52a0\u5165\u5bf9\u5e94\u5f3a\u5ea6\u7684\u566a\u58f0\u3002</li> </ol> <p></p>"},{"location":"chapter6/ddpm-unet-mnist/ddpm-unet-mnist/#unet","title":"\u7b80\u5355\u7684UNet","text":"Python<pre><code>class SimpleUNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.downConv2d = nn.Sequential(\n            # !\n            nn.Conv2d(1, 32, 5, padding=2, has_bias=True),\n            nn.Conv2d(32, 64, 5, padding=2, has_bias=True),\n            nn.Conv2d(64, 64, 5, padding=2, has_bias=True),\n        )\n\n        self.upConv2d = nn.Sequential(\n            nn.Conv2d(64, 64, 5, padding=2, has_bias=True),\n            nn.Conv2d(64, 32, 5, padding=2, has_bias=True),\n            nn.Conv2d(32, 1, 5, padding=2, has_bias=True),\n        )\n\n        self.relu = nn.ReLU()\n        self.downscale = nn.MaxPool2d(2, 2)\n        # !\n        self.upscale = nn.Upsample(scale_factor=2.0)\n\n    def forward(self, x):\n        stack = []\n\n        for index, layer in enumerate(self.downConv2d):\n            x = self.relu(layer(x))\n\n            if index &lt; 2:\n                stack.append(x)\n                x = self.downscale(x)\n        for index, layer in enumerate(self.upConv2d):\n            if index &gt; 0:\n                x = self.upscale(x)\n                x += stack.pop()\n            x = self.relu(layer(x))\n        return x\n</code></pre> <ol> <li>\u5f62\u72b6\u4e3a<code>(batch size, 1, 28, 28)</code>\u7684\u5c0f\u6279\u91cf\u6570\u636e\u4e0d\u65ad\u8fdb\u884c\u5377\u79ef\u4e0e\u6700\u5927\u6c60\u5316\u64cd\u4f5c\u3002\u7279\u5f81\u56fe\u7684\u7ef4\u5ea6\u53d8\u5316\u662f\u8fd9\u6837\u7684<ul> <li>\u5de6\uff1a<code>(batch size, 1, 28, 28)</code>\u2014&gt;<code>(batch size, 32, 28, 28)</code>\u2014&gt;<code>(batch size, 32, 14, 14)</code>\u2014&gt;<code>(batch size, 64, 14, 14)</code>\u2014&gt;<code>(batch size, 64, 7, 7)</code>\u2014&gt;<code>(batch size, 64, 7, 7)</code></li> <li>\u53f3\uff1a<code>(batch size, 64, 7, 7)</code>\u2014&gt;<code>(batch size, 64, 7, 7)</code> \u2014&gt; <code>(batch size, 64, 14, 14)</code> \u2014&gt;<code>(batch size, 32, 14, 14)</code> \u2014&gt;<code>(batch size, 32, 28, 28)</code> \u2014&gt;<code>(batch size, 1, 28, 28)</code></li> </ul> </li> <li>\u5bf9\u4e8e\u5377\u79ef\u3001\u6c60\u5316\u3001\u91c7\u6837\u7684\u987a\u5e8f\u6765\u8bb2\uff0c\u5728\u4e0b\u91c7\u6837\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5148\u662f\u5377\u79ef\u6c60\u5316\uff0c\u540e\u662f\u4e0b\u91c7\u6837\uff0c\u5728\u4e0a\u91c7\u6837\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5148\u662f\u4e0a\u91c7\u6837\uff0c\u540e\u662f\u5377\u79ef\u6c60\u5316\u3002\u8fd9\u53e5\u8bdd\u5176\u5b9e\u4e0d\u7b97\u4e25\u8c28\uff0c\u4f46\u662fget\u5230\u610f\u601d\u5c31\u597d\u4e86\u3002</li> </ol>"},{"location":"chapter6/ddpm-unet-mnist/ddpm-unet-mnist/#_6","title":"\u8bad\u7ec3\u90e8\u5206","text":"Python<pre><code>net = SimpleUNet()\nbatch_size = 128\nloss_fn = nn.MSELoss()\nnum_epoches = 3 # \u5199\u6587\u7ae0\u7684\u65f6\u5019\u53ea\u8ba9\u7a0b\u5e8f\u8dd1\u4e86\u4e00\u8f6e\noptimizer = optim.Adam(net.parameters(), lr=1e-3)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n</code></pre> Python<pre><code>for epoch in range(num_epoches):\n    for i, (x, y) in enumerate(train_loader):\n        # \u6570\u636e\u9884\u5904\u7406\n        x = corrupt(x, torch.rand(x.shape[0]))\n\n        # \u524d\u5411\u4f20\u64ad\n        y_hat = net(x)\n        loss = loss_fn(y_hat, y)\n\n        # \u53cd\u5411\u4f20\u64ad\n        optimizer.zero_grad()  # \u6e05\u7a7a\u68af\u5ea6\n        loss.backward()  # \u8ba1\u7b97\u68af\u5ea6\n        optimizer.step()  # \u66f4\u65b0\u53c2\u6570\n\n        # \u6253\u5370\u635f\u5931\n        if i % 10 == 0:\n            print(f\"epoch:{epoch}, step:{i}, loss:{loss.item()}\")\n</code></pre> <p>\u5728\u8fd9\u91cc\u5c31\u653e\u4e0a\u524d\u51e0\u6b65\u7684\u8bad\u7ec3\u4fe1\u606f\u3002</p> Epoch Step Loss 0 10 0.065431 0 20 0.038543 \\(\\cdots\\) \\(\\cdots\\) \\(\\cdots\\) 2 310 0.018558 2 320 0.013773"},{"location":"chapter6/ddpm-unet-mnist/ddpm-unet-mnist/#_7","title":"\u6d4b\u8bd5","text":"Python<pre><code>fig, axes = plt.subplots(3, 4, figsize=(16, 8))\n\nnet.train()\nfor x, y in test_loader:\n    noised_img = corrupt(x, ops.rand(x.shape[0]))\n    x = net(noised_img)\n    imgs = torch.concat([noised_img, x, y], dim=0).transpose(0, 2, 3, 1).asnumpy()\n    for ax, img in zip(axes.flatten(), imgs):\n        ax.imshow(img, cmap=\"gray\")\n        ax.axis(\"off\")\n    break\n</code></pre> <p>\u6548\u679c\u8fd8\u662f\u80fd\u6253\u7684!</p>"},{"location":"chapter6/mlcoftc/multi-label-classification-of-toxic-comments/","title":"\u9762\u5bf9\u6709\u5bb3\u8a00\u8bba, \u662f\u65f6\u5019\u8ba9AI\u91cd\u62f3\u51fa\u51fb\u4e86","text":""},{"location":"chapter6/mlcoftc/multi-label-classification-of-toxic-comments/#_1","title":"\u603b\u89c8","text":"<p>\u5728\u7f51\u7edc\u4e16\u754c\u4e2d\uff0c\u6709\u6548\u8fc7\u6ee4\u548c\u7ba1\u7406\u6076\u610f\u8bc4\u8bba\u662f\u4e00\u9879\u6311\u6218\u3002Toxic Comment Classification Challenge \u9879\u76ee\u81f4\u529b\u4e8e\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u89e3\u51b3\u8fd9\u4e00\u96be\u9898\u3002\u8be5\u9879\u76ee\u6e90\u4e8e Kaggle \u7ade\u8d5b\uff0c\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u7cbe\u51c6\u8bc6\u522b\u5728\u7ebf\u5bf9\u8bdd\u4e2d\u6709\u6bd2\u8bc4\u8bba\u7684\u7b97\u6cd5\u3002\u9879\u76ee\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u548c\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\uff0c\u5bf9\u8bc4\u8bba\u8fdb\u884c\u591a\u7c7b\u522b\u5206\u7c7b\uff0c\u4f8b\u5982\u8bc6\u522b\u5a01\u80c1\u3001\u6deb\u79fd\u8272\u60c5\u3001\u4fae\u8fb1\u548c\u57fa\u4e8e\u8eab\u4efd\u7684\u4ec7\u6068\u8a00\u8bba\u7b49\uff0c\u4ece\u800c\u5e2e\u52a9\u51cf\u5c11\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u4e0d\u826f\u5f71\u54cd\u3002</p>"},{"location":"chapter6/mlcoftc/multi-label-classification-of-toxic-comments/#_2","title":"\u6570\u636e","text":"<p>\u8bad\u7ec3\u96c6</p> <p></p> <p>\u6d4b\u8bd5\u96c6</p> <p></p>"},{"location":"chapter6/mlcoftc/multi-label-classification-of-toxic-comments/#_3","title":"\u4ee3\u7801","text":"Python<pre><code>import os\n\nos.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n# os.environ[\"HTTP_PROXY\"] = \"http://127.0.0.1:7890\"\n# os.environ[\"HTTPS_PROXY\"] = \"http://127.0.0.1:7890\"\n</code></pre>"},{"location":"chapter6/mlcoftc/multi-label-classification-of-toxic-comments/#_4","title":"\u6570\u636e\u96c6\u52a0\u8f7d","text":"Python<pre><code>from datasets import load_dataset\n\ndata_files = {\"train\": \"./data/train.csv\"}\n\ndataset = load_dataset(\"csv\", data_files=data_files, num_proc=8)\ntrain_and_test = dataset[\"train\"].train_test_split(test_size=0.2)\n</code></pre> <p>\u4f7f\u7528 <code>train_test_split</code>\u65b9\u6cd5\u5212\u5206\u51fa\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002</p> train_and_test<pre><code>DatasetDict({\n    train: Dataset({\n        features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n        num_rows: 127656\n    })\n    test: Dataset({\n        features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n        num_rows: 31915\n    })\n})\n</code></pre> Python<pre><code>label2id = {\n    \"toxic\": 0,\n    \"severe_toxic\": 1,\n    \"obscene\": 2,\n    \"threat\": 3,\n    \"insult\": 4,\n    \"identity_hate\": 5,\n}\n\nid2label = {\n    0: \"toxic\",\n    1: \"severe_toxic\",\n    2: \"obscene\",\n    3: \"threat\",\n    4: \"insult\",\n    5: \"identity_hate\",\n}\n</code></pre>"},{"location":"chapter6/mlcoftc/multi-label-classification-of-toxic-comments/#_5","title":"\u6570\u636e\u9884\u5904\u7406","text":"Python<pre><code>from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n</code></pre> Python<pre><code>def tokenized_fn(example):\n    tokenized_example = tokenizer(\n        example[\"comment_text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=64,\n    )\n    return tokenized_example\n</code></pre> Python<pre><code>def gen_labels(label1, label2, label3, label4, label5, label6):\n    labels = []\n\n    for i in range(len(label1)):\n        labels.append(\n            [\n                float(label1[i]),\n                float(label2[i]),\n                float(label3[i]),\n                float(label4[i]),\n                float(label5[i]),\n                float(label6[i]),\n            ]\n        )\n\n    return {\"labels\": labels}\n</code></pre> Python<pre><code>def datapipe(dataset):\n    dataset = dataset.map(tokenized_fn, batched=True)\n    dataset = dataset.map(\n        gen_labels,\n        input_columns=[\n            \"toxic\",\n            \"severe_toxic\",\n            \"obscene\",\n            \"threat\",\n            \"insult\",\n            \"identity_hate\",\n        ],\n        batched=True,\n    )\n    return dataset\n</code></pre> Python<pre><code>train_and_test = datapipe(train_and_test)\ntrain_and_test = train_and_test.select_columns(\n    [\n        \"input_ids\",\n        \"attention_mask\",\n        \"labels\",\n    ]\n)\n</code></pre> train_and_test<pre><code>DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 127656\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 31915\n    })\n})\n</code></pre> train_and_test[\"train\"][0]<pre><code>{\n  \"input_ids\": [101, 1045, 2134, 1005, 1056, 5382, 1998, 1045, 2572, 2047, 2182, 2074, 2893, 1996, 6865, 1997, 2009, 1012, 4283, 2005, 1996, 4641, 2039, 2295, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  \"attention_mask\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  \"labels\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n}\n</code></pre> <p>\u591a\u6807\u7b7e\u5206\u7c7b\u548c\u5355\u6807\u7b7e\u5206\u7c7b\u5728\u6570\u636e\u96c6\u683c\u5f0f\u4e0a\u5927\u540c\u5c0f\u5f02</p> <ul> <li>\u5728\u5355\u6807\u7b7e\u5206\u7c7b\u4e2d\uff0c\u5355\u4e2a\u6837\u672c\u7684 <code>labels</code>\u4e3a\u4e00\u4e2a\u6574\u6570</li> <li>\u5728\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\uff0c\u5355\u4e2a\u6837\u672c\u7684 <code>labels</code>\u4e3a\u7c7b\u522b\u4e2a\u6570\u957f\u5ea6\u4e2a0\u62161\u7ec4\u6210\u5217\u8868\u3002\u5176\u4e2d1\u4ee3\u8868\u8be5\u6837\u672c\u5c5e\u4e8e\u8be5\u7c7b\uff0c\u5426\u5219\u4e0d\u5c5e\u4e8e\u8be5\u7c7b\u3002</li> </ul>"},{"location":"chapter6/mlcoftc/multi-label-classification-of-toxic-comments/#_6","title":"\u9884\u8bad\u7ec3\u6a21\u578b","text":"Python<pre><code>from transformers import AutoModelForSequenceClassification\n</code></pre> Python<pre><code>model = AutoModelForSequenceClassification.from_pretrained(\n    \"google-bert/bert-base-uncased\",\n    num_labels=len(id2label),\n    id2label=id2label,\n    label2id=label2id,\n    problem_type=\"multi_label_classification\",\n)\n</code></pre> <p>\u5982\u679c\u4efb\u52a1\u7c7b\u578b\u4e3a\u591a\u4efb\u52a1\u6807\u7b7e\uff0c\u90a3\u4e48\u9700\u8981\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u65f6\u6307\u5b9a <code>problem_type</code>\u4e3a <code>multi_label_classification</code>\u3002</p> Note <p>Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized:['classifier.bias', 'classifier.weight'] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</p> Python<pre><code>model.requires_grad = False\nmodel.classifier.requires_grad = True\n</code></pre> <ol> <li>\u5c06\u7f51\u7edc\u53c2\u6570\u90fd\u51bb\u7ed3\uff0c</li> <li>\u5c06 <code>classifier.requires_grad</code>\u8bbe\u7f6e\u4e3a <code>True</code>\u53ea\u5141\u8bb8\u5206\u7c7b\u5934\u53c2\u4e0e\u68af\u5ea6\u66f4\u65b0\u3002</li> </ol>"},{"location":"chapter6/mlcoftc/multi-label-classification-of-toxic-comments/#_7","title":"\u8bc4\u4ef7\u6307\u6807","text":"Python<pre><code>import numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score\n</code></pre> Python<pre><code>def sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n</code></pre> Python<pre><code>def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = sigmoid(logits)\n    preds = (preds &gt; 0.5).astype(int).reshape(-1)\n    labels = labels.reshape(-1)\n    accuracy = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average=\"macro\")\n    return {\n        \"accuracy\": accuracy,\n        \"f1\": f1,\n    }\n</code></pre>"},{"location":"chapter6/mlcoftc/multi-label-classification-of-toxic-comments/#_8","title":"\u8bad\u7ec3","text":"Python<pre><code>from transformers import TrainingArguments, Trainer\n</code></pre> Python<pre><code>training_args = TrainingArguments(\n    output_dir=\"./output/\",\n    eval_strategy=\"epoch\",\n    per_device_train_batch_size=128,\n    per_device_eval_batch_size=128,\n    weight_decay=0.01,\n    num_train_epochs=5,\n    learning_rate=2e-5,\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)\n</code></pre> Python<pre><code>trainer = Trainer(\n    args=training_args,\n    model=model,\n    train_dataset=train_and_test[\"train\"],\n    eval_dataset=train_and_test[\"test\"],\n    compute_metrics=compute_metrics,\n)\n</code></pre> Python<pre><code>trainer.train()\n</code></pre>"},{"location":"chapter6/mlcoftc/multi-label-classification-of-toxic-comments/#_9","title":"\u6a21\u578b\u8bad\u7ec3\u7ed3\u679c","text":"Epoch Training Loss Validation Loss Accuracy F1 1 0.046600 0.042239 0.984312 0.882476 2 0.036300 0.041644 0.984067 0.881441 3 0.029900 0.043375 0.983816 0.883072 4 0.024800 0.048329 0.983503 0.882226 5 0.021100 0.049663 0.983153 0.881117"},{"location":"chapter6/mlcoftc/multi-label-classification-of-toxic-comments/#_10","title":"\u63a8\u7406","text":"Python<pre><code>data = load_dataset('csv', data_files={'val':'./data/test.csv'}, num_proc=8)\ndata = data.map(tokenized_fn, batched=True)\n</code></pre> Python<pre><code>answer = (sigmoid(trainer.predict(data['val']).predictions) &gt; 0.5).astype(int)\n</code></pre> Python<pre><code>import pandas as pd\n\npd.DataFrame(answer).to_csv('./answer.csv', index=False)\n</code></pre> <p>\u7ecf\u8fc7\u540e\u7eed\u7684\u6570\u636e\u96c6\u683c\u5f0f\u6574\u7406\uff0c\u63d0\u4ea4\u8bc4\u6d4b\u540e\uff1a</p> <p></p>"},{"location":"chapter6/text-summary/text-summary/","title":"\u201c\u6587\u672c\u6458\u8981\u201d","text":""},{"location":"chapter6/text-summary/text-summary/#_1","title":"\u524d\u8a00","text":"<p>\u6587\u672c\u6458\u8981\u662f\u4ece\u957f\u6587\u672c\u4e2d\u63d0\u53d6\u5173\u952e\u4fe1\u606f\u7684\u8fc7\u7a0b\uff0c\u4f7f\u5f97\u5185\u5bb9\u66f4\u7b80\u6d01\uff0c\u540c\u65f6\u5c3d\u53ef\u80fd\u4fdd\u7559\u539f\u59cb\u6587\u672c\u7684\u4e3b\u8981\u5185\u5bb9\u548c\u91cd\u8981\u7ec6\u8282\u3002</p>"},{"location":"chapter6/text-summary/text-summary/#_2","title":"\u4ee3\u7801","text":""},{"location":"chapter6/text-summary/text-summary/#_3","title":"\u5bfc\u5165\u51fd\u6570\u5305","text":"Python<pre><code>import numpy as np\nimport torch\nfrom datasets import load_dataset\nfrom peft import LoraConfig, TaskType, get_peft_model\nfrom rouge_chinese import Rouge\nfrom transformers import (\nAutoModelForSeq2SeqLM,\nAutoTokenizer,\nDataCollatorForSeq2Seq,\npipeline,\nSeq2SeqTrainer,\nSeq2SeqTrainingArguments,\n)\n</code></pre> Python<pre><code>model_name_or_path = \"Langboat/mengzi-t5-base\"\nfile_path = \"hugcyp/LCSTS\"\n</code></pre>"},{"location":"chapter6/text-summary/text-summary/#_4","title":"\u52a0\u8f7d\u6570\u636e\u96c6","text":"Python<pre><code>ds = load_dataset(file_path, num_proc=4)\n</code></pre> <ul> <li>\u539f\u672c\u7684\u6570\u636e\u96c6\u4e2d\u8bad\u7ec3\u96c6\u90e8\u5206\u89c4\u6a21\u8f83\u5927\uff0c\u5f00\u53d1\u8005\u53ef\u4ee5\u6839\u636e\u81ea\u4e3b\u8c03\u8282\u6570\u636e\u91cf\u3002</li> </ul> ds<pre><code>DatasetDict({\n    train: Dataset({\n        features: ['summary', 'text'],\n        num_rows: 2400591\n    })\n    validation: Dataset({\n        features: ['summary', 'text'],\n        num_rows: 8685\n    })\n    test: Dataset({\n        features: ['summary', 'text'],\n        num_rows: 725\n    })\n})\n</code></pre> Python<pre><code>ds[\"train\"] = ds[\"train\"].select(range(8000))\n</code></pre> <ul> <li>\u4f7f\u7528 <code>select</code> \u65b9\u6cd5\u4fdd\u7559\u8bad\u7ec3\u96c6\u524d 8000 \u6761\u6837\u672c\u3002</li> </ul>"},{"location":"chapter6/text-summary/text-summary/#_5","title":"\u6570\u636e\u9884\u5904\u7406","text":"Python<pre><code>tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n</code></pre> <ul> <li>\u52a0\u8f7d\u5206\u8bcd\u5668\u3002</li> </ul> Python<pre><code>def data_pipe(example):\n    text_inputs = tokenizer(\n        text=[\"\u6458\u8981\u751f\u6210\uff1a\\n\" + e for e in example[\"text\"]],\n        max_length=64,\n        truncation=True,\n    )\n\n    target_inputs = tokenizer(\n        text_target=example[\"summary\"],\n        max_length=32,\n        truncation=True,\n    )\n\n    text_inputs[\"labels\"] = target_inputs[\"input_ids\"]\n    return text_inputs\n</code></pre> <ul> <li>\u5bf9\u6bcf\u6761\u6837\u672c\u5185\u5bb9\u6dfb\u52a0\u524d\u7f00\u5b57\u7b26\u4e32 <code>\"\u6458\u8981\u751f\u6210\uff1a\\n\"</code>\u3002</li> <li>\u5206\u522b\u5bf9\u539f\u6587\u5185\u5bb9\u548c\u6458\u8981\u5185\u5bb9\u8fdb\u884c\u7f16\u7801\u3002</li> <li>\u8fd4\u56de <code>input_ids</code>, <code>token_type_ids</code>, <code>attention_mask</code>, <code>labels</code>\u3002</li> </ul> Python<pre><code>tokenized_ds = ds.map(data_pipe, batched=True)\n</code></pre>"},{"location":"chapter6/text-summary/text-summary/#_6","title":"\u6a21\u578b","text":"Python<pre><code>model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n\n# LoRa\n\npeft_config = LoraConfig(\n    peft_type=TaskType.SEQ_2_SEQ_LM,\n    inference_mode=False,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1,\n)\n\nmodel = get_peft_model(model, peft_config)\n</code></pre> peft_config<pre><code>LoraConfig(peft_type=&lt;PeftType.LORA: 'LORA'&gt;, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=None, inference_mode=False, r=8, target_modules=None, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))\n</code></pre> model.print_trainable_parameters()<pre><code>trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3561\n</code></pre>"},{"location":"chapter6/text-summary/text-summary/#_7","title":"\u6027\u80fd\u6307\u6807","text":"Python<pre><code>rouge = Rouge()\n\ndef compute_metrics(evalPred):\n    predictions, labels = evalPred\n    decode_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    decode_preds = [\" \".join(p) for p in decode_preds]\n    decode_labels = [\" \".join(l) for l in decode_labels]\n    scores = rouge.get_scores(decode_preds, decode_labels, avg=True)\n    return {\n        \"rouge-1\": scores[\"rouge-1\"][\"f\"],\n        \"rouge-2\": scores[\"rouge-2\"][\"f\"],\n        \"rouge-l\": scores[\"rouge-l\"][\"f\"],\n    }\n</code></pre>"},{"location":"chapter6/text-summary/text-summary/#_8","title":"\u8bad\u7ec3\u53c2\u6570","text":"Python<pre><code>training_args = Seq2SeqTrainingArguments(\n    output_dir=\"./mengzi_lcsts\",\n    num_train_epochs=5,\n    learning_rate=1e-3,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    eval_strategy=\"epoch\",\n    save_total_limit=3,\n    metric_for_best_model=\"rouge-l\",\n    predict_with_generate=True,\n)\n</code></pre>"},{"location":"chapter6/text-summary/text-summary/#trainer","title":"Trainer","text":"Python<pre><code>trainer = Seq2SeqTrainer(\n    model=model,\n    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n    train_dataset=tokenized_ds[\"train\"],\n    eval_dataset=tokenized_ds[\"validation\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    args=training_args,\n)\n</code></pre>"},{"location":"chapter6/text-summary/text-summary/#_9","title":"\u8bad\u7ec3","text":"Python<pre><code>trainer.train()\n</code></pre>"},{"location":"chapter6/text-summary/text-summary/#_10","title":"\u63a8\u7406","text":"Python<pre><code>pipe = pipeline(\"summarization\", model=\"./mengzi_lcsts\", tokenizer=\"./mengzi_lcsts\")\nout = pipe(\"xxxxxxxxxx\")\n\nprint(out)\n</code></pre>"},{"location":"chapter6/translation/translation/","title":"\u6587\u672c\u7ffb\u8bd1","text":""},{"location":"chapter6/translation/translation/#_1","title":"\u524d\u8a00","text":""},{"location":"chapter6/translation/translation/#_2","title":"\u4ee3\u7801","text":""},{"location":"chapter6/translation/translation/#_3","title":"\u52a0\u8f7d\u6570\u636e\u96c6","text":"Python<pre><code>from datasets import load_dataset\n\nraw_datasets = load_dataset(\"Helsinki-NLP/news_commentary\", \"en-zh\", trust_remote_code=True)\n</code></pre> <p>\u5728\u8fd9\u91cc\u9009\u62e9\u7684\u914d\u7f6e\"en-zh\"\u8fdb\u884c\u4e2d\u82f1\u6587\u6587\u672c\u7ffb\u8bd1\uff0c\u4e0b\u9762\u4e3a\u5168\u90e8\u6570\u636e\u96c6\u8be6\u7ec6\u4fe1\u606f\uff1a</p> <p> </p> raw_datasets<pre><code>DatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 69206\n    })\n})\n</code></pre> raw_datasets[\"train\"][0]<pre><code>{'translation': {'en': '1929 or 1989?', 'zh': '1929\u5e74\u8fd8\u662f1989\u5e74?'}}\n</code></pre> Python<pre><code>raw_datasets = raw_datasets[\"train\"].train_test_split(test_size=0.2)\n</code></pre> raw_datasets<pre><code>DatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 55364\n    })\n    test: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 13842\n    })\n})\n</code></pre>"},{"location":"chapter6/translation/translation/#_4","title":"\u52a0\u8f7d\u5206\u8bcd\u5668","text":"Python<pre><code>from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")\n</code></pre> <p>\u6b63\u786e\u8bbe\u7f6e\u8bed\u8a00</p> <p>\u5728\u505a\u7ffb\u8bd1\u4efb\u52a1\u4e2d\uff0c\u8bf7\u786e\u4fdd\u9002\u7528\u4e8e\u591a\u8bed\u8a00\u7684\u5206\u8bcd\u5668\u7684\u539f\u59cb\u8bed\u79cd\u548c\u76ee\u6807\u8bed\u79cd\u88ab\u6b63\u786e\u8bbe\u7f6e\uff0c\u6216\u8005\u4efb\u52a1\u672c\u8eab\u7b26\u5408\u591a\u8bed\u8a00\u5206\u8bcd\u5668\u4e00\u5f00\u59cb\u7684\u539f\u59cb\u8bed\u8a00\u548c\u76ee\u6807\u8bed\u8a00\u3002</p> <p>\u67e5\u770b\u5206\u8bcd\u5668\u539f\u59cb\u8bed\u8a00\u4e0e\u76ee\u6807\u8bed\u8a00</p> tokenizer.source_lang, tokenizer.target_lang<pre><code>('zho', 'eng')\n</code></pre>"},{"location":"chapter6/translation/translation/#_5","title":"\u5b9a\u4e49\u5206\u8bcd\u51fd\u6570","text":"Python<pre><code>def tokenize_fn(examples):\n    inputs = [example['zh'] for example in examples['translation']]\n    labels = [example['en'] for example in examples['translation']]\n\n    model_inputs = tokenizer(\n        inputs,\n        text_target=labels,\n        max_length = 128)\n\n    return model_inputs\n</code></pre>"},{"location":"chapter6/translation/translation/#_6","title":"\u6570\u636e\u96c6\u8f6c\u5316","text":"Python<pre><code>tokenized_datasets = raw_datasets.map(\n    tokenize_fn,\n    batched=True,\n    remove_columns=raw_datasets[\"train\"].column_names\n)\n</code></pre> tokenized_datasets<pre><code>DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 55364\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 13842\n    })\n})\n</code></pre>"},{"location":"chapter6/translation/translation/#_7","title":"\u52a0\u8f7d\u6a21\u578b","text":"Python<pre><code>from transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")\n</code></pre>"},{"location":"chapter6/translation/translation/#_8","title":"\u5b9a\u4e49\u6574\u7406\u51fd\u6570","text":"Python<pre><code>from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n</code></pre> Python<pre><code>batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n</code></pre> batch.keys()<pre><code>dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])\n</code></pre> Python<pre><code>example_input_ids = batch[\"input_ids\"][3]\nexample_attention_mask = batch[\"attention_mask\"][3]\nexample_labels = batch[\"labels\"][3]\nexample_decoder_input_ids = batch[\"decoder_input_ids\"][3]\n\n\nprint(tokenizer.decode(example_input_ids))\nprint(tokenizer.decode(example_labels))\nprint(tokenizer.decode(example_decoder_input_ids))\n</code></pre> Python<pre><code>'\u666e\u6797\u65af\u987f\u2014\u7f8e\u56fd\u6b63\u5728\u5d1b\u8d77;\u6b27\u6d32\u6b63\u5728\u7a33\u5b9a;\u4e24\u8fb9\u65e5\u76ca\u5bc6\u5207\u3002\u8fd9\u662f\u672c\u6708\u4e3e\u884c\u7684\u4e00\u5e74\u4e00\u5ea6\u7684\u6155\u5c3c\u9ed1\u5b89\u5168\u4f1a\u8bae(MSC)\u653e\u51fa\u7684\u4e3b\u8981\u4fe1\u606f\u3002MSC\u662f\u5404\u56fd\u56fd\u9632\u90e8\u957f\u3001\u5916\u4ea4\u90e8\u957f\u3001\u9ad8\u7ea7\u519b\u5b98\u3001\u8bae\u5458\u3001\u8bb0\u8005\u548c\u5404\u9886\u57df\u56fd\u5bb6\u5b89\u5168\u987e\u95ee\u53c2\u4e0e\u7684\u9ad8\u89c4\u683c\u4f1a\u8bae\u3002&lt;/s&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;'\n'Europe is stabilizing; and both are moving closer together. That was the principal message earlier this month at the annual Munich Security Conference (MSC), a high-powered gathering of defense ministers, foreign ministers, senior military officials, parliamentarians, journalists, and national-security experts of every variety.&lt;/s&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt;'\n'&lt;pad&gt; Europe is stabilizing; and both are moving closer together. That was the principal message earlier this month at the annual Munich Security Conference (MSC), a high-powered gathering of defense ministers, foreign ministers, senior military officials, parliamentarians, journalists, and national-security experts of every variety.&lt;/s&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;'\n</code></pre>"},{"location":"chapter6/translation/translation/#_9","title":"\u5b9a\u4e49\u8bc4\u4f30\u51fd\u6570","text":"Python<pre><code># pip install sacrebleu\nimport evaluate\n\nmetric = evaluate.load(\"sacrebleu\")\n</code></pre> Python<pre><code>import numpy as np\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    # In case the model returns more than the prediction logits\n    if isinstance(preds, tuple):\n        preds = preds[0]\n\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    # Replace -100s in the labels as we can't decode them\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds = [pred.strip() for pred in decoded_preds]\n    decoded_labels = [[label.strip()] for label in decoded_labels]\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": result[\"score\"]}\n</code></pre>"},{"location":"chapter6/translation/translation/#_10","title":"\u5b9a\u4e49\u8d85\u53c2\u6570","text":"Python<pre><code>from transformers import Seq2SeqTrainingArguments\n\nargs = Seq2SeqTrainingArguments(\n    f\"finetuned-zh-to-en\",\n    evaluation_strategy=\"no\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=64,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=3,\n    predict_with_generate=True,\n    fp16=True,\n)\n</code></pre>"},{"location":"chapter6/translation/translation/#_11","title":"\u5b9a\u4e49\u8bad\u7ec3\u5668","text":"Python<pre><code>from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n</code></pre>"},{"location":"chapter6/translation/translation/#_12","title":"\u8bad\u7ec3","text":"Python<pre><code>trainer.train()\n</code></pre>"},{"location":"chapter6/translation/translation/#_13","title":"\u53c2\u8003\u8d44\u6599","text":"<ul> <li> <p>HuggingFace\u793e\u533a\u6559\u7a0b</p> <p>\u6587\u672c\u7ffb\u8bd1\u00a0\u29c9</p> </li> </ul>"},{"location":"chapter7/gradio_index/","title":"\u7d22\u5f15","text":"<p>\u4e3b\u9875</p> <ul> <li><code>Gradio</code>\u7b80\u4ecb</li> <li><code>Gradio</code>\u5e03\u5c40</li> </ul>"},{"location":"chapter7/gradio/gradio_layout/","title":"\u81ea\u5b9a\u4e49\u5e03\u5c40","text":""},{"location":"chapter7/gradio/gradio_layout/#_1","title":"\u524d\u8a00","text":"<p>\u5728 <code>Gradio</code> \u5f00\u53d1\u4e2d\uff0c\u63d0\u524d\u56fa\u5b9a\u597d\u5e03\u5c40\u53ef\u4ee5\u5e2e\u52a9\u5f00\u53d1\u8005\u66f4\u597d\u5730\u7ec4\u7ec7\u754c\u9762\uff0c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\uff0c\u5e76\u786e\u4fdd\u6700\u7ec8\u5e94\u7528\u7684\u89c6\u89c9\u6548\u679c\u3002</p> <p>\u4ee5\u4e0b\u662f\u51e0\u79cd\u5e38\u7528\u7684\u5e03\u5c40\u65b9\u5f0f\u3002</p> <ol> <li>\u4f7f\u7528 <code>gradio.Interface</code> \u6784\u5efa\u57fa\u7840\u5e03\u5c40</li> <li>\u4f7f\u7528\u00a0<code>gradio.Blocks</code>\u00a0\u6784\u5efa\u66f4\u590d\u6742\u7684\u5e03\u5c40</li> <li>\u4f7f\u7528\u6837\u5f0f\u8868\u81ea\u5b9a\u4e49\u5e03\u5c40</li> </ol> <p>\u5e03\u5c40\u9009\u62e9</p> <p>\u5bf9\u4e8e\u5f00\u53d1\u8005\u6765\u8bf4\uff0c\u65b9\u6cd5 1 \u5f80\u5f80\u4e0d\u80fd\u6ee1\u8db3\u65e5\u5e38\u4f7f\u7528\u573a\u666f\uff0c\u56e0\u4e3a\u8fd9\u79cd\u65b9\u6cd5\u8fc7\u4e8e\u7b80\u5355\uff0c\u4e0d\u5982\u65b9\u6cd5 2 \u7075\u6d3b\uff0c\u540c\u65f6\u65b9\u6cd5 3 \u53c8\u8fc7\u4e8e\u590d\u6742\uff0c\u6700\u9002\u5408\u5927\u4f17\u5f00\u53d1\u8005\u7684\u5c31\u662f\u65b9\u6cd5 2\uff0c\u8be5\u65b9\u6cd5\u7075\u6d3b\u6613\u7528\uff0c\u53ef\u6784\u5efa\u590d\u6742\u5e03\u5c40\uff0c\u5982\u679c\u9700\u8981\u6784\u5efa\u66f4\u590d\u6742\u7684\u5e03\u5c40\uff0c\u53ef\u4ee5\u5c06\u65b9\u6cd5 2 \u548c\u65b9\u6cd5 3 \u7ed3\u5408\u3002</p>"},{"location":"chapter7/gradio/gradio_layout/#row","title":"<code>Row</code>\uff08\u884c\u5e03\u5c40\uff09","text":"<p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c<code>Blocks</code> \u4e2d\u7684\u7ec4\u4ef6\u662f\u5782\u76f4\u6392\u5217\u7684\u3002\u8ba9\u6211\u4eec\u5f00\u59cb\u7528 <code>Rows</code> \u91cd\u65b0\u6392\u5217\u7ec4\u4ef6\u3002</p> <p>\u5f53\u5f00\u53d1\u8005\u5e0c\u671b\u591a\u4e2a\u7ec4\u4ef6\u5e76\u6392\u6392\u5217\uff0c\u53ea\u9700\u5728 <code>with gradio.Row()</code> \u4e0b\u6587\u4e2d\u521b\u5efa\u7ec4\u4ef6\uff08\u5404\u79cd\u7ec4\u4ef6\u5c06\u5728\u540e\u7eed\u4e00\u4e00\u8bf4\u660e\uff09\u5373\u53ef  (1)  \u3002</p> <ol> <li>\u4ee3\u7801\u89e3\u8bfb<ol> <li><code>with gr.Blocks() as demo:</code>\uff1a\u521b\u5efa\u4e86\u4e00\u4e2a Gradio \u5e94\u7528\u7a0b\u5e8f\uff0c\u5e76\u5c06\u5176\u8d4b\u503c\u7ed9\u00a0<code>demo</code>\u3002</li> <li><code>with gr.Row():</code>\uff1a\u521b\u5efa\u4e86\u4e00\u4e2a\u6c34\u5e73\u6392\u5217\u7684\u5bb9\u5668\uff0c\u6240\u6709\u5728\u8fd9\u4e2a\u5bb9\u5668\u4e2d\u521b\u5efa\u7684\u5143\u7d20\u90fd\u4f1a\u88ab\u6c34\u5e73\u6392\u5217\u3002</li> <li><code>img = gr.Image()</code>\uff1a\u521b\u5efa\u4e86\u4e00\u4e2a\u56fe\u7247\u7ec4\u4ef6\uff0c\u5e76\u5c06\u5176\u8d4b\u503c\u7ed9\u00a0<code>img</code>\u3002</li> <li><code>audio = gr.Audio()</code>\uff1a\u521b\u5efa\u4e86\u53e6\u4e00\u4e2a\u56fe\u7247\u7ec4\u4ef6\uff0c\u5e76\u5c06\u5176\u8d4b\u503c\u7ed9\u00a0<code>audio</code>\u3002</li> <li><code>demo.launch()</code>\uff1a\u542f\u52a8 Gradio \u5e94\u7528\u7a0b\u5e8f\u3002</li> </ol> </li> </ol> Python<pre><code>import gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        img = gr.Image()\n        audio = gr.Audio()\ndemo.launch()\n</code></pre> <p></p> <p>\u4e0b\u9762\u662f <code>gradio.Row</code>\u00a0\u53c2\u6570\u5bf9\u7167\u8868\uff1a</p> \u53c2\u6570\u540d \u7c7b\u578b \u9ed8\u8ba4\u503c \u63cf\u8ff0 <code>variant</code> <code>Literal[('default', 'panel', 'compact')]</code> <code>\"default\"</code> \u884c\u7c7b\u578b\uff0c<code>'default'</code>\u00a0(\u65e0\u80cc\u666f)\uff0c<code>'panel'</code>\u00a0(\u7070\u8272\u80cc\u666f\u548c\u5706\u89d2)\uff0c\u6216\u8005\u00a0<code>'compact'</code>\u00a0(\u5706\u89d2\u548c\u65e0\u5185\u90e8\u95f4\u8ddd)\u3002 <code>visible</code> <code>bool</code> <code>True</code> \u5982\u679c\u4e3a\u00a0<code>False</code>\uff0c\u5219\u8be5\u884c\u5c06\u88ab\u9690\u85cf\u3002 <code>equal_height</code> <code>bool</code> <code>True</code> \u5982\u679c\u4e3a\u00a0<code>True</code>\uff0c\u5219\u6240\u6709\u5b50\u5143\u7d20\u7684\u9ad8\u5ea6\u4e00\u81f4\u3002 <code>show_progress</code> <code>bool</code> <code>False</code> \u5982\u679c\u4e3a\u00a0<code>True</code>\uff0c\u5219\u5728\u66f4\u65b0\u65f6\u663e\u793a\u8fdb\u5ea6\u52a8\u753b\u3002 <code>elem_id</code> <code>str</code> <code>None</code> \u53ef\u9009\u7684\u5b57\u7b26\u4e32\uff0c\u4f5c\u4e3a\u8be5\u7ec4\u4ef6\u5728 HTML DOM \u4e2d\u7684 id\u3002\u53ef\u7528\u4e8e\u5b9a\u4f4d CSS \u6837\u5f0f\u3002 <code>elem_classes</code> <code>list[str]</code> <code>None</code> \u53ef\u9009\u7684\u5b57\u7b26\u4e32\u6216\u5b57\u7b26\u4e32\u5217\u8868\uff0c\u4f5c\u4e3a\u8be5\u7ec4\u4ef6\u5728 HTML DOM \u4e2d\u7684\u7c7b\u3002\u53ef\u7528\u4e8e\u5b9a\u4f4d CSS \u6837\u5f0f\u3002 <p>\u4e0b\u9762\u662f\u4e00\u4e9b\u53c2\u6570\u53d8\u5316\u5bf9\u7167\u56fe\uff1a</p> visibleequal_heightshow_progress visible<pre><code>import gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row(visible=False):\n        img = gr.Image()\n        audio = gr.Audio()\ndemo.launch()\n</code></pre> <p></p> equal_height<pre><code>import gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row(equal_height=False):\n        img = gr.Image()\n        audio = gr.Audio()\ndemo.launch()\n</code></pre> <p></p> show_progress<pre><code>import gradio as gr\n\nwith gr.Blocks () as demo:\n    with gr.Row (show_progress=True):\n        img = gr.Image ()\n        audio = gr.Audio ()\ndemo.launch ()\n</code></pre> <p></p>"},{"location":"chapter7/gradio/gradio_layout/#column","title":"<code>Column</code>\uff08\u5217\u5e03\u5c40\uff09","text":"<p>\u4e0e <code>Row</code> \u7c7b\u4f3c\uff0c<code>Column</code> \u7528\u4e8e\u5782\u76f4\u6392\u5217\u7ec4\u4ef6\u3002</p> <p>\u5f53\u5f00\u53d1\u8005\u5e0c\u671b\u591a\u4e2a\u7ec4\u4ef6\u4e0a\u4e0b\u6392\u5217\uff0c\u53ea\u9700\u5728 <code>with gradio.Column ()</code> \u4e0b\u6587\u4e2d\u521b\u5efa\u7ec4\u4ef6\u5373\u53ef\u3002</p> Python<pre><code>import gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Column():\n        img = gr.Image()\n        audio = gr.Audio()\ndemo.launch()\n</code></pre> <p></p> <p>\u4e0b\u9762\u662f <code>gradio.Column</code>\u00a0\u53c2\u6570\u5bf9\u7167\u8868\uff1a</p> \u53c2\u6570\u540d \u7c7b\u578b \u9ed8\u8ba4\u503c \u63cf\u8ff0 <code>scale</code> <code>int</code> <code>1</code> \u76f8\u5bf9\u4e8e\u76f8\u90bb\u5217\u7684\u76f8\u5bf9\u5bbd\u5ea6\u3002\u4f8b\u5982\uff0c\u5982\u679c\u5217 A \u7684\u00a0<code>scale</code>\u00a0\u4e3a 2\uff0c\u800c\u5217 B \u7684\u00a0<code>scale</code>\u00a0\u4e3a 1\uff0c\u5219 A \u7684\u5bbd\u5ea6\u5c06\u662f B \u7684\u4e24\u500d\u3002 <code>min_width</code> <code>int</code> <code>320</code> \u5217\u7684\u6700\u5c0f\u50cf\u7d20\u5bbd\u5ea6\uff0c\u5982\u679c\u5c4f\u5e55\u7a7a\u95f4\u4e0d\u8db3\u4ee5\u6ee1\u8db3\u6b64\u503c\uff0c\u5219\u4f1a\u6362\u884c\u3002\u5982\u679c\u67d0\u4e2a\u00a0<code>scale</code>\u00a0\u503c\u5bfc\u81f4\u5217\u5bbd\u5ea6\u5c0f\u4e8e\u00a0<code>min_width</code>\uff0c\u5219\u4f1a\u4f18\u5148\u8003\u8651\u00a0<code>min_width</code>\u00a0\u53c2\u6570\u3002 <code>variant</code> <code>Literal[('default', 'panel', 'compact')]</code> <code>\"default\"</code> \u5217\u7c7b\u578b\uff0c<code>'default'</code>\u00a0(\u65e0\u80cc\u666f)\uff0c<code>'panel'</code>\u00a0(\u7070\u8272\u80cc\u666f\u548c\u5706\u89d2)\uff0c\u6216\u8005\u00a0<code>'compact'</code>\u00a0(\u5706\u89d2\u548c\u65e0\u5185\u90e8\u95f4\u8ddd)\u3002 <code>visible</code> <code>bool</code> <code>True</code> \u5982\u679c\u4e3a\u00a0<code>False</code>\uff0c\u5219\u8be5\u5217\u5c06\u88ab\u9690\u85cf\u3002 <code>show_progress</code> <code>bool</code> <code>False</code> \u5982\u679c\u4e3a\u00a0<code>True</code>\uff0c\u5219\u5728\u66f4\u65b0\u65f6\u663e\u793a\u8fdb\u5ea6\u52a8\u753b\u3002 <code>render</code> <code>bool</code> <code>True</code> \u5982\u679c\u4e3a\u00a0<code>False</code>\uff0c\u5219\u8be5\u7ec4\u4ef6\u4e0d\u4f1a\u5728\u00a0<code>Blocks</code>\u00a0\u4e0a\u4e0b\u6587\u4e2d\u6e32\u67d3\u3002\u5982\u679c\u9700\u8981\u73b0\u5728\u5206\u914d\u4e8b\u4ef6\u76d1\u542c\u5668\uff0c\u4f46\u7a0d\u540e\u6e32\u67d3\u7ec4\u4ef6\uff0c\u5219\u5e94\u4f7f\u7528\u6b64\u53c2\u6570\u3002 <code>elem_id</code> <code>str</code> <code>None</code> \u53ef\u9009\u7684\u5b57\u7b26\u4e32\uff0c\u4f5c\u4e3a\u8be5\u7ec4\u4ef6\u5728 HTML DOM \u4e2d\u7684 id\u3002\u53ef\u7528\u4e8e\u5b9a\u4f4d CSS \u6837\u5f0f\u3002 <code>elem_classes</code> <code>list[str]</code> <code>None</code> \u53ef\u9009\u7684\u5b57\u7b26\u4e32\u6216\u5b57\u7b26\u4e32\u5217\u8868\uff0c\u4f5c\u4e3a\u8be5\u7ec4\u4ef6\u5728 HTML DOM \u4e2d\u7684\u7c7b\u3002\u53ef\u7528\u4e8e\u5b9a\u4f4d CSS \u6837\u5f0f\u3002"},{"location":"chapter7/gradio/gradio_layout/#nesting","title":"<code>Nesting</code>\uff08\u9576\u5d4c\u5e03\u5c40\uff09","text":"<p>\u5728 <code>Gradio</code> \u4e2d\uff0c<code>Column</code>\u00a0\u5e03\u5c40\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u4f1a\u5c06\u5185\u90e8\u7ec4\u4ef6\u5782\u76f4\u6392\u5217\uff0c\u800c\u8fd9\u6070\u597d\u662f\u00a0<code>Blocks</code>\u00a0\u5e94\u7528\u7a0b\u5e8f\u7684\u9ed8\u8ba4\u5e03\u5c40\u65b9\u5f0f\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u4f7f\u00a0<code>Column</code>\u00a0\u7ec4\u4ef6\u53d1\u6325\u4f5c\u7528\uff0c\u901a\u5e38\u9700\u8981\u5c06\u5176\u5d4c\u5957\u5728\u00a0<code>Row</code>\u00a0\u7ec4\u4ef6\u4e2d\uff0c\u4ee5\u5b9e\u73b0\u6c34\u5e73\u6392\u5217\u3002</p> <p>\u5047\u8bbe\u8981\u521b\u5efa\u4e0b\u9762\u793a\u4f8b\u7684\u5e03\u5c40\uff0c\u6216\u662f\u66f4\u590d\u6742\u7684\u5e03\u5c40\u90fd\u53ef\u4ee5\u4f7f\u7528 <code>Row</code> \u4e0e <code>Column</code> \u7684\u5d4c\u5957\u6765\u5b9e\u73b0\u3002</p> Python<pre><code>import gradio as gr\n\nwith gr.Blocks() as demo:\n\u00a0 \u00a0 with gr.Row():\n\u00a0 \u00a0 \u00a0 \u00a0 img1 = gr.Image()\n\u00a0 \u00a0 \u00a0 \u00a0 img2 = gr.Image()\n\u00a0 \u00a0 with gr.Row():\n\u00a0 \u00a0 \u00a0 \u00a0 img3 = gr.Image()\n\u00a0 \u00a0 \u00a0 \u00a0 with gr.Column():\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 with gr.Column():\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 btn1 = gr.Button()\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 btn2 = gr.Button()\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 btn3 = gr.Button()\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 btn4 = gr.Button()\ndemo.launch()\n</code></pre> <p></p>"},{"location":"chapter7/gradio/gradio_layout/#_2","title":"\u53c2\u8003\u8d44\u6599","text":"<ul> <li> <p><code>Gradio</code> \u6587\u6863\uff08\u5e03\u5c40\u90e8\u5206\uff09</p> <p>\u7528 <code>Blocks</code> \u5efa\u7acb\u5e03\u5c40\u00a0\u29c9</p> </li> <li> <p>flexbox \u7684\u57fa\u672c\u6982\u5ff5</p> <p>\u5e03\u5c40\u4ecb\u7ecd\u00a0\u29c9</p> </li> </ul>"},{"location":"chapter7/gradio/gradio_tour/","title":"\u8ba9\u673a\u5668\u5b66\u4e60\u5e94\u7528\u89e6\u624b\u53ef\u53ca","text":""},{"location":"chapter7/gradio/gradio_tour/#_1","title":"\u524d\u8a00","text":"<p>\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u8005\u548c\u79d1\u5b66\u5bb6\u901a\u5e38\u4f1a\u4e13\u6ce8\u4e8e\u7b97\u6cd5\u7814\u7a76\u548c\u5f00\u53d1\uff0c\u800c\u7f3a\u4e4f\u65f6\u95f4\u548c\u7cbe\u529b\u53bb\u6784\u5efa\u7528\u6237\u754c\u9762\u548c\u8fdb\u884c\u90e8\u7f72\u3002\u8fd9\u5bfc\u81f4\u5f88\u591a\u4f18\u79c0\u7684\u6a21\u578b\u65e0\u6cd5\u8d70\u51fa\u5b9e\u9a8c\u5ba4\uff0c\u65e0\u6cd5\u771f\u6b63\u5e94\u7528\u5230\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u4e5f\u65e0\u6cd5\u8ba9\u66f4\u591a\u4eba\u4f53\u9a8c\u5230\u5176\u4ef7\u503c\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u9886\u57df\u5916\u7684\u6280\u672f\u4f53\u9a8c\u7231\u597d\u8005\uff0c\u901a\u5e38\u7f3a\u4e4f\u8db3\u591f\u7684\u673a\u5668\u5b66\u4e60\u77e5\u8bc6\u548c\u7f16\u7a0b\u7ecf\u9a8c\uff0c\u96be\u4ee5\u7406\u89e3\u548c\u4f7f\u7528\u8fd9\u4e9b\u6a21\u578b\u3002\u4ed6\u4eec\u6e34\u671b\u4f53\u9a8c\u548c\u63a2\u7d22\u673a\u5668\u5b66\u4e60\u7684\u9b45\u529b\uff0c\u5374\u96be\u4ee5\u8de8\u8d8a\u6280\u672f\u95e8\u69db\u3002</p> <p>\u800c <code>Gradio</code> \u7684\u51fa\u73b0\u6b63\u662f\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u56f0\u5883\u3002 \u5b83\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u6613\u7528\u7684\u5de5\u5177\uff0c\u8ba9\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u8005\u53ef\u4ee5\u5feb\u901f\u6784\u5efa\u4ea4\u4e92\u5f0f\u5e94\u7528\uff0c\u5c06\u6a21\u578b\u529f\u80fd\u5c55\u793a\u7ed9\u66f4\u591a\u4eba\uff0c\u5b83\u4e5f\u964d\u4f4e\u4e86\u6280\u672f\u4f53\u9a8c\u7231\u597d\u8005\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u95e8\u69db\uff0c\u8ba9\u4f53\u9a8c\u8005\u80fd\u591f\u8f7b\u677e\u5730\u4f53\u9a8c\u548c\u63a2\u7d22\u673a\u5668\u5b66\u4e60\u7684\u9b45\u529b\u3002</p> <p>\u5e02\u9762\u4e0a\u5b58\u5728\u8bb8\u591a\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u90e8\u7f72\u7684\u5de5\u5177\uff0c\u5728\u4e0b\u9762\u7b80\u5355\u5bf9\u6bd4\u4e00\u4e0b\u3002</p> \u5de5\u5177 \u4f18\u52bf \u7279\u70b9 <code>Gradio</code> \u7b80\u5316\u5f00\u53d1\u8fc7\u7a0b \u63d0\u4f9b\u4e30\u5bcc\u7684\u7ec4\u4ef6\u548c\u529f\u80fd\uff0c\u76f4\u89c2\u7684\u754c\u9762\u548c\u4ea4\u4e92\u65b9\u5f0f \u5feb\u901f\u90e8\u7f72 \u53ef\u4ee5\u5feb\u901f\u5c06\u6a21\u578b\u90e8\u7f72\u6210\u4ea4\u4e92\u5f0f Web \u5e94\u7528 \u6613\u4e8e\u5206\u4eab \u53ef\u4ee5\u521b\u5efa\u5916\u90e8\u5206\u4eab\u94fe\u63a5 \u964d\u4f4e\u4f7f\u7528\u95e8\u69db \u65e0\u9700\u4e86\u89e3\u4ee3\u7801\uff0c\u76f4\u63a5\u4e0e\u9875\u9762\u4ea4\u4e92\u5373\u53ef <code>Streamlit</code> \u5feb\u901f\u539f\u578b\u8bbe\u8ba1\uff0c\u4fa7\u91cd\u6570\u636e\u53ef\u89c6\u5316 \u66f4\u4fa7\u91cd\u4e8e\u6570\u636e\u53ef\u89c6\u5316\u548c\u4ea4\u4e92\u5f0f\u5c55\u793a <code>Flask</code> \u7075\u6d3b\u53ef\u63a7\uff0c\u529f\u80fd\u5f3a\u5927 \u9700\u8981\u4e00\u5b9a\u7684 Web \u5f00\u53d1\u7ecf\u9a8c \\(\\cdots\\) \\(\\cdots\\) \\(\\cdots\\) <p>\u7ed3\u8bba</p> <ul> <li>\u7ecf\u8fc7\u5404\u4e2a\u5de5\u5177\u5bf9\u6bd4\u540e\uff0c\u53ef\u4ee5\u77e5\u9053 <code>Gradio</code> \u66f4\u5177\u4f18\u52bf\u3002</li> <li><code>Gradio</code> \u7684\u51fa\u73b0\uff0c\u5c06\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ece\u5b9e\u9a8c\u5ba4\u5e26\u5230\u4e86\u5927\u4f17\u9762\u524d\uff0c\u8ba9\u66f4\u591a\u4eba\u80fd\u591f\u4f53\u9a8c\u548c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u63a8\u52a8\u4e86\u673a\u5668\u5b66\u4e60\u6280\u672f\u7684\u666e\u53ca\u548c\u5e94\u7528\u3002</li> </ul> <p>\u5b89\u88c5\uff1a</p> Python<pre><code>pip install gradio\n</code></pre>"},{"location":"chapter7/gradio/gradio_tour/#_2","title":"\u70ed\u91cd\u8f7d","text":"<p>\u5728\u63a5\u4e0b\u6765\u7684\u6559\u7a0b\uff0c\u5c06\u4ecb\u7ecd\u00a0<code>Gradio</code>\u00a0\u63d0\u4f9b\u7684\u5404\u5f0f\u5404\u6837\u7684\u7ec4\u4ef6\uff0c\u8fd9\u4e9b\u7ec4\u4ef6\u53ef\u4ee5\u5e2e\u52a9\u4f60\u5feb\u901f\u6784\u5efa\u4ea4\u4e92\u5f0f\u673a\u5668\u5b66\u4e60\u5e94\u7528\u3002\u7136\u800c\uff0c\u5728\u7f16\u5199\u4ee3\u7801\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5f00\u53d1\u8005\u7ecf\u5e38\u9700\u8981\u5bf9\u4ee3\u7801\u8fdb\u884c\u589e\u5220\u6539\u67e5\uff0c\u7136\u540e\u4e00\u904d\u904d\u8fd0\u884c\u8c03\u8bd5\uff0c\u800c\u4e14\u5927\u90e8\u5206\u60c5\u51b5\u8fd8\u9700\u8981\u6f2b\u957f\u7684\u65f6\u95f4\u7528\u6765\u52a0\u8f7d\u5e9e\u5927\u7684\u6a21\u578b\u3002</p> <p>\u901a\u5e38\uff0c<code>Gradio</code> \u5e94\u7528\u50cf\u8fd0\u884c\u4efb\u4f55\u5176\u4ed6 Python \u811a\u672c\u4e00\u6837\u542f\u52a8\uff0c\u53ea\u9700\u6267\u884c\u00a0<code>python xxx.py</code>\u3002\u8fd9\u4f1a\u542f\u52a8\u4e00\u4e2a <code>HTTP</code> \u670d\u52a1\u5668\uff0c\u6e32\u67d3\u5e94\u7528 <code>UI</code> \u3002\u5982\u679c\u9700\u8981\u4fee\u6539\u5e94\u7528\uff0c\u901a\u5e38\u4f1a\u505c\u6b62\u670d\u52a1\u5668\uff08\u901a\u5e38\u4f7f\u7528  Ctrl+C \uff09\uff0c\u7f16\u8f91\u6e90\u6587\u4ef6\u540e\u91cd\u65b0\u8fd0\u884c\u811a\u672c\u3002\u60f3\u8c61\u4e00\u4e0b\uff0c\u5982\u679c\u5728\u5f00\u53d1\u4e2d\u5bf9 <code>Gradio</code> \u4ee3\u7801\u6539\u52a8\u540e\u7684\u7ed3\u679c\u80fd\u5b9e\u65f6\u9884\u89c8\uff0c\u90a3\u5c5e\u5b9e\u8ba9\u4eba\u5fc3\u60c5\u6109\u60a6\ud83e\udd23\uff01</p> <p>\u597d\u6d88\u606f\u662f\uff0c<code>Gradio</code> \u5185\u7f6e\u4e86\u70ed\u91cd\u8f7d\u529f\u80fd\uff01\u2728\u00a0\u8fd9\u610f\u5473\u7740\u5f00\u53d1\u8005\u5728\u4fee\u6539\u4ee3\u7801\u540e\uff0c\u53ef\u4ee5\u7acb\u5373\u770b\u5230\u4fee\u6539\u540e\u7684\u6548\u679c\uff0c\u65e0\u9700\u91cd\u65b0\u542f\u52a8\u7a0b\u5e8f\uff0c\u8fd9\u5bf9\u4e8e\u5feb\u901f\u8fed\u4ee3\u548c\u8c03\u8bd5\u4ee3\u7801\u975e\u5e38\u6709\u7528\u3002\u5f00\u53d1\u8005\u53ea\u9700\u8fd0\u884c\u00a0<code>gradio app.py</code>\u00a0\u800c\u4e0d\u662f\u00a0<code>python app.py</code>\uff0c\u5373\u53ef\u5728\u70ed\u91cd\u8f7d\u6a21\u5f0f\u4e0b\u542f\u52a8\u5e94\u7528\uff01</p> <p>\u6f14\u793a\ud83c\udf9e\uff1a</p> <p></p> <p>\u70ed\u91cd\u8f7d</p> <p>\u70ed\u91cd\u8f7d\u8fd8\u6709\u5f88\u591a\u53ef\u5708\u53ef\u70b9\u7684\u529f\u80fd\uff0c\u4f46\u662f\u4e0a\u9762\u7684\u6848\u4f8b\u5c31\u8db3\u591f\u652f\u6491\u540e\u9762\u7684\u6559\u7a0b\u3002</p>"},{"location":"chapter7/gradio/gradio_tour/#_3","title":"\u53c2\u8003\u8d44\u6599","text":"<ul> <li> <p>\u4f7f\u7528 <code>Gradio</code> \u7684\u201c\u70ed\u91cd\u8f7d\u201d\u6a21\u5f0f\u5feb\u901f\u5f00\u53d1 AI \u5e94\u7528</p> <p><code>Gradio</code>\u70ed\u91cd\u8f7d\u4e0e\u8fdb\u9636\u529f\u80fd\u00a0\u29c9</p> </li> <li> <p>\u6784\u5efa\u5e76\u5206\u4eab\u4ee4\u4eba\u6109\u5feb\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\u7a0b\u5e8f</p> <p><code>Gradio</code> \u5b98\u65b9\u6587\u6863\u00a0\u29c9</p> </li> </ul>"},{"location":"chapter8/repositories_index/","title":"\u7d22\u5f15","text":"<p>\u4e3b\u9875</p> <ul> <li>HuggingFace\u4ed3\u5e93\u6574\u4f53\u4ecb\u7ecd</li> </ul>"},{"location":"chapter8/repositories/repositories/","title":"\u521d\u8bc6\u4ed3\u5e93\u7ed3\u6784","text":""},{"location":"chapter8/repositories/repositories/#_1","title":"\u524d\u8a00","text":"<p><code>transformers</code> \u5df2\u7136\u6210\u4e3a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u4e0d\u53ef\u6216\u7f3a\u7684\u4e00\u90e8\u5206\uff0c\u56e0\u4e3a\u5b83\u662f\u4e00\u4e2a\u7b80\u6d01\u3001\u6807\u51c6\u3001\u9ad8\u6548\u4e14\u5f3a\u5927\u7684\u5de5\u5177\u3002</p> <p>\u4fd7\u8bdd\u8bf4\u201c\u5de5\u6b32\u5584\u5176\u4e8b\uff0c\u5fc5\u5148\u5229\u5176\u5668\u201d\uff0c\u4e3a\u4e86\u624b\u62ff\u628a\u6390 <code>transformers</code>\uff0c\u7406\u89e3\u5176\u4ed3\u5e93\u7ed3\u6784\u53ca\u76f8\u5173\u4ee3\u7801\u81f3\u5173\u91cd\u8981\u3002</p> <p>\u672c\u6587\u5c06\u4ecb\u7ecd<code>transformers</code>\u00a0\u29c9\u4ed3\u5e93\u7684\u91cd\u8981\u90e8\u5206\u3002</p>"},{"location":"chapter8/repositories/repositories/#_2","title":"\u603b\u4f53","text":"<p>\u5728\u6839\u76ee\u5f55\u53ef\u4ee5\u770b\u5230</p> Text Only<pre><code>.circleci/\n.github/\nbenchmark/\ndocker/\n...\nscripts\nsrc\ntemplates\n...\n</code></pre> <ol> <li>\u91cd\u70b9\u5c31\u5728\u4e8e <code>src</code> \u76ee\u5f55\u4e0b\u7684 <code>transformers</code> \u4e0b\u7684\u4ee3\u7801\uff0c\u5f00\u53d1\u8005\u5728\u4f7f\u7528 <code>transformers</code> \u7684\u65f6\u5019\u5c31\u662f\u5728\u8fd9\u91cc\u8c03\u7528\u51fd\u6570\u3002</li> <li>\u5728transformers\u76ee\u5f55\u4e0b\uff0c\u91cd\u8981\u7684\u90e8\u5206\u5c31\u662f<code>generation</code>\u3001<code>intergration</code>\u3001<code>kernels</code>\u3001<code>models</code>\u3001<code>pipelines</code>\u8fd9\u4e9b\u76ee\u5f55\u3002<ol> <li><code>generation</code>\uff1a\u5b58\u50a8\u7528\u4e8e\u6587\u672c\u751f\u6210\u7684\u5404\u79cd\u7b97\u6cd5\uff0c\u4f8b\u5982<code>beam search</code>\u3001<code>greedy search</code>\u7b49\u7b97\u6cd5\u3002</li> <li><code>intergration</code>\uff1a\u5305\u542b\u4e0e\u5176\u4ed6\u5e93\u548c\u6846\u67b6\u7684\u96c6\u6210\u4ee3\u7801\uff0c\u4f8b\u5982\u5185\u7f6e\u4e00\u90e8\u5206 <code>PEFT</code> \u7b97\u6cd5\u3001 <code>deepspeed</code> \u52a0\u901f\u7ec4\u4ef6\u3002</li> <li><code>kernels</code>\uff1a\u5b58\u50a8\u81ea\u5b9a\u4e49\u5b9e\u73b0\u7684<code>CUDA</code>\u7b97\u5b50\u3002</li> <li><code>models</code>\uff1a\u5b58\u50a8\u7740\u5404\u79cd\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5b9e\u73b0\uff0c\u662f\u8fd9\u4e2a\u4ed3\u5e93\u7684\u7075\u9b42\u6240\u5728\u3002</li> <li><code>pipelines</code>\uff1a\u5b58\u50a8\u7740\u9ad8\u9636\u63a5\u53e3\uff0c\u8fd9\u4e9b\u63a5\u53e3\u5141\u8bb8\u5f00\u53d1\u8005\u65b9\u4fbf\u5730\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u5b8c\u6210\u5404\u79cd\u4efb\u52a1\u3002</li> </ol> </li> <li>\u5bf9\u4e8e\u67d0\u6a21\u578b\uff0c\u5176\u76f8\u5173\u914d\u7f6e\uff0c\u5904\u7406\u5668\u548c\u6a21\u578b\u5b9e\u73b0\u90fd\u4f1a\u88ab\u5b58\u653e\u5230\u540c\u4e00\u6587\u4ef6\u5939\u4e0b\u3002\u540c\u65f6\u4e0d\u540c\u6a21\u578b\u6587\u4ef6\u5939\u53c8\u4f1a\u7edf\u4e00\u653e\u5728 <code>models</code> \u6587\u4ef6\u5939\u4e0b\u3002</li> <li>\u5728\u67d0\u4e00 NLP \u9886\u57df\u6a21\u578b\u6587\u4ef6\u5939\u4e0b\uff0c\u901a\u5e38\u4f1a\u5305\u62ec\u914d\u7f6e\u6587\u4ef6\uff0c\u6a21\u578b\u5b9e\u73b0\uff0c\u5206\u8bcd\u5668\uff0c\u5176\u4f59\u6587\u4ef6\u56e0\u6a21\u578b\u800c\u5f02\u3002<ol> <li>\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u6a21\u578b\u53ef\u80fd\u8fd8\u4f1a\u5b58\u5728\u9884\u5904\u7406\u5668\u6587\u4ef6\u3002</li> <li>\u90e8\u5206\u6a21\u578b\u5b58\u5728\u4e0d\u540c\u6846\u67b6\u6743\u91cd\u6587\u4ef6\u8f6c\u5316\u5668\u3002</li> <li>\u53ef\u80fd\u6709\u7684\u6a21\u578b\u7528\u7684\u662f\u522b\u7684\u6a21\u578b\u7684\u5206\u8bcd\u5668\uff0c\u81ea\u7136\u4e5f\u5c31\u4e0d\u4f1a\u5728\u6a21\u578b\u6587\u4ef6\u5939\u4e0b\u5b58\u5728\u5206\u8bcd\u5668\u6587\u4ef6\u3002</li> <li>\u6587\u4ef6\u540d\u79f0\u4e2d\u5b58\u5728<code>tf</code>\u3001<code>flax</code>\u7b49\u4e0d\u540c\u6846\u67b6\u7f29\u5199\u7684\uff0c\u8868\u793a\u8be5\u6587\u4ef6\u662f\u5728\u5bf9\u5e94\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e0b\u5b9e\u73b0\u7684\u3002</li> <li>\\(\\cdots\\)</li> </ol> </li> <li><code>configuration_xxx.py</code> \u901a\u5e38\u4ee3\u8868\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u914d\u7f6e\u53c2\u6570\u3002<code>model_xxx.py</code> \u901a\u5e38\u4ee3\u8868\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5b9e\u73b0\u3002<code>tokenization_xxx.py</code> \u901a\u5e38\u4ee3\u8868\u4e0e\u6a21\u578b\u914d\u5957\u7684\u5206\u8bcd\u5668\u3002</li> </ol>"}]}