<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content=Datawhale开源教程Unlock-HF><meta name=author content=moyanxinxu><link href=../../peft_index/ rel=prev><link href=../../lora_tour/lora_tour/ rel=next><link rel=icon href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.44"><title>PEFT（Parameter-Efficient Fine-Tuning） - Unlock-HF</title><link rel=stylesheet href=../../../assets/stylesheets/main.0253249f.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><style>:root{--md-annotation-icon:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M22 12a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M6 13h8l-3.5 3.5 1.42 1.42L17.84 12l-5.92-5.92L10.5 7.5 14 11H6z"/></svg>');}</style><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><link href=../../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#_1 class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title=Unlock-HF class="md-header__button md-logo" aria-label=Unlock-HF data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Unlock-HF </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> PEFT（Parameter-Efficient Fine-Tuning） </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label=暗色模式 type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title=暗色模式 for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=teal data-md-color-accent=indigo aria-label=亮色模式 type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title=亮色模式 for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/datawhalechina/unlock-hf title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> 主页 </a> </li> <li class=md-tabs__item> <a href=../../../chapter1/datasets_index/ class=md-tabs__link> Datasets工具 </a> </li> <li class=md-tabs__item> <a href=../../../chapter2/transformers_index/ class=md-tabs__link> Transformers工具 </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../peft_index/ class=md-tabs__link> PEFT工具 </a> </li> <li class=md-tabs__item> <a href=../../../chapter5/diffusers_index/ class=md-tabs__link> Diffusers工具 </a> </li> <li class=md-tabs__item> <a href=../../../chapter6/code_index/ class=md-tabs__link> 代码案例 </a> </li> <li class=md-tabs__item> <a href=../../../chapter7/gradio_index/ class=md-tabs__link> Gradio工具 </a> </li> <li class=md-tabs__item> <a href=../../../chapter8/repositories_index/ class=md-tabs__link> HuggingFace 代码仓库 </a> </li> <li class=md-tabs__item> <a href=../../../appendix/appendix_index/ class=md-tabs__link> 附录 </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title=Unlock-HF class="md-nav__button md-logo" aria-label=Unlock-HF data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Unlock-HF </label> <div class=md-nav__source> <a href=https://github.com/datawhalechina/unlock-hf title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> 主页 </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../chapter1/datasets_index/ class=md-nav__link> <span class=md-ellipsis> Datasets工具 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../chapter2/transformers_index/ class=md-nav__link> <span class=md-ellipsis> Transformers工具 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> PEFT工具 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> PEFT工具 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../peft_index/ class=md-nav__link> <span class=md-ellipsis> 索引 </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> PEFT </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> PEFT </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 前言 </span> </a> </li> <li class=md-nav__item> <a href=#peftconfig class=md-nav__link> <span class=md-ellipsis> PeftConfig </span> </a> <nav class=md-nav aria-label=PeftConfig> <ul class=md-nav__list> <li class=md-nav__item> <a href=#peft class=md-nav__link> <span class=md-ellipsis> PEFT 参数详解 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#peftmodel class=md-nav__link> <span class=md-ellipsis> PeftModel </span> </a> </li> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 训练 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 保存模型、推理 </span> </a> <nav class=md-nav aria-label=保存模型、推理> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 保存 </span> </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 推理 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> 参考资料 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../lora_tour/lora_tour/ class=md-nav__link> <span class=md-ellipsis> LoRA </span> </a> </li> <li class=md-nav__item> <a href=../../adalora_tour/adalora_tour/ class=md-nav__link> <span class=md-ellipsis> AdaLoRA </span> </a> </li> <li class=md-nav__item> <a href=../../ia3_tour/ia3_tour/ class=md-nav__link> <span class=md-ellipsis> IA3 </span> </a> </li> <li class=md-nav__item> <a href=../../prefix_tuning_tour/prefix_tuning_tour/ class=md-nav__link> <span class=md-ellipsis> Prefix-Tuning </span> </a> </li> <li class=md-nav__item> <a href=../../prompt_tuning_tour/prompt_tuning_tour/ class=md-nav__link> <span class=md-ellipsis> Prompt-Tuning </span> </a> </li> <li class=md-nav__item> <a href=../../p_tuning_tour/p_tuning_tour/ class=md-nav__link> <span class=md-ellipsis> P-Tuning </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../chapter5/diffusers_index/ class=md-nav__link> <span class=md-ellipsis> Diffusers工具 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../chapter6/code_index/ class=md-nav__link> <span class=md-ellipsis> 代码案例 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../chapter7/gradio_index/ class=md-nav__link> <span class=md-ellipsis> Gradio工具 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../chapter8/repositories_index/ class=md-nav__link> <span class=md-ellipsis> HuggingFace 代码仓库 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../appendix/appendix_index/ class=md-nav__link> <span class=md-ellipsis> 附录 </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/datawhalechina/unlock-hf/edit/main/docs/chapter3/peft_tour/peft_tour.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/datawhalechina/unlock-hf/raw/main/docs/chapter3/peft_tour/peft_tour.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1>PEFT</h1> <p><a class=glightbox href=../imgs/peft.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt=peft src=../imgs/peft.png></a></p> <h2 id=_1>前言<a class=headerlink href=#_1 title="Permanent link">&para;</a></h2> <p>🤗 <code>PEFT</code>（参数高效微调）是一个用于高效地将大规模预训练模型适配到各种下游应用的库。</p> <p>由于微调模型的所有参数成本高昂且难以实现，而 <code>PEFT</code> 方法只需要微调少量额外模型参数，从而显著降低了计算和存储成本，同时实现了与模型全量微调<strong>近乎相当</strong>的性能。这使得在消费级硬件上训练和保存大语言模型 (LLM) 变得更加容易。</p> <p>安装 <code>peft</code></p> <div class=highlight><table class=highlighttable><tr><th colspan=2 class=filename><span class=filename>安装peft</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1>1</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1 name=__codelineno-0-1></a>pip<span class=w> </span>install<span class=w> </span>peft
</code></pre></div></td></tr></table></div> <p>PEFT 涵盖众多主流低参高校微调技术，并可以和 <code>Transformers</code>、<code>Accelerate</code> 一起使用，比如</p> <ol> <li><code>LoRa</code></li> <li><code>Prefix Tuning</code></li> <li><code>AdaLoRA</code></li> <li><code>Prompt Tuning</code></li> <li><code>MultiTask Prompt Tuning</code></li> <li><code>LoHa</code></li> <li><span class=arithmatex>\(\cdots\)</span></li> </ol> <p><code>PEFT</code> 库支持的方法均可在 <a href=https://huggingface.co/docs/peft/main/en/package_reference/adalora#peft.AdaLoraConfig>Adapters HuggingFace&nbsp;⧉</a> 左侧导航栏查找</p> <p>接下来的内容将介绍 <code>PEFT</code> 的主要组成，以及如何训练或运行那些通常在消费级设备上难以训练的大规模语言模型。</p> <h2 id=peftconfig><code>PeftConfig</code><a class=headerlink href=#peftconfig title="Permanent link">&para;</a></h2> <p>每种 <code>PEFT</code> 方法都对应一个独特的 <code>PeftConfig</code> 类，用于存储构建<strong>相应</strong> <code>PeftModel</code> 的所有必要参数。</p> <p>当你想要调用某个 <code>PEFT</code> 方法时，需要先加载并创建一个该方法对应的 <code>PeftConfig</code> 类实例，并在实例化过程中指定该方法需要的参数。这些参数会因 <code>PEFT</code> 方法的不同而有所差异，例如：</p> <ul> <li><code>LoRa</code> (<code>LoraConfig</code>)：需要指定 <code>lora_rank</code>（低秩矩阵的秩）、<code>lora_alpha</code>（缩放因子）和 <code>lora_dropout</code>（dropout 概率）等参数。</li> <li><code>Prompt Tuning</code> (<code>PromptTuningConfig</code>)：需要指定 <code>prompt_tuning_num_tokens</code>（prompt 中的 token 数量）、<code>prompt_tuning_init_text</code>（prompt 的初始化文本）和 <code>prompt_tuning_placeholder_id</code>（占位符 ID）等参数。</li> </ul> <p>假如以 <code>LoRa</code> 为例子，怎么让 <code>LoRa</code> 作用于模型呢？</p> <ol> <li>引入 <code>LoraConfig</code> 类。</li> <li>定义 <code>LoRa</code> 的参数，包括 <code>task_type</code>，<code>inference_mode</code>，<code>r</code>，<code>lora_alpha</code> 和 <code>lora_dropout</code> 等。</li> </ol> <div class=highlight><table class=highlighttable><tr><th colspan=2 class=filename><span class=filename>LoraConfig</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-1-1>1</a></span>
<span class=normal><a href=#__codelineno-1-2>2</a></span>
<span class=normal><a href=#__codelineno-1-3>3</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-1-1 name=__codelineno-1-1></a><span class=kn>from</span> <span class=nn>peft</span> <span class=kn>import</span> <span class=n>LoraConfig</span><span class=p>,</span> <span class=n>TaskType</span>
<a id=__codelineno-1-2 name=__codelineno-1-2></a>
<a id=__codelineno-1-3 name=__codelineno-1-3></a><span class=n>peft_config</span> <span class=o>=</span> <span class=n>LoraConfig</span><span class=p>(</span><span class=n>task_type</span><span class=o>=</span><span class=n>TaskType</span><span class=o>.</span><span class=n>SEQ_2_SEQ_LM</span><span class=p>,</span> <span class=n>inference_mode</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>r</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span> <span class=n>lora_alpha</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>lora_dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> <h3 id=peft>PEFT 参数详解<a class=headerlink href=#peft title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>参数</th> <th>说明</th> </tr> </thead> <tbody> <tr> <td><strong><code>Task_type</code></strong></td> <td><strong>下游任务类型</strong>，影响 PEFT 方法调整模型的方式。不同的任务类型可能需要不同的微调策略，因此需要根据实际情况选择合适的 <code>Task_type</code>。例如，<code>SEQ_CLS</code> 用于文本分类，<code>SEQ_2_SEQ_LM</code> 用于序列到序列的语言模型，<code>CAUSAL_LM</code> 用于因果关系模型等。更多任务类型请参考官方文档：<a href=https://huggingface.co/docs/peft/main/en/package_reference/peft_types#peft.TaskType>Task_type Huggingface&nbsp;⧉</a></td> </tr> <tr> <td><strong><code>Inference_mode</code></strong></td> <td><strong>优化模型推理阶段性能的机制</strong>。<code>False</code> 代表<strong>训练模式</strong>，启用梯度更新和训练阶段特有的操作。<code>True</code> 代表<strong>推理模式</strong>，禁用梯度更新，释放内存空间，提高推理速度。</td> </tr> <tr> <td><strong><code>r</code></strong></td> <td><strong>低秩矩阵的维度</strong>，影响 LoRa 添加的参数量和训练速度。<code>r</code> 值越小，参数越少，训练越快，但可能降低模型性能。需要根据实际情况权衡训练速度和模型性能来选择合适的 <code>r</code> 值。</td> </tr> <tr> <td><strong><code>lora_alpha</code></strong></td> <td><strong>低秩矩阵的缩放因子</strong>，影响 LoRa 对模型的影响程度。<code>lora_alpha</code> 值越大，影响越大。</td> </tr> <tr> <td><strong><code>lora_dropout</code></strong></td> <td>应用于 LoRa 层的 dropout 概率，防止模型过拟合。<code>lora_dropout</code> 可以设置为 0 到 1 之间的数值，适当的数值范围可以提高模型的泛化能力，防止模型在训练数据上过拟合。</td> </tr> <tr> <td><strong><code>target_modules</code></strong></td> <td><strong>选择要应用适配器的模块</strong>。可以通过<strong>正则表达式</strong>、<strong>精确匹配</strong>、<strong>模块名称结尾匹配</strong>或<strong>选择所有线性层</strong>来实现对目标模块的选择。未指定时，PEFT 会根据模型架构<strong>自动选择目标模块</strong>。 无法识别模型架构时，需要<strong>手动指定目标模块</strong>。 所有默认的微调模块都可以在 <a href=https://github.com/huggingface/peft/blob/main/src/peft/utils/constants.py>peft.utils.constants&nbsp;⧉</a> 查看。</td> </tr> </tbody> </table> <p>上面的例子是针对于 <code>LoRa</code> 的，但是现实中可能需要更多不同的 <code>PEFT</code> 方法, 不同的 <code>PEFT</code> 方法又需要指定不同的参数，在不了解需要什么参数的时候怎么操作呢？</p> <p>所有的微调方法的配置及其参数介绍都能在 <a href=https://huggingface.co/docs/peft/main/en/package_reference/adalora#peft.AdaLoraConfig>Adapters HuggingFace&nbsp;⧉</a> 左侧导航栏被找到。</p> <p>进入详细介绍界面，整体能看到相应 <code>PEFT</code> 方法的介绍</p> <p><a class=glightbox href=../imgs/lora.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt=lora src=../imgs/lora.png></a></p> <p>其次是相应 <code>PEFT</code> 方法的内置的参数，在 <code>Parameters</code> 栏列出了最为重要的参数，使用者可以根据说明及需求自定义相关参数。</p> <p><a class=glightbox href=../imgs/lora_config.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt=lora_config src=../imgs/lora_config.png></a></p> <h2 id=peftmodel><code>PeftModel</code><a class=headerlink href=#peftmodel title="Permanent link">&para;</a></h2> <p>设置完 <code>PeftConfig</code> 后，然后使用 <code>get_peft_model()</code> 函数创建 <code>PeftModel</code>。 <code>get_peft_model()</code> 需要一个从 <code>transformers</code> 加载的基础模型和已经定义好的 <code>PeftModel</code> 实例。</p> <div class=highlight><table class=highlighttable><tr><th colspan=2 class=filename><span class=filename>base model</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-2-1>1</a></span>
<span class=normal><a href=#__codelineno-2-2>2</a></span>
<span class=normal><a href=#__codelineno-2-3>3</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-2-1 name=__codelineno-2-1></a><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoModelForSeq2SeqLM</span>
<a id=__codelineno-2-2 name=__codelineno-2-2></a>
<a id=__codelineno-2-3 name=__codelineno-2-3></a><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForSeq2SeqLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&quot;bigscience/mt0-large&quot;</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> <p>使用 <code>get_peft_model()</code> 和 <code>peft_config</code> 创建 <code>PeftModel</code> 是使用 <code>PEFT</code> 的标准方法。</p> <div class=highlight><table class=highlighttable><tr><th colspan=2 class=filename><span class=filename>LoraModel</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-3-1>1</a></span>
<span class=normal><a href=#__codelineno-3-2>2</a></span>
<span class=normal><a href=#__codelineno-3-3>3</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-3-1 name=__codelineno-3-1></a><span class=kn>from</span> <span class=nn>peft</span> <span class=kn>import</span> <span class=n>get_peft_model</span>
<a id=__codelineno-3-2 name=__codelineno-3-2></a>
<a id=__codelineno-3-3 name=__codelineno-3-3></a><span class=n>model</span> <span class=o>=</span> <span class=n>get_peft_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>peft_config</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> <p><code>PeftModel</code> 拥有许多内置的属性和方法，这里主要介绍以下三种。</p> <ol> <li><code>peft_model.base_model</code>: 访问基础模型</li> <li><code>peft_model.print_trainable_parameters()</code>: 打印可训练参数的数量和名称</li> <li><code>peft_model.save_pretrained()</code>: 保存 <code>PeftModel</code>，包括基础模型和 <code>PEFT</code> 适配器</li> </ol> <p>现在让我们看看全量微调与使用低参高效微调时，参与梯度更新的参数对比吧。</p> <div class=highlight><table class=highlighttable><tr><th colspan=2 class=filename><span class=filename>model.print_trainable_parameters()</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-4-1>1</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-4-1 name=__codelineno-4-1></a>&quot;output: trainable params: 2359296 || all params: 1231940608 || trainable%: 0.19151053100118282&quot;
</code></pre></div></td></tr></table></div> <p><code>bigscience/mt0-large</code> 模型拥有 <span class=arithmatex>\(12\)</span> 亿参数，而我们只需要微调其中 <span class=arithmatex>\(0.19\%\)</span> 就能实现令人印象深刻的效果！总的来说面对庞大的预训练模型，<code>PEFT</code> 巧妙地冻结大部分参数，只微调少量的额外参数，就能取得与全量微调相当甚至更好的效果。这是一项多么令人心情愉悦的事情！</p> <h2 id=_2>训练<a class=headerlink href=#_2 title="Permanent link">&para;</a></h2> <p>🎉 到现在已经成功地设置好了被 <code>PEFT</code> 方法包裹后的模型了，并且准备好开始训练了！</p> <p>接下来就可以使用 <code>Trainer</code>, <code>Accelerate</code>, 或者自定义的 <code>PyTorch</code> 的训练流程。</p> <p>训练部分不是本节的重点，故直接引用官方的代码。</p> <div class=highlight><table class=highlighttable><tr><th colspan=2 class=filename><span class=filename>training_args</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-5-1> 1</a></span>
<span class=normal><a href=#__codelineno-5-2> 2</a></span>
<span class=normal><a href=#__codelineno-5-3> 3</a></span>
<span class=normal><a href=#__codelineno-5-4> 4</a></span>
<span class=normal><a href=#__codelineno-5-5> 5</a></span>
<span class=normal><a href=#__codelineno-5-6> 6</a></span>
<span class=normal><a href=#__codelineno-5-7> 7</a></span>
<span class=normal><a href=#__codelineno-5-8> 8</a></span>
<span class=normal><a href=#__codelineno-5-9> 9</a></span>
<span class=normal><a href=#__codelineno-5-10>10</a></span>
<span class=normal><a href=#__codelineno-5-11>11</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-5-1 name=__codelineno-5-1></a><span class=n>training_args</span> <span class=o>=</span> <span class=n>TrainingArguments</span><span class=p>(</span>
<a id=__codelineno-5-2 name=__codelineno-5-2></a>    <span class=n>output_dir</span><span class=o>=</span><span class=s2>&quot;your-name/bigscience/mt0-large-lora&quot;</span><span class=p>,</span>
<a id=__codelineno-5-3 name=__codelineno-5-3></a>    <span class=n>learning_rate</span><span class=o>=</span><span class=mf>1e-3</span><span class=p>,</span>
<a id=__codelineno-5-4 name=__codelineno-5-4></a>    <span class=n>per_device_train_batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
<a id=__codelineno-5-5 name=__codelineno-5-5></a>    <span class=n>per_device_eval_batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
<a id=__codelineno-5-6 name=__codelineno-5-6></a>    <span class=n>num_train_epochs</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-5-7 name=__codelineno-5-7></a>    <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span>
<a id=__codelineno-5-8 name=__codelineno-5-8></a>    <span class=n>evaluation_strategy</span><span class=o>=</span><span class=s2>&quot;epoch&quot;</span><span class=p>,</span>
<a id=__codelineno-5-9 name=__codelineno-5-9></a>    <span class=n>save_strategy</span><span class=o>=</span><span class=s2>&quot;epoch&quot;</span><span class=p>,</span>
<a id=__codelineno-5-10 name=__codelineno-5-10></a>    <span class=n>load_best_model_at_end</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
<a id=__codelineno-5-11 name=__codelineno-5-11></a><span class=p>)</span>
</code></pre></div></td></tr></table></div> <p>现在就可以把模型、训练参数、数据集、分词器和其他必要组件统统扔给 <code>Trainer</code> ，然后调用 <code>train()</code> 方法开始训练！</p> <div class=highlight><table class=highlighttable><tr><th colspan=2 class=filename><span class=filename>Trainer</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-6-1> 1</a></span>
<span class=normal><a href=#__codelineno-6-2> 2</a></span>
<span class=normal><a href=#__codelineno-6-3> 3</a></span>
<span class=normal><a href=#__codelineno-6-4> 4</a></span>
<span class=normal><a href=#__codelineno-6-5> 5</a></span>
<span class=normal><a href=#__codelineno-6-6> 6</a></span>
<span class=normal><a href=#__codelineno-6-7> 7</a></span>
<span class=normal><a href=#__codelineno-6-8> 8</a></span>
<span class=normal><a href=#__codelineno-6-9> 9</a></span>
<span class=normal><a href=#__codelineno-6-10>10</a></span>
<span class=normal><a href=#__codelineno-6-11>11</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-6-1 name=__codelineno-6-1></a><span class=n>trainer</span> <span class=o>=</span> <span class=n>Trainer</span><span class=p>(</span>
<a id=__codelineno-6-2 name=__codelineno-6-2></a>    <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
<a id=__codelineno-6-3 name=__codelineno-6-3></a>    <span class=n>args</span><span class=o>=</span><span class=n>training_args</span><span class=p>,</span>
<a id=__codelineno-6-4 name=__codelineno-6-4></a>    <span class=n>train_dataset</span><span class=o>=</span><span class=n>tokenized_datasets</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>],</span>
<a id=__codelineno-6-5 name=__codelineno-6-5></a>    <span class=n>eval_dataset</span><span class=o>=</span><span class=n>tokenized_datasets</span><span class=p>[</span><span class=s2>&quot;test&quot;</span><span class=p>],</span>
<a id=__codelineno-6-6 name=__codelineno-6-6></a>    <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span>
<a id=__codelineno-6-7 name=__codelineno-6-7></a>    <span class=n>data_collator</span><span class=o>=</span><span class=n>data_collator</span><span class=p>,</span>
<a id=__codelineno-6-8 name=__codelineno-6-8></a>    <span class=n>compute_metrics</span><span class=o>=</span><span class=n>compute_metrics</span><span class=p>,</span>
<a id=__codelineno-6-9 name=__codelineno-6-9></a><span class=p>)</span>
<a id=__codelineno-6-10 name=__codelineno-6-10></a>
<a id=__codelineno-6-11 name=__codelineno-6-11></a><span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</code></pre></div></td></tr></table></div> <h2 id=_3>保存模型、推理<a class=headerlink href=#_3 title="Permanent link">&para;</a></h2> <h3 id=_4>保存<a class=headerlink href=#_4 title="Permanent link">&para;</a></h3> <p>当模型完成训练后，我们可以使用 <code>model.save_pretrained()</code> 函数将其保存到指定的目录中。</p> <h3 id=_5>推理<a class=headerlink href=#_5 title="Permanent link">&para;</a></h3> <p>无论是自己还是别人使用 <code>PEFT</code> 训练出来的模型，只要拿到模型文件，就可以使用 <code>AutoPeftModel</code> 类及其 <code>from_pretrained</code> 方法轻松加载 <code>PEFT</code> 训练的模型以进行推理。这种方法提供了一种无缝的方式来加载和使用你的微调模型，而无需手动指定模型架构或 <code>PEFT</code> 配置。</p> <div class=highlight><table class=highlighttable><tr><th colspan=2 class=filename><span class=filename>PeftModel infer</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-7-1> 1</a></span>
<span class=normal><a href=#__codelineno-7-2> 2</a></span>
<span class=normal><a href=#__codelineno-7-3> 3</a></span>
<span class=normal><a href=#__codelineno-7-4> 4</a></span>
<span class=normal><a href=#__codelineno-7-5> 5</a></span>
<span class=normal><a href=#__codelineno-7-6> 6</a></span>
<span class=normal><a href=#__codelineno-7-7> 7</a></span>
<span class=normal><a href=#__codelineno-7-8> 8</a></span>
<span class=normal><a href=#__codelineno-7-9> 9</a></span>
<span class=normal><a href=#__codelineno-7-10>10</a></span>
<span class=normal><a href=#__codelineno-7-11>11</a></span>
<span class=normal><a href=#__codelineno-7-12>12</a></span>
<span class=normal><a href=#__codelineno-7-13>13</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-7-1 name=__codelineno-7-1></a><span class=kn>from</span> <span class=nn>peft</span> <span class=kn>import</span> <span class=n>AutoPeftModelForCausalLM</span>
<a id=__codelineno-7-2 name=__codelineno-7-2></a><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoTokenizer</span>
<a id=__codelineno-7-3 name=__codelineno-7-3></a><span class=kn>import</span> <span class=nn>torch</span>
<a id=__codelineno-7-4 name=__codelineno-7-4></a>
<a id=__codelineno-7-5 name=__codelineno-7-5></a><span class=n>model</span> <span class=o>=</span> <span class=n>AutoPeftModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&quot;ybelkada/opt-350m-lora&quot;</span><span class=p>)</span>
<a id=__codelineno-7-6 name=__codelineno-7-6></a><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&quot;facebook/opt-350m&quot;</span><span class=p>)</span>
<a id=__codelineno-7-7 name=__codelineno-7-7></a>
<a id=__codelineno-7-8 name=__codelineno-7-8></a><span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&quot;cuda&quot;</span><span class=p>)</span>
<a id=__codelineno-7-9 name=__codelineno-7-9></a><span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
<a id=__codelineno-7-10 name=__codelineno-7-10></a><span class=n>inputs</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=s2>&quot;Preheat the oven to 350 degrees and place the cookie dough&quot;</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&quot;pt&quot;</span><span class=p>)</span>
<a id=__codelineno-7-11 name=__codelineno-7-11></a>
<a id=__codelineno-7-12 name=__codelineno-7-12></a><span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=n>input_ids</span><span class=o>=</span><span class=n>inputs</span><span class=p>[</span><span class=s2>&quot;input_ids&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&quot;cuda&quot;</span><span class=p>),</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
<a id=__codelineno-7-13 name=__codelineno-7-13></a><span class=nb>print</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>(),</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)[</span><span class=mi>0</span><span class=p>])</span>
</code></pre></div></td></tr></table></div> <div class=highlight><table class=highlighttable><tr><th colspan=2 class=filename><span class=filename>output</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-8-1>1</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-8-1 name=__codelineno-8-1></a>&quot;Preheat the oven to 350 degrees and place the cookie dough in the center of the oven. In a large bowl, combine the flour, baking powder, baking soda, salt, and cinnamon. In a separate bowl, combine the egg yolks, sugar, and vanilla.&quot;
</code></pre></div></td></tr></table></div> <div class="admonition note"> <p class=admonition-title>加载模型的方式</p> <p>我们既可以在训练完成后立即使用训练好的 <code>PEFT</code> 模型进行推理，也可以将模型保存到磁盘，稍后再加载它进行推理。选择哪种方法取决于你的具体需求。如果只是想快速测试模型，那么第一种方法更方便。如果需要长期保存和管理模型，那么第二种方法更合适。</p> </div> <h2 id=_6>参考资料<a class=headerlink href=#_6 title="Permanent link">&para;</a></h2> <div class="grid cards"> <ul> <li> <p><code>PEFT</code>支持的微调方法</p> <hr> <p><a href=https://huggingface.co/docs/peft/main/en/package_reference/adalora#peft.AdaLoraConfig>Adapters HuggingFace&nbsp;⧉</a></p> </li> <li> <p><code>PEFT</code> 支持的任务类型</p> <hr> <p><a href=https://huggingface.co/docs/peft/main/en/package_reference/peft_types#peft.TaskType>Task_type Huggingface&nbsp;⧉</a></p> </li> <li> <p>Hugging Face 官方的的参数高效微调快速入门和示例。</p> <hr> <p><a href=https://huggingface.co/docs/peft/quicktour>PEFT HuggingFace&nbsp;⧉</a></p> </li> <li> <p><code>PEFT</code>方法默认的目标模块</p> <hr> <p><a href=https://github.com/huggingface/peft/blob/main/src/peft/utils/constants.py>peft.utils.constants&nbsp;⧉</a></p> </li> </ul> </div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 3, 2024</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">June 18, 2024</span> </span> </aside> <h2 id=__comments>Comments</h2> <script src=https://giscus.app/client.js data-repo=moyanxinxu/unlock-hf data-repo-id=R_kgDOMHA4Tg data-category=Q&amp;A data-category-id=DIC_kwDOMHA4Ts4CgCdi data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN crossorigin=anonymous async>
    </script> <script>
    var giscus = document.querySelector("script[src*=giscus]")

    /* Set palette on initial load */
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate" ? "dark" : "light"
        giscus.setAttribute("data-theme", theme) // (1)!
    }

    /* Register event handlers after documented loaded */
    document.addEventListener("DOMContentLoaded", function () {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function () {
            var palette = __md_get("__palette")
            if (palette && typeof palette.color === "object") {
                var theme = palette.color.scheme === "slate" ? "dark" : "light"

                /* Instruct giscus to change theme */
                var frame = document.querySelector(".giscus-frame")
                frame.contentWindow.postMessage(
                    { giscus: { setConfig: { theme } } },
                    "https://giscus.app"
                )
            }
        })
    })
</script> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../peft_index/ class="md-footer__link md-footer__link--prev" aria-label="Previous: 索引"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> 索引 </div> </div> </a> <a href=../../lora_tour/lora_tour/ class="md-footer__link md-footer__link--next" aria-label="Next: LoRA"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> LoRA </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../../..", "features": ["content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.tabs.link", "header.autohide", "navigation.expand", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "navigation.footer", "navigation.path", "navigation.instant", "navigation.instant.progress", "navigation.prune", "search.suggest", "search.share", "toc.integrate"], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../assets/javascripts/bundle.83f73b43.min.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>