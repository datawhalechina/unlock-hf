{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Unlock-HuggingFace","text":"<p>\u8fd1\u5e74\u6765\uff0c\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u9886\u57df\u968f\u7740 Transformer \u67b6\u6784\u7684\u51fa\u73b0\u53d6\u5f97\u4e86\u7a81\u7834\u6027\u8fdb\u5c55\uff0cHuggingFace \u4f5c\u4e3a NLP \u793e\u533a\u7684\u91cd\u8981\u529b\u91cf\uff0c\u63d0\u4f9b\u4e86\u6d77\u91cf\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u4f17\u591a\u5f3a\u5927\u6613\u7528\u7684\u51fd\u6570\u5e93\uff0c\u6781\u5927\u5730\u964d\u4f4e\u4e86 NLP \u5e94\u7528\u5f00\u53d1\u7684\u95e8\u69db\u3002</p> <p>\u672c\u9879\u76ee\u65e8\u5728\u4e3a\u5b66\u4e60\u8005\u63d0\u4f9b\u6df1\u5165\u5b66\u4e60 HuggingFace\ud83d\ude0a \u751f\u6001\u7cfb\u7edf\u7684\u6559\u7a0b\uff0c\u5e76\u901a\u8fc7\u5b8c\u6210\u751f\u52a8\u6709\u8da3\u7684\u5177\u4f53\u9879\u76ee\u63d0\u5347\u5b66\u4e60\u8005\u5b9e\u8df5\u6c34\u5e73\u3002</p>"},{"location":"#_1","title":"\u5185\u5bb9\u5bfc\u822a","text":"<p>\u5185\u5bb9\u5927\u7eb2\u5927\u81f4\u4e3a:</p> <p></p> \u7ae0\u8282 \u5185\u5bb9 \u5907\u6ce8 \u524d\u8a00 NLP\u4e0eHuggingFace\u6574\u4f53\u4ecb\u7ecd \u5305\u62ec\u73af\u5883\u914d\u7f6e \u7b2c\u4e00\u7ae0 Datasets\u5de5\u5177 \u7b2c\u4e8c\u7ae0 Transformers\u5de5\u5177 Pipeline\u5de5\u5177,Tokenizer\u5de5\u5177,Model\u5de5\u5177 \u7b2c\u4e09\u7ae0 PEFT\u5de5\u5177 \u7b2c\u56db\u7ae0 Evaluate\u5de5\u5177 \u7b2c\u4e94\u7ae0 Diffusers\u5de5\u5177 \u7b2c\u516d\u7ae0 \u9879\u76ee\u6848\u4f8b \u7b2c\u4e03\u7ae0 Gradio\u5de5\u5177 <p>\u5927\u7eb2\u5177\u4f53\u5185\u5bb9:</p> <p></p>"},{"location":"#_2","title":"\u53c2\u4e0e\u8d21\u732e","text":"<ul> <li>\u5982\u679c\u4f60\u60f3\u53c2\u4e0e\u5230\u9879\u76ee\u4e2d\u6765\u6b22\u8fce\u67e5\u770b\u9879\u76ee\u7684 Issue \u67e5\u770b\u6ca1\u6709\u88ab\u5206\u914d\u7684\u4efb\u52a1\u2728\u3002</li> <li>\u5982\u679c\u4f60\u53d1\u73b0\u4e86\u4e00\u4e9b\u95ee\u9898\uff0c\u6b22\u8fce\u5728 Issue \u4e2d\u8fdb\u884c\u53cd\u9988\ud83d\udc1b\u3002</li> </ul> <p>\u5982\u679c\u4f60\u5bf9 Datawhale \u5f88\u611f\u5174\u8da3\u5e76\u60f3\u8981\u53d1\u8d77\u4e00\u4e2a\u65b0\u7684\u9879\u76ee\uff0c\u6b22\u8fce\u67e5\u770b Datawhale \u8d21\u732e\u6307\u5357\u3002</p>"},{"location":"#_3","title":"\u8d21\u732e\u8005\u540d\u5355","text":"\u59d3\u540d \u804c\u8d23 \u7b80\u4ecb \u7530\u5065\u7fd4 \u9879\u76ee\u8d1f\u8d23\u4eba \u5185\u5bb9\u521b\u4f5c\u8005 \u4e8e\u5c0f\u654f \u9879\u76ee\u6307\u5bfc\u4eba DataWhale\u6b63\u5f0f\u6210\u5458 \u5362\u946b\u658c \u7b2c1\u7ae0(Datasets)\u8d21\u732e\u8005 \u5185\u5bb9\u521b\u4f5c\u8005 \u80e5\u4f73\u7a0b \u7b2c3\u7ae0(PEFT)\u8d21\u732e\u8005 \u5185\u5bb9\u521b\u4f5c\u8005 \u79e6\u5b50\u6db5 \u7b2c5\u7ae0(Diffusers)\u8d21\u732e\u8005 \u5185\u5bb9\u521b\u4f5c\u8005 \u9648\u51ef\u6b4c \u7b2c7\u7ae0(Gradio)\u8d21\u732e\u8005 \u5185\u5bb9\u521b\u4f5c\u8005 \u5218\u7855 \u7b2c7\u7ae0(Gradio)\u8d21\u732e\u8005 \u5185\u5bb9\u521b\u4f5c\u8005 <p>\u8d1f\u8d23\u4eba\u8054\u7cfb\u90ae\u7bb1\ud83d\udceb: wwxy.mail@gmail.com</p>"},{"location":"#_4","title":"\u5173\u6ce8\u6211\u4eec","text":"<p>\u626b\u63cf\u4e0b\u65b9\u4e8c\u7ef4\u7801\u5173\u6ce8\u516c\u4f17\u53f7\uff1aDatawhale</p>"},{"location":"#license","title":"LICENSE","text":"<p>\u672c\u4f5c\u54c1\u91c7\u7528\u77e5\u8bc6\u5171\u4eab\u7f72\u540d-\u975e\u5546\u4e1a\u6027\u4f7f\u7528-\u76f8\u540c\u65b9\u5f0f\u5171\u4eab 4.0 \u56fd\u9645\u8bb8\u53ef\u534f\u8bae\u8fdb\u884c\u8bb8\u53ef\u3002</p> <p>\u6ce8\uff1a\u9ed8\u8ba4\u4f7f\u7528CC 4.0\u534f\u8bae\uff0c\u4e5f\u53ef\u6839\u636e\u81ea\u8eab\u9879\u76ee\u60c5\u51b5\u9009\u7528\u5176\u4ed6\u534f\u8bae</p>"},{"location":"_sidebar/","title":"sidebar","text":"<ul> <li>\u7b2c1\u7ae0 \u6211\u662f\u7b2c1\u7ae0\u7684\u6807\u9898</li> <li>\u7b2c2\u7ae0 \u6211\u662f\u7b2c2\u7ae0\u7684\u6807\u9898<ul> <li>2.1 \u6211\u662f2.1\u7684\u6807\u9898</li> <li>2.2 \u6211\u662f2.2\u7684\u6807\u9898</li> </ul> </li> <li>\u7b2c3\u7ae0 \u6211\u662f\u7b2c3\u7ae0\u7684\u6807\u9898<ul> <li>3.1 \u6211\u662f3.1\u7684\u6807\u9898<ul> <li>3.1.1 \u6211\u662f3.1.1\u7684\u6807\u9898</li> <li>3.1.2 \u6211\u662f3.1.2\u7684\u6807\u9898</li> </ul> </li> </ul> </li> </ul>"},{"location":"chapter1/chapter1/","title":"\u6211\u662f\u7b2c1\u7ae0\u7684\u6807\u9898","text":"<p>\u6211\u662f\u7b2c1\u7ae0\u7684\u6b63\u6587\uff0c\u4e0b\u9762\u7ed9\u51fa\u63d2\u5165\u56fe\u7247\u7684\u4e24\u79cd\u65b9\u5f0f\uff0c\u5206\u522b\u4e3amarkdown\u8bed\u6cd5\u548chtml\u8bed\u6cd5\u3002</p> <p>markdown\u8bed\u6cd5\u4ee3\u7801\u5982\u4e0b\uff1a Markdown<pre><code>![\u56fe1.1 \u6211\u662f\u56fe\u7247\u540d\u79f0](./images/1_1.jpeg)\n</code></pre> \u6548\u679c\u5982\u4e0b\uff1a </p> <p>markdown\u8bed\u6cd5\u7b80\u6d01\u660e\u4e86\uff0c\u4f46\u662f\u5176\u65e0\u6cd5\u63a7\u5236\u56fe\u7247\u7684\u5927\u5c0f\uff0c\u56e0\u6b64\u6709\u56fe\u7247\u7f29\u653e\u9700\u6c42\u65f6\u53ef\u4f7f\u7528html\u8bed\u6cd5\uff0chtml\u8bed\u6cd5\u4ee3\u7801\u5982\u4e0b\uff1a HTML<pre><code>&lt;div align=center&gt;\n&lt; img width=\"300\" src=\"./images/1_1.jpeg\"/&gt;\n&lt;/div&gt;\n&lt;div align=center&gt;\u56fe1.1 \u6211\u662f\u56fe\u7247\u540d\u79f0&lt;/div&gt;\n</code></pre> \u6548\u679c\u5982\u4e0b\uff1a</p> \u56fe1.1 \u6211\u662f\u56fe\u7247\u540d\u79f0"},{"location":"chapter2/chapter2_1/","title":"\u6211\u662f2.1\u7684\u6807\u9898","text":"<p>\u6211\u662f2.1\u7684\u6b63\u6587</p>"},{"location":"chapter2/chapter2_2/","title":"\u6211\u662f2.2\u7684\u6807\u9898","text":"<p>\u6211\u662f2.2\u7684\u6b63\u6587</p>"},{"location":"chapter2/chapter2_3/","title":"\u6211\u662f2.3\u7684\u6807\u9898","text":"<p>\u6211\u662f2.3\u7684\u6b63\u6587</p>"},{"location":"chapter3/chapter3_1/chapter3_1_1/","title":"\u6211\u662f3.1.1\u7684\u6807\u9898","text":"<p>\u6211\u662f3.1.1\u7684\u6b63\u6587</p>"},{"location":"chapter3/chapter3_1/chapter3_1_2/","title":"\u6211\u662f3.1.2\u7684\u6807\u9898","text":"<p>\u6211\u662f3.1.2\u7684\u6b63\u6587</p>"},{"location":"chapter6/multi-label-classification-of-toxic-comments/multi-label-classification-of-toxic-comments/","title":"\u9762\u5bf9\u6709\u5bb3\u8a00\u8bba, \u662f\u65f6\u5019\u8ba9AI\u91cd\u62f3\u51fa\u51fb\u4e86(\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1)","text":"<p>\u4efb\u52a1\u6765\u6e90\uff1a</p> <p>Toxic Comment Classification Challenge</p>"},{"location":"chapter6/multi-label-classification-of-toxic-comments/multi-label-classification-of-toxic-comments/#_1","title":"\u603b\u89c8","text":"<p>\u5728\u7f51\u7edc\u4e16\u754c\u4e2d\uff0c\u6709\u6548\u8fc7\u6ee4\u548c\u7ba1\u7406\u6076\u610f\u8bc4\u8bba\u662f\u4e00\u9879\u6311\u6218\u3002Toxic Comment Classification Challenge \u9879\u76ee\u81f4\u529b\u4e8e\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u89e3\u51b3\u8fd9\u4e00\u96be\u9898\u3002\u8be5\u9879\u76ee\u6e90\u4e8e Kaggle \u7ade\u8d5b\uff0c\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u7cbe\u51c6\u8bc6\u522b\u5728\u7ebf\u5bf9\u8bdd\u4e2d\u6709\u6bd2\u8bc4\u8bba\u7684\u7b97\u6cd5\u3002\u9879\u76ee\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u548c\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\uff0c\u5bf9\u8bc4\u8bba\u8fdb\u884c\u591a\u7c7b\u522b\u5206\u7c7b\uff0c\u4f8b\u5982\u8bc6\u522b\u5a01\u80c1\u3001\u6deb\u79fd\u8272\u60c5\u3001\u4fae\u8fb1\u548c\u57fa\u4e8e\u8eab\u4efd\u7684\u4ec7\u6068\u8a00\u8bba\u7b49\uff0c\u4ece\u800c\u5e2e\u52a9\u51cf\u5c11\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u4e0d\u826f\u5f71\u54cd\u3002</p>"},{"location":"chapter6/multi-label-classification-of-toxic-comments/multi-label-classification-of-toxic-comments/#_2","title":"\u6570\u636e","text":"\u8bad\u7ec3\u96c6 \u6d4b\u8bd5\u96c6"},{"location":"chapter6/multi-label-classification-of-toxic-comments/multi-label-classification-of-toxic-comments/#_3","title":"\u4ee3\u7801","text":"Python<pre><code>import os\n\nos.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n# os.environ[\"HTTP_PROXY\"] = \"http://127.0.0.1:7890\"\n# os.environ[\"HTTPS_PROXY\"] = \"http://127.0.0.1:7890\"\n</code></pre>"},{"location":"chapter6/multi-label-classification-of-toxic-comments/multi-label-classification-of-toxic-comments/#_4","title":"\u6570\u636e\u96c6\u52a0\u8f7d","text":"Python<pre><code>from datasets import load_dataset\n\ndata_files = {\"train\": \"./data/train.csv\"}\n\ndataset = load_dataset(\"csv\", data_files=data_files, num_proc=8)\ntrain_and_test = dataset[\"train\"].train_test_split(test_size=0.2)\n</code></pre> <p>\u4f7f\u7528 <code>train_test_split</code>\u65b9\u6cd5\u5212\u5206\u51fa\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002</p> train_and_test<pre><code>DatasetDict({\n    train: Dataset({\n        features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n        num_rows: 127656\n    })\n    test: Dataset({\n        features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n        num_rows: 31915\n    })\n})\n</code></pre> Python<pre><code>label2id = {\n    \"toxic\": 0,\n    \"severe_toxic\": 1,\n    \"obscene\": 2,\n    \"threat\": 3,\n    \"insult\": 4,\n    \"identity_hate\": 5,\n}\n\nid2label = {\n    0: \"toxic\",\n    1: \"severe_toxic\",\n    2: \"obscene\",\n    3: \"threat\",\n    4: \"insult\",\n    5: \"identity_hate\",\n}\n</code></pre>"},{"location":"chapter6/multi-label-classification-of-toxic-comments/multi-label-classification-of-toxic-comments/#_5","title":"\u6570\u636e\u9884\u5904\u7406","text":"Python<pre><code>from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n</code></pre> Python<pre><code>def tokenized_fn(example):\n    tokenized_example = tokenizer(\n        example[\"comment_text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=64,\n    )\n    return tokenized_example\n</code></pre> Python<pre><code>def gen_labels(label1, label2, label3, label4, label5, label6):\n    labels = []\n\n    for i in range(len(label1)):\n        labels.append(\n            [\n                float(label1[i]),\n                float(label2[i]),\n                float(label3[i]),\n                float(label4[i]),\n                float(label5[i]),\n                float(label6[i]),\n            ]\n        )\n\n    return {\"labels\": labels}\n</code></pre> Python<pre><code>def datapipe(dataset):\n    dataset = dataset.map(tokenized_fn, batched=True)\n    dataset = dataset.map(\n        gen_labels,\n        input_columns=[\n            \"toxic\",\n            \"severe_toxic\",\n            \"obscene\",\n            \"threat\",\n            \"insult\",\n            \"identity_hate\",\n        ],\n        batched=True,\n    )\n    return dataset\n</code></pre> Python<pre><code>train_and_test = datapipe(train_and_test)\ntrain_and_test = train_and_test.select_columns(\n    [\n        \"input_ids\",\n        \"attention_mask\",\n        \"labels\",\n    ]\n)\n</code></pre> train_and_test<pre><code>DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 127656\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 31915\n    })\n})\n</code></pre> train_and_test[\"train\"][0]<pre><code>{\n  \"input_ids\": [101, 1045, 2134, 1005, 1056, 5382, 1998, 1045, 2572, 2047, 2182, 2074, 2893, 1996, 6865, 1997, 2009, 1012, 4283, 2005, 1996, 4641, 2039, 2295, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  \"attention_mask\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  \"labels\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n}\n</code></pre> <p>\u591a\u6807\u7b7e\u5206\u7c7b\u548c\u5355\u6807\u7b7e\u5206\u7c7b\u5728\u6570\u636e\u96c6\u683c\u5f0f\u4e0a\u5927\u540c\u5c0f\u5f02</p> <ul> <li>\u5728\u5355\u6807\u7b7e\u5206\u7c7b\u4e2d\uff0c\u5355\u4e2a\u6837\u672c\u7684 <code>labels</code>\u4e3a\u4e00\u4e2a\u6574\u6570</li> <li>\u5728\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\uff0c\u5355\u4e2a\u6837\u672c\u7684 <code>labels</code>\u4e3a\u7c7b\u522b\u4e2a\u6570\u957f\u5ea6\u4e2a0\u62161\u7ec4\u6210\u5217\u8868\u3002\u5176\u4e2d1\u4ee3\u8868\u8be5\u6837\u672c\u5c5e\u4e8e\u8be5\u7c7b\uff0c\u5426\u5219\u4e0d\u5c5e\u4e8e\u8be5\u7c7b\u3002</li> </ul>"},{"location":"chapter6/multi-label-classification-of-toxic-comments/multi-label-classification-of-toxic-comments/#_6","title":"\u9884\u8bad\u7ec3\u6a21\u578b","text":"Python<pre><code>from transformers import AutoModelForSequenceClassification\n</code></pre> Python<pre><code>model = AutoModelForSequenceClassification.from_pretrained(\n    \"google-bert/bert-base-uncased\",\n    num_labels=len(id2label),\n    id2label=id2label,\n    label2id=label2id,\n    problem_type=\"multi_label_classification\",\n)\n</code></pre> <p>\u5982\u679c\u4efb\u52a1\u7c7b\u578b\u4e3a\u591a\u4efb\u52a1\u6807\u7b7e\uff0c\u90a3\u4e48\u9700\u8981\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u65f6\u6307\u5b9a <code>problem_type</code>\u4e3a <code>multi_label_classification</code>\u3002</p> Note <p>Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized:['classifier.bias', 'classifier.weight'] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</p> Python<pre><code>model.requires_grad = False\nmodel.classifier.requires_grad = True\n</code></pre> <ol> <li>\u5c06\u7f51\u7edc\u53c2\u6570\u90fd\u51bb\u7ed3\uff0c</li> <li>\u5c06 <code>classifier.requires_grad</code>\u8bbe\u7f6e\u4e3a <code>True</code>\u53ea\u5141\u8bb8\u5206\u7c7b\u5934\u53c2\u4e0e\u68af\u5ea6\u66f4\u65b0\u3002</li> </ol>"},{"location":"chapter6/multi-label-classification-of-toxic-comments/multi-label-classification-of-toxic-comments/#_7","title":"\u8bc4\u4ef7\u6307\u6807","text":"Python<pre><code>import numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score\n</code></pre> Python<pre><code>def sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n</code></pre> Python<pre><code>def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = sigmoid(logits)\n    preds = (preds &gt; 0.5).astype(int).reshape(-1)\n    labels = labels.reshape(-1)\n    accuracy = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average=\"macro\")\n    return {\n        \"accuracy\": accuracy,\n        \"f1\": f1,\n    }\n</code></pre>"},{"location":"chapter6/multi-label-classification-of-toxic-comments/multi-label-classification-of-toxic-comments/#_8","title":"\u8bad\u7ec3","text":"Python<pre><code>from transformers import TrainingArguments, Trainer\n</code></pre> Python<pre><code>training_args = TrainingArguments(\n    output_dir=\"./output/\",\n    eval_strategy=\"epoch\",\n    per_device_train_batch_size=128,\n    per_device_eval_batch_size=128,\n    weight_decay=0.01,\n    num_train_epochs=5,\n    learning_rate=2e-5,\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)\n</code></pre> Python<pre><code>trainer = Trainer(\n    args=training_args,\n    model=model,\n    train_dataset=train_and_test[\"train\"],\n    eval_dataset=train_and_test[\"test\"],\n    compute_metrics=compute_metrics,\n)\n</code></pre> Python<pre><code>trainer.train()\n</code></pre>"},{"location":"chapter6/multi-label-classification-of-toxic-comments/multi-label-classification-of-toxic-comments/#_9","title":"\u6a21\u578b\u8bad\u7ec3\u7ed3\u679c","text":"Epoch Training Loss Validation Loss Accuracy F1 1 0.046600 0.042239 0.984312 0.882476 2 0.036300 0.041644 0.984067 0.881441 3 0.029900 0.043375 0.983816 0.883072 4 0.024800 0.048329 0.983503 0.882226 5 0.021100 0.049663 0.983153 0.881117"},{"location":"chapter6/multi-label-classification-of-toxic-comments/multi-label-classification-of-toxic-comments/#_10","title":"\u63a8\u7406","text":"Python<pre><code>data = load_dataset('csv', data_files={'val':'./data/test.csv'}, num_proc=8)\ndata = data.map(tokenized_fn, batched=True)\n</code></pre> Python<pre><code>answer = (sigmoid(trainer.predict(data['val']).predictions) &gt; 0.5).astype(int)\n</code></pre> Python<pre><code>import pandas as pd\n\npd.DataFrame(answer).to_csv('./answer.csv', index=False)\n</code></pre> <p>\u7ecf\u8fc7\u540e\u7eed\u7684\u6570\u636e\u96c6\u683c\u5f0f\u6574\u7406\uff0c\u63d0\u4ea4\u8bc4\u6d4b\u540e\uff1a</p> <p></p>"}]}