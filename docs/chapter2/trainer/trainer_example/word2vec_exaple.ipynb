{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, vocab_file, stop_words_file=None):\n",
    "        self.stop_words_file = self.load_stop_words(stop_words_file)\n",
    "        self.idx2word, self.word2idx, self.vocab = self.load_vocab(vocab_file)\n",
    "        self.vocab_size = len(self.idx2word)\n",
    "\n",
    "    def load_vocab(self, vocab_file):\n",
    "        idx2word = {}\n",
    "        word2idx = {}\n",
    "        vocab = []\n",
    "        contents = pd.read_csv(vocab_file, encoding=\"GBK\", header=None)\n",
    "\n",
    "        for idx, row in contents.iterrows():\n",
    "            line = row[0]\n",
    "            if not self.stop_words_file:\n",
    "                current_line_words = [\n",
    "                    word for word in jieba.cut(line) if word not in self.stop_words_file\n",
    "                ]\n",
    "\n",
    "            else:\n",
    "                current_line_words = list(jieba.cut(line))\n",
    "            vocab += current_line_words\n",
    "\n",
    "        for idx, word in enumerate(vocab):\n",
    "            idx2word[idx] = word\n",
    "            word2idx[word] = idx\n",
    "        return idx2word, word2idx, vocab\n",
    "\n",
    "    def load_stop_words(self, stop_words_file):\n",
    "        if stop_words_file is None:\n",
    "            return set()\n",
    "        else:\n",
    "            with open(stop_words_file, \"r\") as f:\n",
    "                return set(f.read().splitlines())\n",
    "\n",
    "    def get_idx(self, word):\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def get_word(self, idx):\n",
    "        return self.idx2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(\"./assets/数学原始数据.csv\", \"./assets/stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.model = nn.ModuleDict(\n",
    "            {\n",
    "                \"onehot2embedding\": nn.Linear(\n",
    "                    vocab_size,\n",
    "                    embedding_size,\n",
    "                    bias=True,\n",
    "                ),\n",
    "                \"embedding2logits\": nn.Linear(\n",
    "                    embedding_size,\n",
    "                    vocab_size,\n",
    "                    bias=True,\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(vocab.vocab_size, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, vocab: Vocab, ngram: int):\n",
    "        self.vocab_object = vocab\n",
    "        self.vocab = vocab.vocab\n",
    "        self.vocab_size = vocab.vocab_size\n",
    "        self.ngram = ngram\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_word = self.vocab_object.get_word(idx)\n",
    "        left_idx = max(0, idx - self.ngram)\n",
    "        right_idx = min(self.vocab_size, idx + self.ngram)\n",
    "\n",
    "        annother_words = (\n",
    "            self.vocab[left_idx + 1 : idx] + self.vocab[idx + 1 : right_idx]\n",
    "        )\n",
    "\n",
    "        return {\"current_word\": current_word, \"annother_word\": annother_words}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlock-hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
