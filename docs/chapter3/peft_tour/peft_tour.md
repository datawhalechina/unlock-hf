---
comments: true
title: PEFTï¼ˆParameter-Efficient Fine-Tuningï¼‰
---

![peft](imgs/peft.png)

## å‰è¨€

ğŸ¤— `PEFT`ï¼ˆå‚æ•°é«˜æ•ˆå¾®è°ƒï¼‰æ˜¯ä¸€ä¸ªç”¨äºé«˜æ•ˆåœ°å°†å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹é€‚é…åˆ°å„ç§ä¸‹æ¸¸åº”ç”¨çš„åº“ã€‚

ç”±äºå¾®è°ƒæ¨¡å‹çš„æ‰€æœ‰å‚æ•°æˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥å®ç°ï¼Œè€Œ `PEFT` æ–¹æ³•åªéœ€è¦å¾®è°ƒå°‘é‡é¢å¤–æ¨¡å‹å‚æ•°ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†è®¡ç®—å’Œå­˜å‚¨æˆæœ¬ï¼ŒåŒæ—¶å®ç°äº†ä¸æ¨¡å‹å…¨é‡å¾®è°ƒ**è¿‘ä¹ç›¸å½“**çš„æ€§èƒ½ã€‚è¿™ä½¿å¾—åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šè®­ç»ƒå’Œä¿å­˜å¤§è¯­è¨€æ¨¡å‹ (LLM) å˜å¾—æ›´åŠ å®¹æ˜“ã€‚

å®‰è£… `peft`

```bash title='å®‰è£…peft'
pip install peft
```

PEFT æ¶µç›–ä¼—å¤šä¸»æµä½å‚é«˜æ ¡å¾®è°ƒæŠ€æœ¯ï¼Œå¹¶å¯ä»¥å’Œ `Transformers`ã€`Accelerate` ä¸€èµ·ä½¿ç”¨ï¼Œæ¯”å¦‚

1. `LoRa`
2. `Prefix Tuning`
3. `AdaLoRA`
4. `Prompt Tuning`
5. `MultiTask Prompt Tuning`
6. `LoHa`
7. $\cdots$

`PEFT` åº“æ”¯æŒçš„æ–¹æ³•å‡å¯åœ¨ [Adapters HuggingFace](https://huggingface.co/docs/peft/main/en/package_reference/adalora#peft.AdaLoraConfig) å·¦ä¾§å¯¼èˆªæ æŸ¥æ‰¾

æ¥ä¸‹æ¥çš„å†…å®¹å°†ä»‹ç» `PEFT` çš„ä¸»è¦ç»„æˆï¼Œä»¥åŠå¦‚ä½•è®­ç»ƒæˆ–è¿è¡Œé‚£äº›é€šå¸¸åœ¨æ¶ˆè´¹çº§è®¾å¤‡ä¸Šéš¾ä»¥è®­ç»ƒçš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚

## `PeftConfig`

æ¯ç§ `PEFT` æ–¹æ³•éƒ½å¯¹åº”ä¸€ä¸ªç‹¬ç‰¹çš„ `PeftConfig` ç±»ï¼Œç”¨äºå­˜å‚¨æ„å»º**ç›¸åº”** `PeftModel` çš„æ‰€æœ‰å¿…è¦å‚æ•°ã€‚

å½“ä½ æƒ³è¦è°ƒç”¨æŸä¸ª `PEFT` æ–¹æ³•æ—¶ï¼Œéœ€è¦å…ˆåŠ è½½å¹¶åˆ›å»ºä¸€ä¸ªè¯¥æ–¹æ³•å¯¹åº”çš„ `PeftConfig` ç±»å®ä¾‹ï¼Œå¹¶åœ¨å®ä¾‹åŒ–è¿‡ç¨‹ä¸­æŒ‡å®šè¯¥æ–¹æ³•éœ€è¦çš„å‚æ•°ã€‚è¿™äº›å‚æ•°ä¼šå›  `PEFT` æ–¹æ³•çš„ä¸åŒè€Œæœ‰æ‰€å·®å¼‚ï¼Œä¾‹å¦‚ï¼š

- `LoRa` (`LoraConfig`)ï¼šéœ€è¦æŒ‡å®šÂ `lora_rank`ï¼ˆä½ç§©çŸ©é˜µçš„ç§©ï¼‰ã€`lora_alpha`ï¼ˆç¼©æ”¾å› å­ï¼‰å’ŒÂ `lora_dropout`ï¼ˆdropout æ¦‚ç‡ï¼‰ç­‰å‚æ•°ã€‚
- `Prompt Tuning` (`PromptTuningConfig`)ï¼šéœ€è¦æŒ‡å®šÂ `prompt_tuning_num_tokens`ï¼ˆprompt ä¸­çš„ token æ•°é‡ï¼‰ã€`prompt_tuning_init_text`ï¼ˆprompt çš„åˆå§‹åŒ–æ–‡æœ¬ï¼‰å’ŒÂ `prompt_tuning_placeholder_id`ï¼ˆå ä½ç¬¦ IDï¼‰ç­‰å‚æ•°ã€‚

å‡å¦‚ä»¥ `LoRa` ä¸ºä¾‹å­ï¼Œæ€ä¹ˆè®© `LoRa` ä½œç”¨äºæ¨¡å‹å‘¢ï¼Ÿ

1. å¼•å…¥Â `LoraConfig`Â ç±»ã€‚
2. å®šä¹‰ `LoRa` çš„å‚æ•°ï¼ŒåŒ…æ‹¬Â `task_type`ï¼Œ`inference_mode`ï¼Œ`r`ï¼Œ`lora_alpha`Â å’ŒÂ `lora_dropout` ç­‰ã€‚

```python title='LoraConfig'
from peft import LoraConfig, TaskType

peft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1)
```

### PEFT å‚æ•°è¯¦è§£

| å‚æ•°                   | è¯´æ˜                                                                                                                                                                                                                                                                           |
| -------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`Task_type`**      | **ä¸‹æ¸¸ä»»åŠ¡ç±»å‹**ï¼Œå½±å“ PEFT æ–¹æ³•è°ƒæ•´æ¨¡å‹çš„æ–¹å¼ã€‚ä¸åŒçš„ä»»åŠ¡ç±»å‹å¯èƒ½éœ€è¦ä¸åŒçš„å¾®è°ƒç­–ç•¥ï¼Œå› æ­¤éœ€è¦æ ¹æ®å®é™…æƒ…å†µé€‰æ‹©åˆé€‚çš„Â `Task_type`ã€‚ä¾‹å¦‚ï¼Œ`SEQ_CLS`Â ç”¨äºæ–‡æœ¬åˆ†ç±»ï¼Œ`SEQ_2_SEQ_LM`Â ç”¨äºåºåˆ—åˆ°åºåˆ—çš„è¯­è¨€æ¨¡å‹ï¼Œ`CAUSAL_LM`Â ç”¨äºå› æœå…³ç³»æ¨¡å‹ç­‰ã€‚æ›´å¤šä»»åŠ¡ç±»å‹è¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼š[Task_type Huggingface](https://huggingface.co/docs/peft/main/en/package_reference/peft_types#peft.TaskType) |
| **`Inference_mode`** | **ä¼˜åŒ–æ¨¡å‹æ¨ç†é˜¶æ®µæ€§èƒ½çš„æœºåˆ¶**ã€‚`False`Â ä»£è¡¨**è®­ç»ƒæ¨¡å¼**ï¼Œå¯ç”¨æ¢¯åº¦æ›´æ–°å’Œè®­ç»ƒé˜¶æ®µç‰¹æœ‰çš„æ“ä½œã€‚`True`Â ä»£è¡¨**æ¨ç†æ¨¡å¼**ï¼Œç¦ç”¨æ¢¯åº¦æ›´æ–°ï¼Œé‡Šæ”¾å†…å­˜ç©ºé—´ï¼Œæé«˜æ¨ç†é€Ÿåº¦ã€‚                                                                                                                                                                                |
| **`r`**              | **ä½ç§©çŸ©é˜µçš„ç»´åº¦**ï¼Œå½±å“ LoRa æ·»åŠ çš„å‚æ•°é‡å’Œè®­ç»ƒé€Ÿåº¦ã€‚`r`Â å€¼è¶Šå°ï¼Œå‚æ•°è¶Šå°‘ï¼Œè®­ç»ƒè¶Šå¿«ï¼Œä½†å¯èƒ½é™ä½æ¨¡å‹æ€§èƒ½ã€‚éœ€è¦æ ¹æ®å®é™…æƒ…å†µæƒè¡¡è®­ç»ƒé€Ÿåº¦å’Œæ¨¡å‹æ€§èƒ½æ¥é€‰æ‹©åˆé€‚çš„Â `r`Â å€¼ã€‚                                                                                                                                                                                 |
| **`lora_alpha`**     | **ä½ç§©çŸ©é˜µçš„ç¼©æ”¾å› å­**ï¼Œå½±å“ LoRa å¯¹æ¨¡å‹çš„å½±å“ç¨‹åº¦ã€‚`lora_alpha`Â å€¼è¶Šå¤§ï¼Œå½±å“è¶Šå¤§ã€‚                                                                                                                                                                                                                        |
| **`lora_dropout`**   | åº”ç”¨äº LoRa å±‚çš„ dropout æ¦‚ç‡ï¼Œé˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆã€‚`lora_dropout`Â å¯ä»¥è®¾ç½®ä¸º 0 åˆ° 1 ä¹‹é—´çš„æ•°å€¼ï¼Œé€‚å½“çš„æ•°å€¼èŒƒå›´å¯ä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œé˜²æ­¢æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿‡æ‹Ÿåˆã€‚                                                                                                                                                                            |
| **`target_modules`** | **é€‰æ‹©è¦åº”ç”¨é€‚é…å™¨çš„æ¨¡å—**ã€‚å¯ä»¥é€šè¿‡**æ­£åˆ™è¡¨è¾¾å¼**ã€**ç²¾ç¡®åŒ¹é…**ã€**æ¨¡å—åç§°ç»“å°¾åŒ¹é…**æˆ–**é€‰æ‹©æ‰€æœ‰çº¿æ€§å±‚**æ¥å®ç°å¯¹ç›®æ ‡æ¨¡å—çš„é€‰æ‹©ã€‚æœªæŒ‡å®šæ—¶ï¼ŒPEFT ä¼šæ ¹æ®æ¨¡å‹æ¶æ„**è‡ªåŠ¨é€‰æ‹©ç›®æ ‡æ¨¡å—**ã€‚ æ— æ³•è¯†åˆ«æ¨¡å‹æ¶æ„æ—¶ï¼Œéœ€è¦**æ‰‹åŠ¨æŒ‡å®šç›®æ ‡æ¨¡å—**ã€‚ æ‰€æœ‰é»˜è®¤çš„å¾®è°ƒæ¨¡å—éƒ½å¯ä»¥åœ¨Â [peft.utils.constants](https://github.com/huggingface/peft/blob/main/src/peft/utils/constants.py)Â æŸ¥çœ‹ã€‚                      |

ä¸Šé¢çš„ä¾‹å­æ˜¯é’ˆå¯¹äº `LoRa` çš„ï¼Œä½†æ˜¯ç°å®ä¸­å¯èƒ½éœ€è¦æ›´å¤šä¸åŒçš„ `PEFT` æ–¹æ³•, ä¸åŒçš„ `PEFT` æ–¹æ³•åˆéœ€è¦æŒ‡å®šä¸åŒçš„å‚æ•°ï¼Œåœ¨ä¸äº†è§£éœ€è¦ä»€ä¹ˆå‚æ•°çš„æ—¶å€™æ€ä¹ˆæ“ä½œå‘¢ï¼Ÿ

æ‰€æœ‰çš„å¾®è°ƒæ–¹æ³•çš„é…ç½®åŠå…¶å‚æ•°ä»‹ç»éƒ½èƒ½åœ¨ [Adapters HuggingFace](https://huggingface.co/docs/peft/main/en/package_reference/adalora#peft.AdaLoraConfig) å·¦ä¾§å¯¼èˆªæ è¢«æ‰¾åˆ°ã€‚

è¿›å…¥è¯¦ç»†ä»‹ç»ç•Œé¢ï¼Œæ•´ä½“èƒ½çœ‹åˆ°ç›¸åº” `PEFT` æ–¹æ³•çš„ä»‹ç»
![lora_config](./imgs/lora_config.png)

å…¶æ¬¡æ˜¯ç›¸åº” `PEFT` æ–¹æ³•çš„å†…ç½®çš„å‚æ•°ï¼Œåœ¨ `Parameters` æ åˆ—å‡ºäº†æœ€ä¸ºé‡è¦çš„å‚æ•°ï¼Œä½¿ç”¨è€…å¯ä»¥æ ¹æ®è¯´æ˜åŠéœ€æ±‚è‡ªå®šä¹‰ç›¸å…³å‚æ•°ã€‚

![lora_parameters](./imgs/lora_parameters.png)

---

## `PeftModel`

è®¾ç½®å®Œ `PeftConfig` åï¼Œç„¶åä½¿ç”¨ `get_peft_model()` å‡½æ•°åˆ›å»º `PeftModel`ã€‚ `get_peft_model()` éœ€è¦ä¸€ä¸ªä» `transformers` åŠ è½½çš„åŸºç¡€æ¨¡å‹å’Œå·²ç»å®šä¹‰å¥½çš„ `PeftModel` å®ä¾‹ã€‚

```python title='base model'
from transformers import AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/mt0-large")
```

ä½¿ç”¨Â `get_peft_model()`Â å’ŒÂ `peft_config`Â åˆ›å»ºÂ `PeftModel`Â æ˜¯ä½¿ç”¨ `PEFT` çš„æ ‡å‡†æ–¹æ³•ã€‚

```python title='LoraModel'
from peft import get_peft_model

model = get_peft_model(model, peft_config)
```

`PeftModel` æ‹¥æœ‰è®¸å¤šå†…ç½®çš„å±æ€§å’Œæ–¹æ³•ï¼Œè¿™é‡Œä¸»è¦ä»‹ç»ä»¥ä¸‹ä¸‰ç§ã€‚

1. `peft_model.base_model`: è®¿é—®åŸºç¡€æ¨¡å‹
2. `peft_model.print_trainable_parameters()`: æ‰“å°å¯è®­ç»ƒå‚æ•°çš„æ•°é‡å’Œåç§°
3. `peft_model.save_pretrained()`: ä¿å­˜Â `PeftModel`ï¼ŒåŒ…æ‹¬åŸºç¡€æ¨¡å‹å’Œ `PEFT` é€‚é…å™¨

ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å…¨é‡å¾®è°ƒä¸ä½¿ç”¨ä½å‚é«˜æ•ˆå¾®è°ƒæ—¶ï¼Œå‚ä¸æ¢¯åº¦æ›´æ–°çš„å‚æ•°å¯¹æ¯”å§ã€‚

```text title='model.print_trainable_parameters()'
"output: trainable params: 2359296 || all params: 1231940608 || trainable%: 0.19151053100118282"
```

`bigscience/mt0-large` æ¨¡å‹æ‹¥æœ‰ $12$ äº¿å‚æ•°ï¼Œè€Œæˆ‘ä»¬åªéœ€è¦å¾®è°ƒå…¶ä¸­ $0.19\%$ å°±èƒ½å®ç°ä»¤äººå°è±¡æ·±åˆ»çš„æ•ˆæœï¼æ€»çš„æ¥è¯´é¢å¯¹åºå¤§çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œ`PEFT` å·§å¦™åœ°å†»ç»“å¤§éƒ¨åˆ†å‚æ•°ï¼Œåªå¾®è°ƒå°‘é‡çš„é¢å¤–å‚æ•°ï¼Œå°±èƒ½å–å¾—ä¸å…¨é‡å¾®è°ƒç›¸å½“ç”šè‡³æ›´å¥½çš„æ•ˆæœã€‚è¿™æ˜¯ä¸€é¡¹å¤šä¹ˆä»¤äººå¿ƒæƒ…æ„‰æ‚¦çš„äº‹æƒ…ï¼

## è®­ç»ƒ

ğŸ‰ åˆ°ç°åœ¨å·²ç»æˆåŠŸåœ°è®¾ç½®å¥½äº†è¢« `PEFT` æ–¹æ³•åŒ…è£¹åçš„æ¨¡å‹äº†ï¼Œå¹¶ä¸”å‡†å¤‡å¥½å¼€å§‹è®­ç»ƒäº†ï¼æ¥ä¸‹æ¥å°±å¯ä»¥ä½¿ç”¨ `Trainer`, `Accelerate`, æˆ–è€…è‡ªå®šä¹‰çš„ `PyTorch` çš„è®­ç»ƒæµç¨‹ã€‚

è®­ç»ƒéƒ¨åˆ†ä¸æ˜¯æœ¬èŠ‚çš„é‡ç‚¹ï¼Œæ•…ç›´æ¥å¼•ç”¨å®˜æ–¹çš„ä»£ç ã€‚

```python title='training_args'
training_args = TrainingArguments(
    output_dir="your-name/bigscience/mt0-large-lora",
    learning_rate=1e-3,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    num_train_epochs=2,
    weight_decay=0.01,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
)
```

ç°åœ¨å°±å¯ä»¥æŠŠæ¨¡å‹ã€è®­ç»ƒå‚æ•°ã€æ•°æ®é›†ã€åˆ†è¯å™¨å’Œå…¶ä»–å¿…è¦ç»„ä»¶ç»Ÿç»Ÿæ‰”ç»™ `Trainer` ï¼Œç„¶åè°ƒç”¨ `train()` æ–¹æ³•å¼€å§‹è®­ç»ƒï¼

```python title='Trainer'
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["test"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

trainer.train()
```

## ä¿å­˜æ¨¡å‹ã€æ¨ç†

### ä¿å­˜

å½“æ¨¡å‹å®Œæˆè®­ç»ƒåï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨Â `model.save_pretrained()`Â å‡½æ•°å°†å…¶ä¿å­˜åˆ°æŒ‡å®šçš„ç›®å½•ä¸­ã€‚

### æ¨ç†

æ— è®ºæ˜¯è‡ªå·±è¿˜æ˜¯åˆ«äººä½¿ç”¨ `PEFT` è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹ï¼Œåªè¦æ‹¿åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œå°±å¯ä»¥ä½¿ç”¨Â `AutoPeftModel`Â ç±»åŠå…¶Â `from_pretrained`Â æ–¹æ³•è½»æ¾åŠ è½½ `PEFT` è®­ç»ƒçš„æ¨¡å‹ä»¥è¿›è¡Œæ¨ç†ã€‚è¿™ç§æ–¹æ³•æä¾›äº†ä¸€ç§æ— ç¼çš„æ–¹å¼æ¥åŠ è½½å’Œä½¿ç”¨ä½ çš„å¾®è°ƒæ¨¡å‹ï¼Œè€Œæ— éœ€æ‰‹åŠ¨æŒ‡å®šæ¨¡å‹æ¶æ„æˆ– `PEFT` é…ç½®ã€‚

```python title='PeftModel infer'
from peft import AutoPeftModelForCausalLM
from transformers import AutoTokenizer
import torch

model = AutoPeftModelForCausalLM.from_pretrained("ybelkada/opt-350m-lora")
tokenizer = AutoTokenizer.from_pretrained("facebook/opt-350m")

model = model.to("cuda")
model.eval()
inputs = tokenizer("Preheat the oven to 350 degrees and place the cookie dough", return_tensors="pt")

outputs = model.generate(input_ids=inputs["input_ids"].to("cuda"), max_new_tokens=50)
print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0])
```

```text title='output'
"Preheat the oven to 350 degrees and place the cookie dough in the center of the oven. In a large bowl, combine the flour, baking powder, baking soda, salt, and cinnamon. In a separate bowl, combine the egg yolks, sugar, and vanilla."
```

!!! note
	æˆ‘ä»¬æ—¢å¯ä»¥åœ¨è®­ç»ƒå®Œæˆåç«‹å³ä½¿ç”¨è®­ç»ƒå¥½çš„ `PEFT` æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œä¹Ÿå¯ä»¥å°†æ¨¡å‹ä¿å­˜åˆ°ç£ç›˜ï¼Œç¨åå†åŠ è½½å®ƒè¿›è¡Œæ¨ç†ã€‚é€‰æ‹©å“ªç§æ–¹æ³•å–å†³äºä½ çš„å…·ä½“éœ€æ±‚ã€‚å¦‚æœåªæ˜¯æƒ³å¿«é€Ÿæµ‹è¯•æ¨¡å‹ï¼Œé‚£ä¹ˆç¬¬ä¸€ç§æ–¹æ³•æ›´æ–¹ä¾¿ã€‚å¦‚æœéœ€è¦é•¿æœŸä¿å­˜å’Œç®¡ç†æ¨¡å‹ï¼Œé‚£ä¹ˆç¬¬äºŒç§æ–¹æ³•æ›´åˆé€‚ã€‚

## å‚è€ƒèµ„æ–™

<div class="grid cards" markdown>

- `PEFT`æ”¯æŒçš„å¾®è°ƒæ–¹æ³•

    ---

    äº†è§£ å·²æœ‰çš„ `PEFT` æ–¹æ³•ã€‚

    [--> Adapters HuggingFace](https://huggingface.co/docs/peft/main/en/package_reference/adalora#peft.AdaLoraConfig)

- `PEFT` æ”¯æŒçš„ä»»åŠ¡ç±»å‹

    ---

    æ¢ç´¢ `PEFT` æ”¯æŒç”¨äºå¾®è°ƒçš„ä¸åŒä¸‹æ¸¸ä»»åŠ¡ç±»å‹ã€‚

    [--> Task_type Huggingface](https://huggingface.co/docs/peft/main/en/package_reference/peft_types#peft.TaskType)

- Get Started with PEFT

    ---

    Hugging Face å®˜æ–¹çš„çš„å‚æ•°é«˜æ•ˆå¾®è°ƒå¿«é€Ÿå…¥é—¨å’Œç¤ºä¾‹ã€‚

    [--> PEFT HuggingFace](https://huggingface.co/docs/peft/quicktour)

- `PEFT`æ–¹æ³•é»˜è®¤çš„ç›®æ ‡æ¨¡å—

    ---

    `PEFT` åº“ä¸­ `constants.py` æ–‡ä»¶å®šä¹‰äº† `PEFT` åº“ä¸­ä½¿ç”¨çš„å„ç§å¸¸é‡ï¼Œå…¶ä¸­åŒ…æ‹¬äº†é»˜è®¤çš„ç›®æ ‡æ¨¡å—ã€‚

    [--> peft.utils.constants](https://github.com/huggingface/peft/blob/main/src/peft/utils/constants.py)

</div>
